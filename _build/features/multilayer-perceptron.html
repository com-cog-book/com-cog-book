---
interact_link: content/features/multilayer-perceptron.ipynb
kernel_name: python3
kernel_path: content/features
has_widgets: false
title: |-
  The Multilayer Perceptron
pagenum: 7
prev_page:
  url: /features/adaline.html
next_page:
  url: /features/cov-net.html
suffix: .ipynb
search: l partial function w frac neural perceptron times network e error j z layer linear backpropagation networks weights not units learning b multilayer sigmoid activation x com k multi book output derivative layers training figure y does hidden multiple problems cog features bias rumelhart problem matrix need algorithm adaline bmatrix value different where change cost bf compute hinton unit functions input ill vector derivatives r weight gradient html xor img src images svg width end part research idea solve learn brain index point update t jk science processing minima io non same data notation center our begin sigma single biases

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">The Multilayer Perceptron</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning-objectives">Learning objectives<a class="anchor-link" href="#Learning-objectives"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>Understand the principles behind the creation of the multilayer perceptron</li>
<li>Identify how the multilayer perceptron overcame many of the limitations of previous models</li>
<li>Expand understanding of learning via gradient descent methods</li>
<li>Develop a basic code implementation of the multilayer perceptron in Python</li>
<li>Be aware of the main limitations of multilayer perceptrons</li>
</ol>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Historical-and-theoretical-background">Historical and theoretical background<a class="anchor-link" href="#Historical-and-theoretical-background"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-origin-of-the-backpropagation-algorithm">The origin of the backpropagation algorithm<a class="anchor-link" href="#The-origin-of-the-backpropagation-algorithm"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Neural networks research came close to become an anecdote in the history of cognitive science during the '70s. The majority of researchers in cognitive science and artificial intelligence thought that neural nets were a silly idea, they could not possibly work. Minsky and Papert even provided formal proofs about it 1969. Yet, as any person that has been around science long enough knows, there are plenty of stubborn researchers that will continue paddling against the current in pursue of their own ideas.</p>
<p>David Rumelhart first heard about perceptrons and neural nets in 1963 while in graduate school at Stanford. At the time, he was doing research in mathematical psychology, which although it has lots of equations, is a different field, so he did not pay too much attention to neural nets. It wasn't until the early '70s that Rumelhart took neural nets more seriously. He was in pursuit of a more general framework to understand cognition. Mathematical psychology looked too much like a disconnected mosaic of ad-doc formulas for him. By the late '70s, Rumelhart was working at UC San Diego. He and some colleagues formed a study group about neural networks in cognitive science, that eventually evolved into what is known as the <strong>"Parallel Distributed Processing" (PDP) research group</strong>. Among the members of that group were Geoffrey Hinton, Terrence Sejnowski, Michael I. Jordan, Jeffrey L. Elman, and others that eventually became prominent researchers in the neural networks and artificial intelligence fields.</p>
<p>The original intention of the PDP group was to create a compendium of the most important research on neural networks. Their enterprise eventually evolved into something larger, producing the famous two volumes book where the so-called <strong>"backpropagation" algorithm was introduced</strong>, along with other important models and ideas. Although most people today associate the invention of the gradient descent algorithm with Hinton, the person that came up the idea was David Rumelhart, and as in most things in science, it was just a small change to a previous idea. Rumelhart and James McClelland (another young professor at UC San Diego at the time) wanted to train a neural network with multiple layers and <strong>sigmoidal units</strong> instead of threshold units (as in the perceptron) or linear units (as in the ADALINE), but they did not how to train such a model. Rumelhart knew that you could use gradient descent to train networks with linear units, as Widrow and Hoff did, so he thought that he might as well <strong>pretend that sigmoids units were linear units and see what happens</strong>. It worked, but he realized that training the model took too many iterations, so the got discouraged and let the idea aside for a while.</p>
<p>Backpropagation remained dormant for a couple of years until Hinton picked it up again. Rumelhart introduced the idea to Hinton, and <strong>Hinton thought it was a terrible idea</strong>. I could not work. He knew that backpropagation could not break the symmetry between weights and it will get stuck in local minima. He was passionate about energy-based systems known as <a href="https://www.cs.toronto.edu/~hinton/csc321/readings/boltz321.pdf">Boltzmann machines</a>, which seemed to have nicer mathematical properties. Yet, as he failed to solve more and more problems with Boltzmann machines he decided to try out backpropagation, mostly out of frustration. It worked amazingly well, way better than Boltzmann machines. He got in touch with Rumelhart about their results and both decided to include a backpropagation chapter in the PDP book and published <em>Nature</em> paper along with Ronald Williams. The <em>Nature</em> paper became highly visible and <strong>the interest in neural networks got reignited for at least the next decade</strong>. And that is how backpropagation was introduced: by a mathematical psychologist with no training in neural nets modeling and a neural net researcher that thought it was a terrible idea.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Overcoming-limitations-and-creating-advantages">Overcoming limitations and creating advantages<a class="anchor-link" href="#Overcoming-limitations-and-creating-advantages"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Truth be told, "multilayer perceptron" is a terrible name for what Rumelhart, Hinton, and Williams introduced in the mid-'80s. It is a bad name because its most fundamental piece, the <em>training algorithm</em>, is completely different from <a href="https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Learning-procedure">the one in the perceptron</a>. Therefore, a multilayer perceptron it is not simply "a perceptron with multiple layers" as the name suggests. True, it is a network composed of multiple neuron-like processing units but not every neuron-like processing unit is a perceptron. If you were to put together a bunch of Rossenblat's perceptron in sequence, you would obtain something very different from what most people today would call a multilayer perceptron. If anything, the multi-layer perceptron is more similar to the Widrow and Hoff ADALINE, and in fact, Widrow and Hoff did try multi-layer ADALINEs, known as MADALINEs (i.e., many ADALINEs), but they did not incorporate non-linear functions.</p>
<p>Now, the main reason for the resurgence of interest in neural networks was that finally someone designed an architecture that could overcome the perceptron and ADALINE limitations: <strong>to solve problems requiring non-linear solutions</strong>. Problems like the famous <a href="https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Example-1:-the-XOR-problem">XOR (exclusive or)</a> function (to learn more about it, see the "Limitations" section in the <a href="https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Example-1:-the-XOR-problem">"The Perceptron"</a> and <a href="https://com-cog-book.github.io/com-cog-book/features/adaline.html#ADALINE-limitations">"The ADALINE"</a> chapters).</p>
<p>Further, a side effect of the capacity to use multiple layers of non-linear units is that neural networks can form <strong>complex internal representations of entities</strong>. The perceptron and ADALINE did not have this capacity. They both are linear models, therefore, it doesn't matter how many layers of processing units you concatenate together, the representation learned by the network will be a linear model. You may as well dropped all the extra layers and the network eventually would learn the same solution that with multiple layers (see <a href="https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Why-adding-multiple-layers-of-processing-units-does-not-work">Why adding multiple layers of processing units does not work</a> for an explanation). This capacity is important in so far <strong>complex multi-level representation of phenomena</strong> is -probably- what the human mind does when solving problems in language, perception, learning, etc.</p>
<p>Finally, the backpropagation algorithm effectively <strong>automates the so-called "feature engineering" process</strong>. If you have ever done data analysis of any kind, you may have come across variables or features that were not in the original data but was <strong>created by transforming or combining other variables</strong>. For instance, you may have variables for income and education, and combine those to create a socio-economic status variable. That variable may have a predictive capacity above and beyond income and education in isolation. With a multilayer neural network with non-linear units trained with backpropagatio such a <em>transformation process happens automatically</em> in the intermediate or <strong>"hidden" layers of the network</strong>. Those intermediate representations often are hard or impossible to interpret for humans. They may make no sense whatsoever for us but somehow help to solve the pattern recognition problem at hand, so the network will learn that representation. Does this mean that neural nets learn different representations from the human brain? Maybe, maybe not. The problem is that we don't have direct access to the kind of representations learned by the brain either, and a neural net will seldom be trained with the same data that a human brain is trained in real life.</p>
<p>The application of the backpropagation algorithm in multilayer neural network architectures was a major breakthrough in the artificial intelligence and cognitive science community, that catalyzed a new generation of research in cognitive science. Nonetheless, it took several decades of advance on computing and data availability before artificial neural networks became the dominant paradigm in the research landscape as it is today. Next, we will explore its mathematical formalization and application.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Mathematical-formalization">Mathematical formalization<a class="anchor-link" href="#Mathematical-formalization"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The classical multilayer perceptron as introduced by Rumelhart, Hinton, and Williams, can be described by:</p>
<ul>
<li>a <em>linear function</em> that aggregates the input values</li>
<li>a <em>sigmoid function</em>, also called <em>activation function</em></li>
<li>a <em>threshold function</em> for classification process, and an <em>identity function</em> for regression problems</li>
<li>a <em>loss or cost</em> function that computes the overall error of the network</li>
<li>a <em>learning procedure</em> to adjust the weights of the network, i.e., the so-called <em>backpropagation</em> algorithm</li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Linear-function">Linear function<a class="anchor-link" href="#Linear-function"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The linear aggregation function is the same as in the perceptron and the ADALINE. But, with a couple of differences that change the notation: now we are dealing multiple layers and processing units. The conventional way to represent this is with <strong>linear algebra notation</strong>. This is not a course of linear algebra, reason I won't cover the mathematics in detail. However, I'll introduce enough concepts and notation to understand the fundamental operations involved in the neural network calculation. The most important aspect is to understand what is a <em>matrix</em>, a <em>vector</em>, and how to <em>multiply</em> them together.</p>
<p>A <strong>vector</strong> is a collection of <em>ordered numbers</em> or <em>scalars</em>. If you are familiar with data analysis, a vector is like a column or row in a dataframe. If you are familiar with programming, a vector is like an array or a list. A generic Vector $\bf{x}$ is defined as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/vector.svg" width="60%"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A <strong>matrix</strong> is a <em>collection of vectors</em> or <em>lists of numbers</em>. In data analysis, this is equivalent to a 2-dimensional dataframe. In programming is equivalent to a multidimensional array or a list of lists. A generic matrix $W$ is defined as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/matrix.svg" width="80%"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using this notation, let's look at a simplified example of a network with:</p>
<ul>
<li>3 inputs units</li>
<li>1 hidden layer with 2 units</li>
</ul>
<p>Like the one in <strong>Figure 1</strong></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>Figure 1</center>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/simple-net.svg" width="40%"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The input vector for our first training example would look like:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$ \bf{x=}
\begin{bmatrix}
x_1 \\
x_2 \\
x_3 \\
\end{bmatrix}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since we have 3 input units connecting to hidden 2 units we have 3x2 weights. This is represented with a matrix as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$W=
\begin{bmatrix}
w_{11} &amp; w_{12}\\
w_{21} &amp; w_{22}\\
w_{31} &amp; w_{32}
\end{bmatrix}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <em>output of the linear function equals to the multiplication of the vector $\bf{x}$ and the matrix $W$</em>. To perform the multiplication in this case we need to transpose the matrix $W$ to match the number of columns in $W$ with the number of rows in $\bf{x}$. Transposing means to "flip" the columns of $W$ such that the first column becomes the first row, the second column becomes the second row, and so forth. The matrix-vector multiplication equals to:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
{\bf z=} 
W^T\times {\bf x=}
\begin{bmatrix}
w_{11} &amp; w_{12} &amp; w_{13} \\
w_{21} &amp; w_{22} &amp; w_{23} \\
\end{bmatrix}
\begin{bmatrix}
x_1 \\
x_2 \\
x_3 \\
\end{bmatrix}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$${\bf z=} 
W^T\times {\bf x=}
\begin{bmatrix}
x_1w_{11} + x_2w_{12} + x_3w_{13}\\
x_1w_{21} + x_2w_{22} + x_3w_{23}
\end{bmatrix}
=
\begin{bmatrix}
z_1 \\
z_2
\end{bmatrix}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The previous matrix operation in summation notation equals to:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/linear-function-multi-perceptron.svg" width="70%"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here, $f$ is a function of each element of the vector $\bf{x}$ and each element of the matrix $W$. The $m$ index identifies the rows in $W^T$ and the rows in $\bf{z}$. The $n$ index indicates the columns in $W^T$ and the rows in $\bf{x}$. Notice that we add a $b$ bias term, that has the role to simplify learning a proper threshold for the function. If you are curious about that <a href="https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Linear-aggregation-function">read this</a>. In sum, the <strong>linear function is a weighted sum of the inputs plus a bias</strong>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Sigmoid-function">Sigmoid function<a class="anchor-link" href="#Sigmoid-function"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each element of the $\bf{z}$ vector becomes an input for the sigmoid function $\sigma$():</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/sigmoid-function-multi-perceptron.svg" width="60%"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The output of $\sigma(z_m)$ is another $m$ dimensional vector $a$, one entry for each unit in the hidden layer like:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\bf{a}=
\begin{bmatrix}
a_1 \\
a_2
\end{bmatrix}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here, $a$ stands for "activation", which is a common way to refer to the output of hidden units. This sigmoid function "wrapping" the outcome of the linear function is commonly called <strong>activation function</strong>. The idea is that a unit gets "activated" in more or less the same manner that a neuron gets activated when a sufficiently strong input is received. The selection of a sigmoid is arbitrary. Many different non-linear functions could be selected at this stage in the network, like a <a href="https://mathworld.wolfram.com/HyperbolicTangent.html">Tanh</a> or a <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks">ReLU</a>). Unfortunately, there is no principled way to chose activation functions for hidden layers. It is mostly a matter of trial and error.</p>
<p>A nice property of sigmoid functions is they are "mostly linear" but they saturate as they approach 1 and 0 in the extremes. <strong>Chart 1</strong> shows the shape of a sigmoid function (blue line) and the point where the gradient is at its maximum (the red line connecting the blue line).</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">expit</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">altair</span> <span class="k">as</span> <span class="nn">alt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;a&quot;</span><span class="p">:</span><span class="n">a</span><span class="p">,</span> <span class="s2">&quot;z&quot;</span><span class="p">:</span><span class="n">z</span><span class="p">})</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;z1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;a1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">sigmoid</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">mark_line</span><span class="p">()</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;a&quot;</span><span class="p">)</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">mark_rule</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;z1&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;a1&quot;</span><span class="p">)</span>
<span class="p">(</span><span class="n">sigmoid</span> <span class="o">+</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">properties</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Chart 1&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

<div id="altair-viz-51a15a55061c48e1a9db3bea35a2d4ef"></div>
<script type="text/javascript">
  (function(spec, embedOpt){
    const outputDiv = document.getElementById("altair-viz-51a15a55061c48e1a9db3bea35a2d4ef");
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm//vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm//vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm//vega-embed@6?noext",
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () => resolve(paths[lib]);
        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName("head")[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === "function") {
      displayChart(vegaEmbed);
    } else {
      loadScript("vega")
        .then(() => loadScript("vega-lite"))
        .then(() => loadScript("vega-embed"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 400, "continuousHeight": 300}}, "layer": [{"mark": "line", "encoding": {"x": {"type": "quantitative", "field": "z"}, "y": {"type": "quantitative", "field": "a"}}}, {"mark": {"type": "rule", "color": "red"}, "encoding": {"x": {"type": "quantitative", "field": "z1"}, "y": {"type": "quantitative", "field": "a1"}}}], "data": {"name": "data-4ce8df9580f59e633b8d399e9190ac6d"}, "title": "Chart 1", "$schema": "https://vega.github.io/schema/vega-lite/v4.0.2.json", "datasets": {"data-4ce8df9580f59e633b8d399e9190ac6d": [{"a": 0.0066928509242848554, "z": -5.0, "z1": 0, "a1": 0.5}, {"a": 0.007391541344281971, "z": -4.9, "z1": 0, "a1": 0.5}, {"a": 0.00816257115315989, "z": -4.800000000000001, "z1": 0, "a1": 0.5}, {"a": 0.009013298652847815, "z": -4.700000000000001, "z1": 0, "a1": 0.5}, {"a": 0.009951801866904308, "z": -4.600000000000001, "z1": 0, "a1": 0.5}, {"a": 0.010986942630593162, "z": -4.500000000000002, "z1": 0, "a1": 0.5}, {"a": 0.012128434984274213, "z": -4.400000000000002, "z1": 0, "a1": 0.5}, {"a": 0.013386917827664744, "z": -4.3000000000000025, "z1": 0, "a1": 0.5}, {"a": 0.014774031693273017, "z": -4.200000000000003, "z1": 0, "a1": 0.5}, {"a": 0.01630249937144089, "z": -4.100000000000003, "z1": 0, "a1": 0.5}, {"a": 0.017986209962091496, "z": -4.0000000000000036, "z1": 0, "a1": 0.5}, {"a": 0.01984030573407743, "z": -3.900000000000004, "z1": 0, "a1": 0.5}, {"a": 0.021881270936130383, "z": -3.8000000000000043, "z1": 0, "a1": 0.5}, {"a": 0.024127021417669092, "z": -3.7000000000000046, "z1": 0, "a1": 0.5}, {"a": 0.026596993576865725, "z": -3.600000000000005, "z1": 0, "a1": 0.5}, {"a": 0.02931223075135617, "z": -3.5000000000000053, "z1": 0, "a1": 0.5}, {"a": 0.03229546469845033, "z": -3.4000000000000057, "z1": 0, "a1": 0.5}, {"a": 0.035571189272635965, "z": -3.300000000000006, "z1": 0, "a1": 0.5}, {"a": 0.03916572279676412, "z": -3.2000000000000064, "z1": 0, "a1": 0.5}, {"a": 0.043107254941085846, "z": -3.1000000000000068, "z1": 0, "a1": 0.5}, {"a": 0.04742587317756646, "z": -3.000000000000007, "z1": 0, "a1": 0.5}, {"a": 0.05215356307841737, "z": -2.9000000000000075, "z1": 0, "a1": 0.5}, {"a": 0.05732417589886832, "z": -2.800000000000008, "z1": 0, "a1": 0.5}, {"a": 0.06297335605699601, "z": -2.700000000000008, "z1": 0, "a1": 0.5}, {"a": 0.06913842034334627, "z": -2.6000000000000085, "z1": 0, "a1": 0.5}, {"a": 0.07585818002124294, "z": -2.500000000000009, "z1": 0, "a1": 0.5}, {"a": 0.08317269649392166, "z": -2.4000000000000092, "z1": 0, "a1": 0.5}, {"a": 0.09112296101485534, "z": -2.3000000000000096, "z1": 0, "a1": 0.5}, {"a": 0.09975048911968425, "z": -2.20000000000001, "z1": 0, "a1": 0.5}, {"a": 0.10909682119561194, "z": -2.1000000000000103, "z1": 0, "a1": 0.5}, {"a": 0.11920292202211644, "z": -2.0000000000000107, "z1": 0, "a1": 0.5}, {"a": 0.1301084743629966, "z": -1.900000000000011, "z1": 0, "a1": 0.5}, {"a": 0.1418510649004864, "z": -1.8000000000000114, "z1": 0, "a1": 0.5}, {"a": 0.15446526508353317, "z": -1.7000000000000117, "z1": 0, "a1": 0.5}, {"a": 0.16798161486607383, "z": -1.600000000000012, "z1": 0, "a1": 0.5}, {"a": 0.1824255238063545, "z": -1.5000000000000124, "z1": 0, "a1": 0.5}, {"a": 0.19781611144141623, "z": -1.4000000000000128, "z1": 0, "a1": 0.5}, {"a": 0.21416501695743917, "z": -1.3000000000000131, "z1": 0, "a1": 0.5}, {"a": 0.23147521650098, "z": -1.2000000000000135, "z1": 0, "a1": 0.5}, {"a": 0.24973989440487981, "z": -1.1000000000000139, "z1": 0, "a1": 0.5}, {"a": 0.26894142136999233, "z": -1.0000000000000142, "z1": 0, "a1": 0.5}, {"a": 0.28905049737499305, "z": -0.9000000000000146, "z1": 0, "a1": 0.5}, {"a": 0.3100255188723844, "z": -0.8000000000000149, "z1": 0, "a1": 0.5}, {"a": 0.3318122278318305, "z": -0.7000000000000153, "z1": 0, "a1": 0.5}, {"a": 0.35434369377420094, "z": -0.6000000000000156, "z1": 0, "a1": 0.5}, {"a": 0.3775406687981417, "z": -0.500000000000016, "z1": 0, "a1": 0.5}, {"a": 0.40131233988754406, "z": -0.40000000000001634, "z1": 0, "a1": 0.5}, {"a": 0.4255574831883369, "z": -0.3000000000000167, "z1": 0, "a1": 0.5}, {"a": 0.45016600268751783, "z": -0.20000000000001705, "z1": 0, "a1": 0.5}, {"a": 0.47502081252105566, "z": -0.10000000000001741, "z1": 0, "a1": 0.5}, {"a": 0.49999999999999556, "z": -1.7763568394002505e-14, "z1": 0, "a1": 0.5}, {"a": 0.5249791874789355, "z": 0.09999999999998188, "z1": 0, "a1": 0.5}, {"a": 0.5498339973124733, "z": 0.19999999999998153, "z1": 0, "a1": 0.5}, {"a": 0.5744425168116544, "z": 0.29999999999998117, "z1": 0, "a1": 0.5}, {"a": 0.5986876601124473, "z": 0.3999999999999808, "z1": 0, "a1": 0.5}, {"a": 0.62245933120185, "z": 0.49999999999998046, "z1": 0, "a1": 0.5}, {"a": 0.6456563062257908, "z": 0.5999999999999801, "z1": 0, "a1": 0.5}, {"a": 0.6681877721681616, "z": 0.6999999999999797, "z1": 0, "a1": 0.5}, {"a": 0.6899744811276081, "z": 0.7999999999999794, "z1": 0, "a1": 0.5}, {"a": 0.7109495026249997, "z": 0.899999999999979, "z1": 0, "a1": 0.5}, {"a": 0.7310585786300007, "z": 0.9999999999999787, "z1": 0, "a1": 0.5}, {"a": 0.7502601055951135, "z": 1.0999999999999783, "z1": 0, "a1": 0.5}, {"a": 0.7685247834990137, "z": 1.199999999999978, "z1": 0, "a1": 0.5}, {"a": 0.7858349830425548, "z": 1.2999999999999776, "z1": 0, "a1": 0.5}, {"a": 0.8021838885585781, "z": 1.3999999999999773, "z1": 0, "a1": 0.5}, {"a": 0.8175744761936402, "z": 1.499999999999977, "z1": 0, "a1": 0.5}, {"a": 0.8320183851339212, "z": 1.5999999999999766, "z1": 0, "a1": 0.5}, {"a": 0.8455347349164622, "z": 1.6999999999999762, "z1": 0, "a1": 0.5}, {"a": 0.8581489350995093, "z": 1.7999999999999758, "z1": 0, "a1": 0.5}, {"a": 0.8698915256369995, "z": 1.8999999999999755, "z1": 0, "a1": 0.5}, {"a": 0.8807970779778798, "z": 1.9999999999999751, "z1": 0, "a1": 0.5}, {"a": 0.8909031788043846, "z": 2.0999999999999748, "z1": 0, "a1": 0.5}, {"a": 0.9002495108803125, "z": 2.1999999999999744, "z1": 0, "a1": 0.5}, {"a": 0.9088770389851418, "z": 2.299999999999974, "z1": 0, "a1": 0.5}, {"a": 0.9168273035060757, "z": 2.3999999999999737, "z1": 0, "a1": 0.5}, {"a": 0.9241418199787546, "z": 2.4999999999999734, "z1": 0, "a1": 0.5}, {"a": 0.9308615796566515, "z": 2.599999999999973, "z1": 0, "a1": 0.5}, {"a": 0.937026643943002, "z": 2.6999999999999726, "z1": 0, "a1": 0.5}, {"a": 0.9426758241011297, "z": 2.7999999999999723, "z1": 0, "a1": 0.5}, {"a": 0.947846436921581, "z": 2.899999999999972, "z1": 0, "a1": 0.5}, {"a": 0.9525741268224319, "z": 2.9999999999999716, "z1": 0, "a1": 0.5}, {"a": 0.9568927450589126, "z": 3.0999999999999712, "z1": 0, "a1": 0.5}, {"a": 0.9608342772032344, "z": 3.199999999999971, "z1": 0, "a1": 0.5}, {"a": 0.9644288107273629, "z": 3.2999999999999705, "z1": 0, "a1": 0.5}, {"a": 0.9677045353015485, "z": 3.39999999999997, "z1": 0, "a1": 0.5}, {"a": 0.9706877692486428, "z": 3.49999999999997, "z1": 0, "a1": 0.5}, {"a": 0.9734030064231335, "z": 3.5999999999999694, "z1": 0, "a1": 0.5}, {"a": 0.97587297858233, "z": 3.699999999999969, "z1": 0, "a1": 0.5}, {"a": 0.9781187290638689, "z": 3.7999999999999687, "z1": 0, "a1": 0.5}, {"a": 0.9801596942659219, "z": 3.8999999999999684, "z1": 0, "a1": 0.5}, {"a": 0.982013790037908, "z": 3.999999999999968, "z1": 0, "a1": 0.5}, {"a": 0.9836975006285584, "z": 4.099999999999968, "z1": 0, "a1": 0.5}, {"a": 0.9852259683067265, "z": 4.199999999999967, "z1": 0, "a1": 0.5}, {"a": 0.9866130821723347, "z": 4.299999999999967, "z1": 0, "a1": 0.5}, {"a": 0.9878715650157253, "z": 4.399999999999967, "z1": 0, "a1": 0.5}, {"a": 0.9890130573694065, "z": 4.499999999999966, "z1": 0, "a1": 0.5}, {"a": 0.9900481981330953, "z": 4.599999999999966, "z1": 0, "a1": 0.5}, {"a": 0.9909867013471519, "z": 4.6999999999999655, "z1": 0, "a1": 0.5}, {"a": 0.9918374288468399, "z": 4.799999999999965, "z1": 0, "a1": 0.5}, {"a": 0.9926084586557179, "z": 4.899999999999965, "z1": 0, "a1": 0.5}]}}, {"mode": "vega-lite"});
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Output-function">Output function<a class="anchor-link" href="#Output-function"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For <strong>binary classification problems</strong> each output unit implements a <strong>threshold function</strong> as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\hat{y} =
f(a_m)
\begin{cases}
+1, &amp; \text{if } a \text{ &gt; 0.5} \\
-1, &amp; \text{otherwise}
\end{cases}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For <strong>regression problems</strong> (problems that require a real-valued output value like predicting income or test-scores) each output unit implements an <strong>identity function</strong> as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\hat{y}=f(a_m)=a_m
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In simple terms, an identity function returns the same value as the input. It does nothing. The point is that the $a$ is already the output of a linear function, therefore, it is the value that we need for this kind of problem.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For <strong>multiclass classification problems</strong>, we can use a <strong>softmax function</strong> as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\hat{y} = \sigma(a)_i = \frac{e^{\beta a_i}}{\sum_{j=1}^{k}e^{\beta z_j}}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Cost-function">Cost function<a class="anchor-link" href="#Cost-function"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The cost function is the <strong>measure of "goodness" or "badness"</strong> (depending on how you like to see things) of the network performance. This can be a confusing term. People sometimes call it <em>objective function</em>, <em>loss function</em>, or <em>error function</em>. Conventionally, <em>loss function</em> usually refers to the measure of error for a <em>single</em> training case, <em>cost function</em> to the aggregate error for the <em>entire</em> dataset, and <em>objective function</em> is a more generic term referring to any measure of the overall error in a network. For instance, "mean squared error", "sum of squared error", and "binary cross-entropy" are all <em>objective functions</em>. For our purposes, I'll use all those terms interchangeably: they all refer to the measure of performance of the network.</p>
<p>Nowadays, you would probably want to use different cost functions for different types of problems. In their original work, Rumelhart, Hinton, and Williams used the <strong>sum of squared errors</strong> defined as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/cost-function.svg" width="60%"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Forward-propagation">Forward propagation<a class="anchor-link" href="#Forward-propagation"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All neural networks can be divided into two parts: a <strong>forward propagation phase</strong>, where the information "flows" forward to compute predictions and the error; and the <strong>backward propagation phase</strong>, where the <em>backpropagation algorithm</em> computes the error derivatives and update the network weights. <strong>Figure 2</strong> illustrate a network with 2 input units, 3 hidden units, and 1 output unit.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center> Figure 2 </center>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/forward-pass.svg" width="100%"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <em>forward propagation</em> phase involves "chaining" all the steps we defined so far: the <em>linear function</em>, the <em>sigmoid function</em>, and the <em>threshold function</em>. Consider the network in <strong>Figure 2</strong>. Let's label the linear function as $\lambda()$, the sigmoid function as $\sigma()$, and the threshold function as $\tau()$. Now, the network in <strong>Figure 2</strong> can be represented as:</p>
$$
\hat{y} = \tau(\sigma^{(2)}(\lambda^{(2)}(\sigma^{(1)}(\lambda^{(1)}(x_n, w_{mn})))))
$$<p>All neural networks can be represented as a <strong>composition of functions</strong> where each step is nested in the next step. For instance, we can add an extra hidden layer to the network in <strong>Figure 2</strong> by:</p>
$$
\hat{y} = \tau(\sigma^{(3)}(\lambda^{(3)}(\sigma^{(2)}(\lambda^{(2)}(\sigma^{(1)}(\lambda^{(1)}(x_n, w_{mn})))))))
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Backpropagation-algorithm">Backpropagation algorithm<a class="anchor-link" href="#Backpropagation-algorithm"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the <a href="https://com-cog-book.github.io/com-cog-book/features/adaline.html#The-ADALINE-error-surface">ADALINE chapter</a> I introduced the ideas of <strong>searching for a set of weights that minimize the error via gradient descent</strong>, and the difference between <strong>convex and non-convex optimization</strong>. If you have not read that section, I'll encourage you to read that first. Otherwise, the important part is to remember that since we are introducing nonlinearities in the network the error surface of the multilayer perceptron is <a href="https://arxiv.org/pdf/1712.07897.pdf">non-convex</a>. This means that there are multiple "valleys" with "local minima", along with the "global minima", and that backpropagation <strong>is not guaranteed to find the global minima</strong>. Remember that the "global minima" is the point where the error (i.e., the value of the cost function) is at its minimum, whereas the "local minima" is the point of minimum error for a sub-section of the error surface. <strong>Figure 3</strong> illustrates these concepts on a 3D surface. The vertical axis represents the error of the surface, and the other two axes represent different combinations of weights for the network. In the figure, you can observe how different combinations of weights produce different values of error.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center> Figure 3 </center>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/sse-nonconvex.svg" width="100%"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we have all the ingredients to <strong>introduce the almighty backpropagation algorithm</strong>. Remember that our goal is to learn <strong>how the error changes as we change the weights of the network by tiny amount</strong> and that the cost function was defined as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
E = \frac{1}{2}\sum_k(a_k - y_k)^2
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There is one piece of notation I'll introduce to clarify where in the network are we at each step of the computation. I'll use the superscript $L$ to index the outermost function in the network. For example, $a^{(L)}$ index the last sigmoid activation function at the output layer, $a^{(L-1)}$ index the previous sigmoid activation function at the hidden layer, and $x^{(L-2)}$ index the features in the input layer (which are the only thing in that layer). Think about this as moving from the right at $(L)$ to the left at $(L-2)$ in the computational graph of the network in <strong>Figure 4</strong>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Backpropagation-for-single-unit-multilayer-perceptron">Backpropagation for single unit multilayer perceptron<a class="anchor-link" href="#Backpropagation-for-single-unit-multilayer-perceptron"> </a></h4>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In my experience, tracing the indices in backpropagation is the most confusing part, so I'll ignore the summation symbol and drop the subscript $k$ to make the math as clear as possible. You can think of this as having a network with a single input unit, a single hidden unit, and a single output unit, as in <strong>Figure 4</strong>. We will first work out backpropagation for this simplified network and then expand for the multi-neuron case.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center> Figure 4 </center>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/single-unit.svg" width="50%"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The whole purpose of backpropagation is to answer the following question: <strong>"How does the error change when we change the weights by a tiny amount?"</strong> (be aware that I'll use the words "derivatives" and "gradients" interchangeably).</p>
<p>To accomplish this you have to realize the following:</p>
<ol>
<li>The error $E$ depends on the value of the sigmoid activation function $a$. </li>
<li>The value of the sigmoid function activation function $a$ depends on the value of the linear function $z$.</li>
<li>The value of the linear function $z$ depends on the value of the weights $w$  </li>
</ol>
<p>Therefore, we can trace a change of dependence on the weights. This means we have to answer these three questions in a chain:</p>
<ol>
<li>How does the error $E$ change when we change the activation $a$ by a tiny amount  </li>
<li>How does the activation $a$ change when we change the activation $z$ by a tiny amount  </li>
<li>How does $z$ change when we change the weights $w$ by a tiny amount</li>
</ol>
<p>Such sequence can be mathematically expressed with the <strong>chain-rule of calculus</strong> as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/chain-rule.svg"  width=70%></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>No deep knowledge of calculus is needed to understand the chain-rule. In essence, indicates <strong>how to differentiate <a href="https://en.wikipedia.org/wiki/Function_composition">composite functions</a></strong>, i.e.,  functions nested inside other functions. If you remember the section above this one, we showed that a multi-layer perceptron can be expressed as a composite function. Very convenient. The rule says that we take the derivative of the outermost function, and multiple by the derivative of the inside function, recursively. That's it.</p>
<p>Good. Now, let's differentiate each part of $\frac{\partial E}{\partial w^(L)}$. Let's begin from the outermost part.</p>
<p>The derivative of the error with respect to (w.r.t) the sigmoid activation function is:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial a^{(L)}} = a^{(L)} - y 
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, the derivative of the sigmoid activation function w.r.t the linear function is:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial a^{(L)}}{\partial z^{(L)}} = a^{(L)}(1-a^{(L)}) 
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, the derivative of the linear function w.r.t the weights is:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial z^{(L)}}{\partial w^{(L)}} = a^{(L-1)}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we put all the pieces together and replace we obtain:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial w^{(L)}}  = a^{(L)} - y \times a^{(L)}(1-a^{(L)}) \times a^{(L-1)}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At this point, we have figured out how the error changes as we change the weight connecting the <strong>hidden layer and the output layer $w^{(L)}$</strong>. Amazing progress. We still need to know how the error changes as we adjust the weight connecting the <strong>input layer and the hidden layer $w^{(L-1)}$</strong>. Fortunately, this is pretty straightforward: we apply the chain-rule again, and again until we get there.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial w^{(L-1)}} = \frac{\partial E}{\partial a^{(L)}} \times \frac{\partial a^{(L)}}{\partial z^{(L)}} \times \frac{\partial z^{(L)}}{\partial a^{(L-1)}} \times \frac{\partial a^{(L-1)}}{\partial z^{(L-1)}}  \times \frac{\partial z^{(L-1)}}{\partial w^{(L-1)}}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Again, replacing with the actual derivatives this becomes:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial w^{(L-1)}}  = a^{(L)} - y \times a^{(L)}(1-a^{(L)}) \times w^{(L)} \times a^{(L-1)}(1-a^{(L-1)}) \times x^{(L-1)}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fantastic. There is one tiny piece we haven't mentioned: <strong>the derivative of the error with respect to the bias term $b$</strong>. There are two ways to approach this. One way is to treat the bias as another feature (usually with value 1) and add the corresponding weight to the matrix $W$. In such a case, the derivative of the weight for the bias is calculated along with the weights for the other features in the exact same manner. The other option is to compute the derivative separately as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial b^{(L)}} = \frac{\partial E}{\partial a^{(L)}} \times \frac{\partial a^{(L)}}{\partial z^{(L)}} \times \frac{\partial z^{(L)}}{\partial b^{(L)}}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We already know the values for the first two derivatives. We just need to figure out the derivative for $\frac{\partial z^{(L)}}{\partial b^{(L)}}$. Now, remember that the <em>slope of $z$ does not depend at all from $b$</em>, because $b$ is just a constant value added at the end. Therefore, the derivative of the error w.r.t the bias reduces to:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial b^{(L)}}  = a^{(L)} - y \times a^{(L)}(1-a^{(L)})
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is very convenient because it means we can reutilize part of the calculation for the derivative of the weights to compute the derivative of the biases.</p>
<p>The last missing part is the derivative of the error w.r.t. the bias $b$ in the $(L-1)$ layer:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial b^{(L-1)}} = \frac{\partial E}{\partial a^{(L)}} \times \frac{\partial a^{(L)}}{\partial z^{(L)}} \times \frac{\partial z^{(L)}}{\partial a^{(L-1)}} \times \frac{\partial a^{(L-1)}}{\partial z^{(L-1)}}  \times \frac{\partial z^{(L-1)}}{\partial b^{(L-1)}}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Replacing with the actual derivatives for each expression:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial b^{(L-1)}}  = a^{(L)} - y \times a^{(L)}(1-a^{(L)}) \times w^{(L)} \times a^{(L-1)}(1-a^{(L-1)})
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Same as before, we can reuse part of the calculation for the derivative of $w^{(L-1)}$ to solve this. Every time we train a neural net wit backpropagation we will need to <strong>compute the derivatives for all the weight and biases as showed before</strong>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Backpropagation-for-multiple-unit-multilayer-perceptron">Backpropagation for multiple unit multilayer perceptron<a class="anchor-link" href="#Backpropagation-for-multiple-unit-multilayer-perceptron"> </a></h4>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Pretty much all neural networks you'll find have more than one neuron. Until now, we have assumed a network with a single neuron per layer. The only difference between the expressions we have used so far and added more units is a couple of <strong>extra indices</strong>. For example, we can use the letter $j$ to index the units in the output layer, the letter $k$ to index the units in the hidden layer, and the letter $i$ to index the units in the input layer. We also need indices for the weights. For any network with multiple units, we will have more weights than units, which means we will need two subscripts to indicate each weight. This is visible in the weight matrix in <strong>Figure 2</strong>. We will index the weights as $w_{\text{destination-units} \text{, } \text{origin-units}}$. For instance, weights in $(L)$ become $w_{jk}$.</p>
<p>With all this notation in mind, our original equation for the derivative of the error w.r.t the weights in $(L)$ layer becomes:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial w^{(L)}_{jk}} = \frac{\partial E_i}{\partial a^{(L)}_j} \times \frac{\partial a^{(L)}_j}{\partial z^{(L)}_j} \times \frac{\partial z^{(L)}_j}{\partial w^{(L)}_{jk}}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Replacing with the derivatives:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial w^{(L)}_{jk}}  = a^{(L)}_j - y \times a^{(L)}_j(1-a^{(L)}_j) \times a^{(L-1)}_k
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There is a second thing to consider. This time we have to take into account that each <strong>sigmoid activation $a$ from  $(L-1)$ layers impacts the error via multiple pathways</strong> (assuming a network with <em>multiple output units</em>). In <strong>Figure 5</strong> this is illustrated by blue and red connections to the output layer. To reflect this, we add a summation symbol and the expression for the derivative of the error w.r.t the sigmoid activation becomes:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial a^{(L-1)}_k} = \sum_{j} \frac{\partial E}{\partial a^{(L)}_j} \times \frac{\partial a^{(L)}_j}{\partial z^{(L)}_j} \times \frac{\partial z^{(L)}_j}{\partial a^{(L-1)}_k}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, considering both the new subscripts and summation for $\frac{\partial E}{\partial a^{(L-1)}_k}$, we can apply the chain-rule one more time to compute the error derivatives for $w$ in $(L-1)$ as:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial w^{(L-1)}_{ki}} = \left(\sum_{j} \frac{\partial E}{\partial a^{(L)}_j} \times \frac{\partial a^{(L)}_j}{\partial z^{(L)}_j} \times \frac{\partial z^{(L)}_j}{\partial a^{(L-1)}_k}\right)  \times \frac{\partial a^{(L-1)}_k}{\partial z^{(L-1)}_k} \times \frac{\partial z^{(L-1)}_k}{\partial w^{(L-1)}_k}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Replacing with the actual derivatives for each expression we obtain:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial w^{(L-1)}_{ki}}  = a^{(L)}_j - y \times a^{(L)}_j(1-a^{(L)}_j) \times w^{(L)}_{jk} \times a^{(L-1)}_k(1-a^{(L-1)}_k) \times x^{(L-1)}_i
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Considering the new indices, the derivative for the error w.r.t the bias $b$ becomes:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial b_j^{(L)}} = \frac{\partial E}{\partial a^{(L)}_j} \times \frac{\partial a^{(L)}_j}{\partial z^{(L)}_j} \times \frac{\partial z^{(L)}_j}{\partial b^{(L)}_j}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Replacing with the actual derivatives we get:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial b^{(L)}_j}  = a^{(L)}_j - y \times a^{(L)}_j(1-a^{(L)}_j)
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Last but not least, the expression for the bias $b$ at layer $(L-1)$ is:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial b^{(L-1)}} = \frac{\partial E}{\partial a^{(L)}_j} \times \frac{\partial a^{(L)}_j}{\partial z^{(L)}_j} \times \frac{\partial z^{(L)}_j}{\partial a^{(L-1)}_k} \times \frac{\partial a^{(L-1)}_k}{\partial z^{(L-1)}_k}  \times \frac{\partial z^{(L-1)}_k}{\partial b^{(L-1)}_k}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Replacing with the actual derivatives we get:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\frac{\partial E}{\partial b^{(L-1)}}  = a^{(L)}_j - y \times a^{(L)}_j(1-a^{(L)}_j) \times w^{(L)}_{jk} \times a^{(L-1)}_k(1-a^{(L-1)}_k)
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And that's it! <strong>Those are all the pieces for the backpropagation algorithm</strong>. Probably, the hardest part is to track all the indices. To further clarify the notation you can look at the diagram in <strong>Figure 5</strong> that exemplifies where each piece of the equation is located.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center> Figure 5 </center>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/multi-perceptron/backprop.svg" width="100%"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Backpropagation-weight-update">Backpropagation weight update<a class="anchor-link" href="#Backpropagation-weight-update"> </a></h4>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We learned how to compute the gradients for all the weights and biases. Now we just need to <strong>use the computed gradients to update the weights and biases values</strong>. This is actually when the <strong>learning</strong> happens. We do this by taking a portion of the gradient and substracting that to the current weight and bias value.</p>
<p>For the wegiths $w_{jk}$ in the $(L)$ layer we update by:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
w_{jk}^{L} = w_{jk}^{L} - \eta \times \frac{\partial E}{\partial w_{jk}^{L}}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For the wegiths $w_{ki}$ in the $(L-1)$ layer we update by:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
w_{ki}^{L-1} = w_{ki}^{L-1} - \eta \times \frac{\partial E}{\partial w_{ki}^{L-1}}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For the bias $b$ in the $(L)$ layer we update by:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
b^{(L)} = b^{(L)} - \eta \times \frac{\partial E}{\partial b^{(L)}}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For the bias $b$ in the $(L-1)$ layer we update by:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
b^{(L-1)} = b^{(L-1)} - \eta \times \frac{\partial E}{\partial b^{(L-1)}}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Where $\eta$ is the <em>step size</em> or <em>learning rate</em>.</p>
<p>If you are not familiar with the idea of a learning rate, you can review the ADALINE chapter where I briefly explain the concept <a href="https://com-cog-book.github.io/com-cog-book/features/adaline.html#Learning-procedure">here</a>. In brief, a learning rate controls <strong>how fast we descend over the error surface given the computed gradient</strong>. This is important because we want to give steps just large enough to reach the minima of the surface at any point we may be when searching for the weights. You can see a more deep explanation <a href="https://en.wikipedia.org/wiki/Learning_rate">here</a>.</p>
<p>I don't know about you but I have to go over several rounds of carefully studying the equations behind backpropagation to finally understand them fully. This may or not be true for you, but I believe the effort pays off as <strong>backpropagation is the engine of every neural network model today</strong>. Regardless, the good news is the modern numerical computation libraries like <code>NumPy</code>, <code>Tensorflow</code>, and <code>Pytorch</code> provide all the necessary methods and abstractions to make the implementation of neural networks and backpropagation relatively easy.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Code-implementation">Code implementation<a class="anchor-link" href="#Code-implementation"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will <strong>implement a multilayer-perceptron with one hidden layer by translating all our equations into code</strong>. One important thing to consider is that we won't implement all the loops that the summation notation implies. Loops are known for being highly inefficient computationally, so we want to avoid them. Fortunately, we can use <strong>matrix operations to achieve the exact same result</strong>. This means that all the computations will be "vectorized". If you are not familiar with <a href="https://www.geeksforgeeks.org/vectorization-in-python/">vectorization</a> you just need to know that instead of looping over each row in our training dataset we compute the outcome for each row all at once using linear algebra operations. This makes computation in neural networks highly efficient compared to using loops. To do this, I'll only use <code>NumPy</code> which is the most popular library for matrix operations and linear algebra in Python.</p>
<p>Remember that we need to computer the following operations in order:</p>
<ol>
<li>linear function aggregation $z$</li>
<li>sigmoid function activation $a$</li>
<li>cost function (error) calculation $E$</li>
<li>derivative of the error w.r.t. the weights $w$ and bias $b$ in the $(L)$ layer</li>
<li>derivative of the error w.r.t. the weights $w$ and bias $b$ in the $(L-1)$ layer</li>
<li>weight and bias update for the $(L)$ layer</li>
<li>weight and bias update for the $(L-1)$ layer</li>
</ol>
<p>Those operations over the entire dataset comprise a single "iteration" or "epoch". Generally, we need to perform multiple repetitions of that sequence to train the weights. That loop can't be avoided unfortunately and will be part of the "fit" function.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Initialize-training-parameters">Initialize training parameters<a class="anchor-link" href="#Initialize-training-parameters"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">init_parameters</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_output</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;generate initial parameters sampled from an uniform distribution</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        n_features (int): number of feature vectors </span>
<span class="sd">        n_neurons (int): number of neurons in hidden layer</span>
<span class="sd">        n_output (int): number of output neurons</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        parameters dictionary:</span>
<span class="sd">            W1: weight matrix, shape = [n_features, n_neurons]</span>
<span class="sd">            b1: bias vector, shape = [1, n_neurons]</span>
<span class="sd">            W2: weight matrix, shape = [n_neurons, n_output]</span>
<span class="sd">            b2: bias vector, shape = [1, n_output]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="c1"># for reproducibility</span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span><span class="n">n_neurons</span><span class="p">))</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_neurons</span><span class="p">))</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span><span class="n">n_output</span><span class="p">))</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_output</span><span class="p">))</span>
    
    <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;W1&quot;</span><span class="p">:</span> <span class="n">W1</span><span class="p">,</span>
                  <span class="s2">&quot;b1&quot;</span><span class="p">:</span> <span class="n">b1</span><span class="p">,</span>
                  <span class="s2">&quot;W2&quot;</span><span class="p">:</span> <span class="n">W2</span><span class="p">,</span>
                  <span class="s2">&quot;b2&quot;</span><span class="p">:</span> <span class="n">b2</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">parameters</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Backpropagation is very sensitive to the initialization of parameters</strong>. For instance, in the process of writing this tutorial I learned that this particular network has a hard time finding a solution if I sample the weights from a normal distribution with mean = 0 and standard deviation = 0.01, but it does much better sampling from a uniform distribution. In any case, it is common practice to initialize the values for the weights and biases to some small values.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compute-$z$:-linear-function">Compute $z$: linear function<a class="anchor-link" href="#Compute-$z$:-linear-function"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">linear_function</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;computes net input as dot product</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        W (ndarray): weight matrix</span>
<span class="sd">        X (ndarray): matrix of features</span>
<span class="sd">        b (ndarray): vector of biases</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        Z (ndarray): weighted sum of features</span>
<span class="sd">        &quot;&quot;&quot;</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">W</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compute-$a$:-sigmoid-activation-function">Compute $a$: sigmoid activation function<a class="anchor-link" href="#Compute-$a$:-sigmoid-activation-function"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid_function</span><span class="p">(</span><span class="n">Z</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;computes sigmoid activation element wise</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        Z (ndarray): weighted sum of features</span>
<span class="sd">    </span>
<span class="sd">    Returns: </span>
<span class="sd">        S (ndarray): neuron activation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Z</span><span class="p">))</span> 
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compute-cost-(error)-function-$E$">Compute cost (error) function $E$<a class="anchor-link" href="#Compute-cost-(error)-function-$E$"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cost_function</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;computes squared error</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        A (ndarray): neuron activation</span>
<span class="sd">        y (ndarray): vector of expected values</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        E (float): total squared error&quot;&quot;&quot;</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">A</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span><span class="o">/</span><span class="mi">2</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compute-predictions-$\hat{y}$-with-learned-parameters">Compute predictions $\hat{y}$ with learned parameters<a class="anchor-link" href="#Compute-predictions-$\hat{y}$-with-learned-parameters"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;computes predictions with learned parameters</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        X (ndarray): matrix of features</span>
<span class="sd">        W1 (ndarray): weight matrix for the first layer</span>
<span class="sd">        W2 (ndarray): weight matrix for the second layer</span>
<span class="sd">        b1 (ndarray): bias vector for the first layer</span>
<span class="sd">        b2 (ndarray): bias vector for the second layer</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        d (ndarray): vector of predicted values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">Z1</span> <span class="o">=</span> <span class="n">linear_function</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">b1</span><span class="p">)</span>
    <span class="n">S1</span> <span class="o">=</span> <span class="n">sigmoid_function</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
    <span class="n">Z2</span> <span class="o">=</span> <span class="n">linear_function</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">S1</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
    <span class="n">S2</span> <span class="o">=</span> <span class="n">sigmoid_function</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">S2</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since I plan to solve a binary classification problem, we define a threshold function that takes the output of the last sigmoid activation function and returns a 0 or a 1 for each class.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Backpropagation-and-training-loop">Backpropagation and training loop<a class="anchor-link" href="#Backpropagation-and-training-loop"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_output</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Multi-layer perceptron trained with backpropagation</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        X (ndarray): matrix of features</span>
<span class="sd">        y (ndarray): vector of expected values</span>
<span class="sd">        n_features (int): number of feature vectors </span>
<span class="sd">        n_neurons (int): number of neurons in hidden layer</span>
<span class="sd">        n_output (int): number of output neurons</span>
<span class="sd">        iterations (int): number of iterations over the training set</span>
<span class="sd">        eta (float): learning rate</span>
<span class="sd">        </span>
<span class="sd">    Returns: </span>
<span class="sd">        errors (list): list of errors over iterations</span>
<span class="sd">        param (dic): dictionary of learned parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1">## ~~ Initialize parameters ~~##</span>
    <span class="n">param</span> <span class="o">=</span> <span class="n">init_parameters</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span> 
                            <span class="n">n_neurons</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">,</span> 
                            <span class="n">n_output</span><span class="o">=</span><span class="n">n_output</span><span class="p">)</span>

    <span class="c1">## ~~ storage errors after each iteration ~~##</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        
        <span class="c1">##~~ Forward-propagation ~~##</span>
        
        <span class="n">Z1</span> <span class="o">=</span> <span class="n">linear_function</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="s1">&#39;W1&#39;</span><span class="p">],</span> <span class="n">X</span><span class="p">,</span> <span class="n">param</span><span class="p">[</span><span class="s1">&#39;b1&#39;</span><span class="p">])</span>
        <span class="n">S1</span> <span class="o">=</span> <span class="n">sigmoid_function</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
        <span class="n">Z2</span> <span class="o">=</span> <span class="n">linear_function</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="s1">&#39;W2&#39;</span><span class="p">],</span> <span class="n">S1</span><span class="p">,</span> <span class="n">param</span><span class="p">[</span><span class="s1">&#39;b2&#39;</span><span class="p">])</span>
        <span class="n">S2</span> <span class="o">=</span> <span class="n">sigmoid_function</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span>
        
        <span class="c1">##~~ Error computation ~~##</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">cost_function</span><span class="p">(</span><span class="n">S2</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
        
        <span class="c1">##~~ Backpropagation ~~##</span>
        
        <span class="c1"># update output weights</span>
        <span class="n">delta2</span> <span class="o">=</span> <span class="p">(</span><span class="n">S2</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">*</span> <span class="n">S2</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">S2</span><span class="p">)</span>
        <span class="n">W2_gradients</span> <span class="o">=</span> <span class="n">S1</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">delta2</span>
        <span class="n">param</span><span class="p">[</span><span class="s2">&quot;W2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="p">[</span><span class="s2">&quot;W2&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">W2_gradients</span> <span class="o">*</span> <span class="n">eta</span>

        <span class="c1"># update output bias</span>
        <span class="n">param</span><span class="p">[</span><span class="s2">&quot;b2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="p">[</span><span class="s2">&quot;b2&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">delta2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="n">eta</span>

        <span class="c1"># update hidden weights</span>
        <span class="n">delta1</span> <span class="o">=</span> <span class="p">(</span><span class="n">delta2</span> <span class="o">@</span> <span class="n">param</span><span class="p">[</span><span class="s2">&quot;W2&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="p">)</span><span class="o">*</span> <span class="n">S1</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">S1</span><span class="p">)</span>
        <span class="n">W1_gradients</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">delta1</span> 
        <span class="n">param</span><span class="p">[</span><span class="s2">&quot;W1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="p">[</span><span class="s2">&quot;W1&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">W1_gradients</span> <span class="o">*</span> <span class="n">eta</span>

        <span class="c1"># update hidden bias</span>
        <span class="n">param</span><span class="p">[</span><span class="s2">&quot;b1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="p">[</span><span class="s2">&quot;b1&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">delta1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="n">eta</span>
        
    <span class="k">return</span> <span class="n">errors</span><span class="p">,</span> <span class="n">param</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here is where we put everything together to train the network. The first part of the function initializes the parameters by calling the <code>init_parameters</code> function. The loop (<code>for _ in range(iterations)</code>) in the second part of the function is where all the action happens:</p>
<ol>
<li>the <strong>Forward-propagation</strong> section chains the linear and sigmoid functions to compute the network output.</li>
<li>the <strong>Error computation</strong> section computes the cost function value after each iteration.</li>
<li>the <strong>Backpropagation</strong> section does two things:<ul>
<li>computes the gradients for the weights and biases in the $(L)$ and $(L-1)$ layers</li>
<li>update the weights and biases in the $(L)$ and $(L-1)$ layers</li>
</ul>
</li>
<li>the <code>fit</code> function returns a list of the errors after each iteration and an updated dictionary with the learned weights and biases.</li>
</ol>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Application:-solving-the-XOR-problem">Application: solving the XOR problem<a class="anchor-link" href="#Application:-solving-the-XOR-problem"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you have read this and previous chapters, you should know by now that one of the problems that brought about the "demise" of the interest in neural network models was the infamous XOR (exclusive or) problem. This was just one example of a large class of problems that can't be solved with linear models as the perceptron and ADALINE. As an act of redemption for neural networks from this criticism, we will solve the XOR problem using our implementation of the multilayer-perceptron.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Generate-features-and-target">Generate features and target<a class="anchor-link" href="#Generate-features-and-target"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first is to generate the targets and features for the XOR problem. <strong>Table 1</strong> shows the matrix of values we need to generate, where $x_1$ and $x_2$ are the features and $y$ the expected output.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Table 1</strong>: Truth Table For XOR Function</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<table>
<thead><tr>
<th>$x_1$</th>
<th>$x_2$</th>
<th>$y$</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># expected values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># features</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Multilayer-perceptron-training">Multilayer perceptron training<a class="anchor-link" href="#Multilayer-perceptron-training"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will train the network by running 5,000 iterations with a learning rate of $\eta = 0.1$.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">errors</span><span class="p">,</span> <span class="n">param</span> <span class="o">=</span> <span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Multilayer-perceptron-predictions-and-error">Multilayer perceptron predictions and error<a class="anchor-link" href="#Multilayer-perceptron-predictions-and-error"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">param</span><span class="p">[</span><span class="s2">&quot;W1&quot;</span><span class="p">],</span> <span class="n">param</span><span class="p">[</span><span class="s2">&quot;W2&quot;</span><span class="p">],</span> <span class="n">param</span><span class="p">[</span><span class="s2">&quot;b1&quot;</span><span class="p">],</span> <span class="n">param</span><span class="p">[</span><span class="s2">&quot;b2&quot;</span><span class="p">])</span>
<span class="n">num_correct_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_correct_predictions</span> <span class="o">/</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Multi-layer perceptron accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Multi-layer perceptron accuracy: 100.00%
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">altair</span> <span class="k">as</span> <span class="nn">alt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">alt</span><span class="o">.</span><span class="n">data_transformers</span><span class="o">.</span><span class="n">disable_max_rows</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>DataTransformerRegistry.enable(&#39;default&#39;)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;errors&quot;</span><span class="p">:</span><span class="n">errors</span><span class="p">,</span> <span class="s2">&quot;time-step&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">errors</span><span class="p">))})</span>

<span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">mark_line</span><span class="p">()</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;time-step&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;errors&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">properties</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Chart 2&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

<div id="altair-viz-59190db2309646e7a355d25ab03e340e"></div>
<script type="text/javascript">
  (function(spec, embedOpt){
    const outputDiv = document.getElementById("altair-viz-59190db2309646e7a355d25ab03e340e");
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm//vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm//vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm//vega-embed@6?noext",
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () => resolve(paths[lib]);
        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName("head")[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === "function") {
      displayChart(vegaEmbed);
    } else {
      loadScript("vega")
        .then(() => loadScript("vega-lite"))
        .then(() => loadScript("vega-embed"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 400, "continuousHeight": 300}}, "data": {"name": "data-bf9f27abf3b922139836e40e6f41caa1"}, "mark": "line", "encoding": {"x": {"type": "quantitative", "field": "time-step"}, "y": {"type": "quantitative", "field": "errors"}}, "title": "Chart 2", "$schema": "https://vega.github.io/schema/vega-lite/v4.0.2.json", "datasets": {"data-bf9f27abf3b922139836e40e6f41caa1": [{"errors": 0.17037699424952266, "time-step": 0}, {"errors": 0.16804892560495124, "time-step": 1}, {"errors": 0.16571393112397487, "time-step": 2}, {"errors": 0.16338264704264036, "time-step": 3}, {"errors": 0.1610662579543201, "time-step": 4}, {"errors": 0.15877627259708382, "time-step": 5}, {"errors": 0.1565242673859441, "time-step": 6}, {"errors": 0.1543216087576396, "time-step": 7}, {"errors": 0.15217916819896438, "time-step": 8}, {"errors": 0.15010704555098447, "time-step": 9}, {"errors": 0.14811431648219273, "time-step": 10}, {"errors": 0.14620881875104452, "time-step": 11}, {"errors": 0.14439698911305815, "time-step": 12}, {"errors": 0.1426837587838099, "time-step": 13}, {"errors": 0.14107251074295576, "time-step": 14}, {"errors": 0.13956509744306175, "time-step": 15}, {"errors": 0.13816191324024166, "time-step": 16}, {"errors": 0.13686201254529293, "time-step": 17}, {"errors": 0.135663262576654, "time-step": 18}, {"errors": 0.13456251874975783, "time-step": 19}, {"errors": 0.13355581104925907, "time-step": 20}, {"errors": 0.13263853095890948, "time-step": 21}, {"errors": 0.13180561036029864, "time-step": 22}, {"errors": 0.131051685942878, "time-step": 23}, {"errors": 0.13037124482129453, "time-step": 24}, {"errors": 0.12975874902740797, "time-step": 25}, {"errors": 0.12920873820454393, "time-step": 26}, {"errors": 0.1287159111213709, "time-step": 27}, {"errors": 0.1282751875384727, "time-step": 28}, {"errors": 0.12788175253641715, "time-step": 29}, {"errors": 0.12753108570555177, "time-step": 30}, {"errors": 0.12721897766859502, "time-step": 31}, {"errors": 0.12694153631952754, "time-step": 32}, {"errors": 0.12669518497121812, "time-step": 33}, {"errors": 0.12647665435446334, "time-step": 34}, {"errors": 0.12628297013687137, "time-step": 35}, {"errors": 0.12611143735561572, "time-step": 36}, {"errors": 0.12595962289952356, "time-step": 37}, {"errors": 0.1258253369426388, "time-step": 38}, {"errors": 0.12570661402779357, "time-step": 39}, {"errors": 0.125601694325875, "time-step": 40}, {"errors": 0.1255090054531816, "time-step": 41}, {"errors": 0.1254271451129971, "time-step": 42}, {"errors": 0.12535486473506974, "time-step": 43}, {"errors": 0.12529105421466827, "time-step": 44}, {"errors": 0.12523472779797296, "time-step": 45}, {"errors": 0.12518501111968122, "time-step": 46}, {"errors": 0.12514112936915028, "time-step": 47}, {"errors": 0.12510239654081265, "time-step": 48}, {"errors": 0.12506820571101648, "time-step": 49}, {"errors": 0.12503802027522573, "time-step": 50}, {"errors": 0.12501136607533925, "time-step": 51}, {"errors": 0.12498782434569705, "time-step": 52}, {"errors": 0.12496702540728763, "time-step": 53}, {"errors": 0.12494864304210929, "time-step": 54}, {"errors": 0.1249323894830601, "time-step": 55}, {"errors": 0.12491801095875943, "time-step": 56}, {"errors": 0.12490528373705131, "time-step": 57}, {"errors": 0.12489401061540381, "time-step": 58}, {"errors": 0.12488401781084196, "time-step": 59}, {"errors": 0.1248751522063403, "time-step": 60}, {"errors": 0.12486727891468291, "time-step": 61}, {"errors": 0.12486027912462828, "time-step": 62}, {"errors": 0.12485404819777907, "time-step": 63}, {"errors": 0.12484849398783454, "time-step": 64}, {"errors": 0.12484353535690637, "time-step": 65}, {"errors": 0.12483910086630588, "time-step": 66}, {"errors": 0.12483512762168453, "time-step": 67}, {"errors": 0.1248315602546366, "time-step": 68}, {"errors": 0.12482835002487688, "time-step": 69}, {"errors": 0.12482545402890177, "time-step": 70}, {"errors": 0.12482283450264597, "time-step": 71}, {"errors": 0.12482045820708018, "time-step": 72}, {"errors": 0.1248182958869694, "time-step": 73}, {"errors": 0.12481632179414603, "time-step": 74}, {"errors": 0.12481451326765822, "time-step": 75}, {"errors": 0.12481285036404699, "time-step": 76}, {"errors": 0.12481131553179806, "time-step": 77}, {"errors": 0.12480989332471248, "time-step": 78}, {"errors": 0.12480857014956259, "time-step": 79}, {"errors": 0.12480733404394578, "time-step": 80}, {"errors": 0.12480617448073301, "time-step": 81}, {"errors": 0.12480508219593676, "time-step": 82}, {"errors": 0.12480404903720019, "time-step": 83}, {"errors": 0.12480306783044212, "time-step": 84}, {"errors": 0.12480213226248582, "time-step": 85}, {"errors": 0.12480123677775917, "time-step": 86}, {"errors": 0.12480037648738115, "time-step": 87}, {"errors": 0.12479954708915163, "time-step": 88}, {"errors": 0.12479874479713798, "time-step": 89}, {"errors": 0.12479796627970868, "time-step": 90}, {"errors": 0.12479720860500113, "time-step": 91}, {"errors": 0.12479646919293283, "time-step": 92}, {"errors": 0.12479574577297092, "time-step": 93}, {"errors": 0.12479503634697006, "time-step": 94}, {"errors": 0.12479433915646981, "time-step": 95}, {"errors": 0.12479365265391765, "time-step": 96}, {"errors": 0.12479297547734565, "time-step": 97}, {"errors": 0.12479230642808714, "time-step": 98}, {"errors": 0.12479164445116839, "time-step": 99}, {"errors": 0.12479098861805385, "time-step": 100}, {"errors": 0.12479033811146312, "time-step": 101}, {"errors": 0.12478969221201064, "time-step": 102}, {"errors": 0.12478905028644971, "time-step": 103}, {"errors": 0.12478841177732727, "time-step": 104}, {"errors": 0.1247877761938817, "time-step": 105}, {"errors": 0.12478714310403269, "time-step": 106}, {"errors": 0.12478651212733347, "time-step": 107}, {"errors": 0.12478588292876899, "time-step": 108}, {"errors": 0.12478525521329914, "time-step": 109}, {"errors": 0.12478462872105672, "time-step": 110}, {"errors": 0.1247840032231226, "time-step": 111}, {"errors": 0.12478337851780788, "time-step": 112}, {"errors": 0.12478275442738253, "time-step": 113}, {"errors": 0.12478213079519716, "time-step": 114}, {"errors": 0.12478150748315013, "time-step": 115}, {"errors": 0.12478088436945906, "time-step": 116}, {"errors": 0.12478026134669988, "time-step": 117}, {"errors": 0.12477963832008138, "time-step": 118}, {"errors": 0.12477901520592714, "time-step": 119}, {"errors": 0.12477839193033967, "time-step": 120}, {"errors": 0.12477776842802496, "time-step": 121}, {"errors": 0.1247771446412583, "time-step": 122}, {"errors": 0.12477652051897434, "time-step": 123}, {"errors": 0.1247758960159664, "time-step": 124}, {"errors": 0.12477527109218191, "time-step": 125}, {"errors": 0.12477464571210263, "time-step": 126}, {"errors": 0.12477401984419925, "time-step": 127}, {"errors": 0.12477339346045138, "time-step": 128}, {"errors": 0.12477276653592548, "time-step": 129}, {"errors": 0.1247721390484033, "time-step": 130}, {"errors": 0.12477151097805492, "time-step": 131}, {"errors": 0.1247708823071513, "time-step": 132}, {"errors": 0.12477025301981115, "time-step": 133}, {"errors": 0.12476962310177833, "time-step": 134}, {"errors": 0.12476899254022594, "time-step": 135}, {"errors": 0.1247683613235839, "time-step": 136}, {"errors": 0.12476772944138759, "time-step": 137}, {"errors": 0.12476709688414411, "time-step": 138}, {"errors": 0.12476646364321507, "time-step": 139}, {"errors": 0.12476582971071333, "time-step": 140}, {"errors": 0.12476519507941201, "time-step": 141}, {"errors": 0.12476455974266487, "time-step": 142}, {"errors": 0.1247639236943355, "time-step": 143}, {"errors": 0.1247632869287359, "time-step": 144}, {"errors": 0.12476264944057175, "time-step": 145}, {"errors": 0.12476201122489476, "time-step": 146}, {"errors": 0.12476137227706025, "time-step": 147}, {"errors": 0.12476073259269024, "time-step": 148}, {"errors": 0.12476009216764103, "time-step": 149}, {"errors": 0.12475945099797411, "time-step": 150}, {"errors": 0.12475880907993124, "time-step": 151}, {"errors": 0.12475816640991215, "time-step": 152}, {"errors": 0.12475752298445497, "time-step": 153}, {"errors": 0.12475687880021905, "time-step": 154}, {"errors": 0.1247562338539699, "time-step": 155}, {"errors": 0.12475558814256588, "time-step": 156}, {"errors": 0.12475494166294643, "time-step": 157}, {"errors": 0.12475429441212191, "time-step": 158}, {"errors": 0.12475364638716444, "time-step": 159}, {"errors": 0.12475299758519993, "time-step": 160}, {"errors": 0.12475234800340114, "time-step": 161}, {"errors": 0.12475169763898157, "time-step": 162}, {"errors": 0.12475104648918978, "time-step": 163}, {"errors": 0.12475039455130497, "time-step": 164}, {"errors": 0.12474974182263254, "time-step": 165}, {"errors": 0.12474908830050044, "time-step": 166}, {"errors": 0.1247484339822561, "time-step": 167}, {"errors": 0.12474777886526325, "time-step": 168}, {"errors": 0.12474712294689963, "time-step": 169}, {"errors": 0.12474646622455492, "time-step": 170}, {"errors": 0.12474580869562829, "time-step": 171}, {"errors": 0.12474515035752733, "time-step": 172}, {"errors": 0.12474449120766598, "time-step": 173}, {"errors": 0.12474383124346361, "time-step": 174}, {"errors": 0.12474317046234354, "time-step": 175}, {"errors": 0.1247425088617323, "time-step": 176}, {"errors": 0.12474184643905854, "time-step": 177}, {"errors": 0.12474118319175224, "time-step": 178}, {"errors": 0.1247405191172441, "time-step": 179}, {"errors": 0.12473985421296485, "time-step": 180}, {"errors": 0.1247391884763447, "time-step": 181}, {"errors": 0.124738521904813, "time-step": 182}, {"errors": 0.12473785449579752, "time-step": 183}, {"errors": 0.12473718624672449, "time-step": 184}, {"errors": 0.12473651715501786, "time-step": 185}, {"errors": 0.12473584721809922, "time-step": 186}, {"errors": 0.12473517643338758, "time-step": 187}, {"errors": 0.12473450479829909, "time-step": 188}, {"errors": 0.1247338323102467, "time-step": 189}, {"errors": 0.12473315896664022, "time-step": 190}, {"errors": 0.12473248476488609, "time-step": 191}, {"errors": 0.12473180970238706, "time-step": 192}, {"errors": 0.12473113377654227, "time-step": 193}, {"errors": 0.1247304569847471, "time-step": 194}, {"errors": 0.12472977932439301, "time-step": 195}, {"errors": 0.1247291007928675, "time-step": 196}, {"errors": 0.12472842138755408, "time-step": 197}, {"errors": 0.12472774110583196, "time-step": 198}, {"errors": 0.12472705994507637, "time-step": 199}, {"errors": 0.12472637790265814, "time-step": 200}, {"errors": 0.1247256949759439, "time-step": 201}, {"errors": 0.12472501116229584, "time-step": 202}, {"errors": 0.12472432645907186, "time-step": 203}, {"errors": 0.12472364086362539, "time-step": 204}, {"errors": 0.12472295437330536, "time-step": 205}, {"errors": 0.12472226698545619, "time-step": 206}, {"errors": 0.12472157869741789, "time-step": 207}, {"errors": 0.12472088950652575, "time-step": 208}, {"errors": 0.12472019941011059, "time-step": 209}, {"errors": 0.12471950840549856, "time-step": 210}, {"errors": 0.12471881649001118, "time-step": 211}, {"errors": 0.12471812366096532, "time-step": 212}, {"errors": 0.12471742991567318, "time-step": 213}, {"errors": 0.1247167352514422, "time-step": 214}, {"errors": 0.1247160396655752, "time-step": 215}, {"errors": 0.12471534315537008, "time-step": 216}, {"errors": 0.12471464571812024, "time-step": 217}, {"errors": 0.12471394735111407, "time-step": 218}, {"errors": 0.12471324805163522, "time-step": 219}, {"errors": 0.12471254781696263, "time-step": 220}, {"errors": 0.12471184664437027, "time-step": 221}, {"errors": 0.12471114453112736, "time-step": 222}, {"errors": 0.1247104414744982, "time-step": 223}, {"errors": 0.12470973747174224, "time-step": 224}, {"errors": 0.12470903252011403, "time-step": 225}, {"errors": 0.12470832661686312, "time-step": 226}, {"errors": 0.12470761975923433, "time-step": 227}, {"errors": 0.12470691194446733, "time-step": 228}, {"errors": 0.12470620316979696, "time-step": 229}, {"errors": 0.12470549343245302, "time-step": 230}, {"errors": 0.12470478272966037, "time-step": 231}, {"errors": 0.12470407105863882, "time-step": 232}, {"errors": 0.12470335841660318, "time-step": 233}, {"errors": 0.12470264480076318, "time-step": 234}, {"errors": 0.1247019302083236, "time-step": 235}, {"errors": 0.12470121463648402, "time-step": 236}, {"errors": 0.1247004980824391, "time-step": 237}, {"errors": 0.12469978054337824, "time-step": 238}, {"errors": 0.1246990620164858, "time-step": 239}, {"errors": 0.12469834249894106, "time-step": 240}, {"errors": 0.12469762198791808, "time-step": 241}, {"errors": 0.12469690048058577, "time-step": 242}, {"errors": 0.1246961779741079, "time-step": 243}, {"errors": 0.12469545446564304, "time-step": 244}, {"errors": 0.12469472995234454, "time-step": 245}, {"errors": 0.12469400443136056, "time-step": 246}, {"errors": 0.12469327789983398, "time-step": 247}, {"errors": 0.12469255035490244, "time-step": 248}, {"errors": 0.12469182179369839, "time-step": 249}, {"errors": 0.12469109221334887, "time-step": 250}, {"errors": 0.12469036161097574, "time-step": 251}, {"errors": 0.12468962998369545, "time-step": 252}, {"errors": 0.12468889732861918, "time-step": 253}, {"errors": 0.12468816364285276, "time-step": 254}, {"errors": 0.12468742892349664, "time-step": 255}, {"errors": 0.12468669316764591, "time-step": 256}, {"errors": 0.12468595637239026, "time-step": 257}, {"errors": 0.12468521853481399, "time-step": 258}, {"errors": 0.12468447965199593, "time-step": 259}, {"errors": 0.12468373972100955, "time-step": 260}, {"errors": 0.12468299873892277, "time-step": 261}, {"errors": 0.1246822567027981, "time-step": 262}, {"errors": 0.12468151360969258, "time-step": 263}, {"errors": 0.12468076945665768, "time-step": 264}, {"errors": 0.12468002424073946, "time-step": 265}, {"errors": 0.12467927795897826, "time-step": 266}, {"errors": 0.12467853060840908, "time-step": 267}, {"errors": 0.12467778218606121, "time-step": 268}, {"errors": 0.12467703268895844, "time-step": 269}, {"errors": 0.1246762821141189, "time-step": 270}, {"errors": 0.12467553045855512, "time-step": 271}, {"errors": 0.12467477771927403, "time-step": 272}, {"errors": 0.12467402389327689, "time-step": 273}, {"errors": 0.12467326897755929, "time-step": 274}, {"errors": 0.12467251296911114, "time-step": 275}, {"errors": 0.12467175586491666, "time-step": 276}, {"errors": 0.12467099766195439, "time-step": 277}, {"errors": 0.12467023835719705, "time-step": 278}, {"errors": 0.12466947794761171, "time-step": 279}, {"errors": 0.12466871643015967, "time-step": 280}, {"errors": 0.12466795380179635, "time-step": 281}, {"errors": 0.12466719005947147, "time-step": 282}, {"errors": 0.12466642520012894, "time-step": 283}, {"errors": 0.1246656592207068, "time-step": 284}, {"errors": 0.12466489211813722, "time-step": 285}, {"errors": 0.12466412388934661, "time-step": 286}, {"errors": 0.1246633545312554, "time-step": 287}, {"errors": 0.12466258404077818, "time-step": 288}, {"errors": 0.12466181241482362, "time-step": 289}, {"errors": 0.1246610396502944, "time-step": 290}, {"errors": 0.12466026574408742, "time-step": 291}, {"errors": 0.12465949069309337, "time-step": 292}, {"errors": 0.1246587144941972, "time-step": 293}, {"errors": 0.1246579371442777, "time-step": 294}, {"errors": 0.12465715864020771, "time-step": 295}, {"errors": 0.12465637897885407, "time-step": 296}, {"errors": 0.12465559815707752, "time-step": 297}, {"errors": 0.12465481617173278, "time-step": 298}, {"errors": 0.12465403301966842, "time-step": 299}, {"errors": 0.12465324869772701, "time-step": 300}, {"errors": 0.1246524632027449, "time-step": 301}, {"errors": 0.12465167653155237, "time-step": 302}, {"errors": 0.12465088868097363, "time-step": 303}, {"errors": 0.12465009964782647, "time-step": 304}, {"errors": 0.12464930942892281, "time-step": 305}, {"errors": 0.12464851802106812, "time-step": 306}, {"errors": 0.12464772542106181, "time-step": 307}, {"errors": 0.12464693162569693, "time-step": 308}, {"errors": 0.1246461366317604, "time-step": 309}, {"errors": 0.12464534043603279, "time-step": 310}, {"errors": 0.1246445430352884, "time-step": 311}, {"errors": 0.12464374442629522, "time-step": 312}, {"errors": 0.1246429446058149, "time-step": 313}, {"errors": 0.12464214357060283, "time-step": 314}, {"errors": 0.12464134131740792, "time-step": 315}, {"errors": 0.1246405378429728, "time-step": 316}, {"errors": 0.12463973314403368, "time-step": 317}, {"errors": 0.12463892721732032, "time-step": 318}, {"errors": 0.12463812005955617, "time-step": 319}, {"errors": 0.12463731166745803, "time-step": 320}, {"errors": 0.12463650203773641, "time-step": 321}, {"errors": 0.12463569116709532, "time-step": 322}, {"errors": 0.12463487905223213, "time-step": 323}, {"errors": 0.12463406568983793, "time-step": 324}, {"errors": 0.12463325107659703, "time-step": 325}, {"errors": 0.1246324352091873, "time-step": 326}, {"errors": 0.12463161808428008, "time-step": 327}, {"errors": 0.12463079969854007, "time-step": 328}, {"errors": 0.12462998004862536, "time-step": 329}, {"errors": 0.12462915913118736, "time-step": 330}, {"errors": 0.12462833694287101, "time-step": 331}, {"errors": 0.1246275134803144, "time-step": 332}, {"errors": 0.124626688740149, "time-step": 333}, {"errors": 0.12462586271899967, "time-step": 334}, {"errors": 0.12462503541348444, "time-step": 335}, {"errors": 0.12462420682021463, "time-step": 336}, {"errors": 0.12462337693579484, "time-step": 337}, {"errors": 0.12462254575682293, "time-step": 338}, {"errors": 0.12462171327988983, "time-step": 339}, {"errors": 0.12462087950157982, "time-step": 340}, {"errors": 0.12462004441847027, "time-step": 341}, {"errors": 0.12461920802713172, "time-step": 342}, {"errors": 0.1246183703241279, "time-step": 343}, {"errors": 0.12461753130601555, "time-step": 344}, {"errors": 0.12461669096934466, "time-step": 345}, {"errors": 0.12461584931065806, "time-step": 346}, {"errors": 0.12461500632649192, "time-step": 347}, {"errors": 0.12461416201337527, "time-step": 348}, {"errors": 0.12461331636783027, "time-step": 349}, {"errors": 0.12461246938637201, "time-step": 350}, {"errors": 0.12461162106550856, "time-step": 351}, {"errors": 0.1246107714017411, "time-step": 352}, {"errors": 0.12460992039156356, "time-step": 353}, {"errors": 0.12460906803146293, "time-step": 354}, {"errors": 0.1246082143179191, "time-step": 355}, {"errors": 0.12460735924740482, "time-step": 356}, {"errors": 0.12460650281638573, "time-step": 357}, {"errors": 0.12460564502132031, "time-step": 358}, {"errors": 0.12460478585865996, "time-step": 359}, {"errors": 0.1246039253248487, "time-step": 360}, {"errors": 0.12460306341632359, "time-step": 361}, {"errors": 0.12460220012951431, "time-step": 362}, {"errors": 0.12460133546084337, "time-step": 363}, {"errors": 0.12460046940672602, "time-step": 364}, {"errors": 0.12459960196357012, "time-step": 365}, {"errors": 0.12459873312777643, "time-step": 366}, {"errors": 0.12459786289573818, "time-step": 367}, {"errors": 0.12459699126384147, "time-step": 368}, {"errors": 0.1245961182284649, "time-step": 369}, {"errors": 0.12459524378597972, "time-step": 370}, {"errors": 0.12459436793274983, "time-step": 371}, {"errors": 0.12459349066513165, "time-step": 372}, {"errors": 0.1245926119794743, "time-step": 373}, {"errors": 0.12459173187211925, "time-step": 374}, {"errors": 0.12459085033940066, "time-step": 375}, {"errors": 0.12458996737764516, "time-step": 376}, {"errors": 0.12458908298317176, "time-step": 377}, {"errors": 0.12458819715229213, "time-step": 378}, {"errors": 0.12458730988131023, "time-step": 379}, {"errors": 0.12458642116652249, "time-step": 380}, {"errors": 0.12458553100421779, "time-step": 381}, {"errors": 0.1245846393906774, "time-step": 382}, {"errors": 0.12458374632217488, "time-step": 383}, {"errors": 0.12458285179497625, "time-step": 384}, {"errors": 0.12458195580533973, "time-step": 385}, {"errors": 0.12458105834951595, "time-step": 386}, {"errors": 0.12458015942374785, "time-step": 387}, {"errors": 0.1245792590242705, "time-step": 388}, {"errors": 0.12457835714731141, "time-step": 389}, {"errors": 0.12457745378909016, "time-step": 390}, {"errors": 0.12457654894581861, "time-step": 391}, {"errors": 0.1245756426137008, "time-step": 392}, {"errors": 0.12457473478893293, "time-step": 393}, {"errors": 0.1245738254677034, "time-step": 394}, {"errors": 0.1245729146461926, "time-step": 395}, {"errors": 0.12457200232057325, "time-step": 396}, {"errors": 0.1245710884870099, "time-step": 397}, {"errors": 0.12457017314165941, "time-step": 398}, {"errors": 0.12456925628067048, "time-step": 399}, {"errors": 0.12456833790018398, "time-step": 400}, {"errors": 0.12456741799633275, "time-step": 401}, {"errors": 0.12456649656524152, "time-step": 402}, {"errors": 0.1245655736030272, "time-step": 403}, {"errors": 0.12456464910579837, "time-step": 404}, {"errors": 0.12456372306965577, "time-step": 405}, {"errors": 0.12456279549069188, "time-step": 406}, {"errors": 0.12456186636499118, "time-step": 407}, {"errors": 0.12456093568862993, "time-step": 408}, {"errors": 0.12456000345767625, "time-step": 409}, {"errors": 0.12455906966819008, "time-step": 410}, {"errors": 0.1245581343162232, "time-step": 411}, {"errors": 0.12455719739781912, "time-step": 412}, {"errors": 0.12455625890901309, "time-step": 413}, {"errors": 0.12455531884583214, "time-step": 414}, {"errors": 0.12455437720429503, "time-step": 415}, {"errors": 0.12455343398041216, "time-step": 416}, {"errors": 0.12455248917018558, "time-step": 417}, {"errors": 0.12455154276960914, "time-step": 418}, {"errors": 0.12455059477466808, "time-step": 419}, {"errors": 0.12454964518133951, "time-step": 420}, {"errors": 0.12454869398559192, "time-step": 421}, {"errors": 0.12454774118338546, "time-step": 422}, {"errors": 0.12454678677067182, "time-step": 423}, {"errors": 0.12454583074339425, "time-step": 424}, {"errors": 0.12454487309748738, "time-step": 425}, {"errors": 0.12454391382887742, "time-step": 426}, {"errors": 0.12454295293348205, "time-step": 427}, {"errors": 0.12454199040721031, "time-step": 428}, {"errors": 0.12454102624596274, "time-step": 429}, {"errors": 0.12454006044563119, "time-step": 430}, {"errors": 0.12453909300209892, "time-step": 431}, {"errors": 0.12453812391124061, "time-step": 432}, {"errors": 0.12453715316892214, "time-step": 433}, {"errors": 0.12453618077100079, "time-step": 434}, {"errors": 0.1245352067133251, "time-step": 435}, {"errors": 0.12453423099173483, "time-step": 436}, {"errors": 0.12453325360206105, "time-step": 437}, {"errors": 0.12453227454012605, "time-step": 438}, {"errors": 0.12453129380174327, "time-step": 439}, {"errors": 0.12453031138271733, "time-step": 440}, {"errors": 0.12452932727884403, "time-step": 441}, {"errors": 0.12452834148591027, "time-step": 442}, {"errors": 0.12452735399969411, "time-step": 443}, {"errors": 0.12452636481596466, "time-step": 444}, {"errors": 0.12452537393048205, "time-step": 445}, {"errors": 0.1245243813389976, "time-step": 446}, {"errors": 0.12452338703725346, "time-step": 447}, {"errors": 0.12452239102098298, "time-step": 448}, {"errors": 0.12452139328591028, "time-step": 449}, {"errors": 0.12452039382775057, "time-step": 450}, {"errors": 0.12451939264220994, "time-step": 451}, {"errors": 0.12451838972498544, "time-step": 452}, {"errors": 0.12451738507176492, "time-step": 453}, {"errors": 0.12451637867822721, "time-step": 454}, {"errors": 0.12451537054004178, "time-step": 455}, {"errors": 0.1245143606528692, "time-step": 456}, {"errors": 0.12451334901236058, "time-step": 457}, {"errors": 0.12451233561415798, "time-step": 458}, {"errors": 0.12451132045389407, "time-step": 459}, {"errors": 0.12451030352719239, "time-step": 460}, {"errors": 0.12450928482966706, "time-step": 461}, {"errors": 0.12450826435692293, "time-step": 462}, {"errors": 0.12450724210455552, "time-step": 463}, {"errors": 0.12450621806815096, "time-step": 464}, {"errors": 0.12450519224328604, "time-step": 465}, {"errors": 0.1245041646255281, "time-step": 466}, {"errors": 0.12450313521043506, "time-step": 467}, {"errors": 0.12450210399355532, "time-step": 468}, {"errors": 0.12450107097042791, "time-step": 469}, {"errors": 0.12450003613658228, "time-step": 470}, {"errors": 0.1244989994875384, "time-step": 471}, {"errors": 0.12449796101880664, "time-step": 472}, {"errors": 0.12449692072588783, "time-step": 473}, {"errors": 0.12449587860427322, "time-step": 474}, {"errors": 0.12449483464944443, "time-step": 475}, {"errors": 0.12449378885687337, "time-step": 476}, {"errors": 0.1244927412220224, "time-step": 477}, {"errors": 0.12449169174034408, "time-step": 478}, {"errors": 0.12449064040728129, "time-step": 479}, {"errors": 0.12448958721826725, "time-step": 480}, {"errors": 0.12448853216872531, "time-step": 481}, {"errors": 0.12448747525406909, "time-step": 482}, {"errors": 0.12448641646970243, "time-step": 483}, {"errors": 0.12448535581101924, "time-step": 484}, {"errors": 0.12448429327340366, "time-step": 485}, {"errors": 0.12448322885222995, "time-step": 486}, {"errors": 0.12448216254286237, "time-step": 487}, {"errors": 0.12448109434065541, "time-step": 488}, {"errors": 0.12448002424095342, "time-step": 489}, {"errors": 0.12447895223909099, "time-step": 490}, {"errors": 0.1244778783303925, "time-step": 491}, {"errors": 0.12447680251017246, "time-step": 492}, {"errors": 0.12447572477373524, "time-step": 493}, {"errors": 0.12447464511637518, "time-step": 494}, {"errors": 0.12447356353337649, "time-step": 495}, {"errors": 0.12447248002001336, "time-step": 496}, {"errors": 0.12447139457154965, "time-step": 497}, {"errors": 0.12447030718323923, "time-step": 498}, {"errors": 0.12446921785032572, "time-step": 499}, {"errors": 0.12446812656804243, "time-step": 500}, {"errors": 0.12446703333161255, "time-step": 501}, {"errors": 0.12446593813624893, "time-step": 502}, {"errors": 0.12446484097715416, "time-step": 503}, {"errors": 0.12446374184952053, "time-step": 504}, {"errors": 0.12446264074852995, "time-step": 505}, {"errors": 0.12446153766935397, "time-step": 506}, {"errors": 0.12446043260715378, "time-step": 507}, {"errors": 0.12445932555708011, "time-step": 508}, {"errors": 0.1244582165142733, "time-step": 509}, {"errors": 0.12445710547386316, "time-step": 510}, {"errors": 0.12445599243096903, "time-step": 511}, {"errors": 0.12445487738069982, "time-step": 512}, {"errors": 0.1244537603181538, "time-step": 513}, {"errors": 0.12445264123841869, "time-step": 514}, {"errors": 0.12445152013657165, "time-step": 515}, {"errors": 0.12445039700767922, "time-step": 516}, {"errors": 0.1244492718467973, "time-step": 517}, {"errors": 0.12444814464897105, "time-step": 518}, {"errors": 0.12444701540923511, "time-step": 519}, {"errors": 0.12444588412261318, "time-step": 520}, {"errors": 0.12444475078411843, "time-step": 521}, {"errors": 0.12444361538875312, "time-step": 522}, {"errors": 0.1244424779315088, "time-step": 523}, {"errors": 0.12444133840736611, "time-step": 524}, {"errors": 0.12444019681129499, "time-step": 525}, {"errors": 0.12443905313825433, "time-step": 526}, {"errors": 0.12443790738319231, "time-step": 527}, {"errors": 0.12443675954104608, "time-step": 528}, {"errors": 0.12443560960674184, "time-step": 529}, {"errors": 0.12443445757519486, "time-step": 530}, {"errors": 0.12443330344130941, "time-step": 531}, {"errors": 0.1244321471999787, "time-step": 532}, {"errors": 0.12443098884608494, "time-step": 533}, {"errors": 0.12442982837449926, "time-step": 534}, {"errors": 0.12442866578008158, "time-step": 535}, {"errors": 0.12442750105768087, "time-step": 536}, {"errors": 0.12442633420213486, "time-step": 537}, {"errors": 0.12442516520827004, "time-step": 538}, {"errors": 0.12442399407090182, "time-step": 539}, {"errors": 0.12442282078483427, "time-step": 540}, {"errors": 0.1244216453448603, "time-step": 541}, {"errors": 0.12442046774576145, "time-step": 542}, {"errors": 0.124419287982308, "time-step": 543}, {"errors": 0.12441810604925889, "time-step": 544}, {"errors": 0.12441692194136164, "time-step": 545}, {"errors": 0.12441573565335245, "time-step": 546}, {"errors": 0.1244145471799561, "time-step": 547}, {"errors": 0.12441335651588598, "time-step": 548}, {"errors": 0.12441216365584382, "time-step": 549}, {"errors": 0.12441096859452, "time-step": 550}, {"errors": 0.1244097713265934, "time-step": 551}, {"errors": 0.12440857184673126, "time-step": 552}, {"errors": 0.12440737014958939, "time-step": 553}, {"errors": 0.12440616622981182, "time-step": 554}, {"errors": 0.12440496008203103, "time-step": 555}, {"errors": 0.12440375170086784, "time-step": 556}, {"errors": 0.12440254108093148, "time-step": 557}, {"errors": 0.12440132821681929, "time-step": 558}, {"errors": 0.12440011310311704, "time-step": 559}, {"errors": 0.12439889573439859, "time-step": 560}, {"errors": 0.12439767610522617, "time-step": 561}, {"errors": 0.12439645421015011, "time-step": 562}, {"errors": 0.12439523004370878, "time-step": 563}, {"errors": 0.12439400360042893, "time-step": 564}, {"errors": 0.12439277487482517, "time-step": 565}, {"errors": 0.12439154386140033, "time-step": 566}, {"errors": 0.12439031055464528, "time-step": 567}, {"errors": 0.12438907494903882, "time-step": 568}, {"errors": 0.12438783703904785, "time-step": 569}, {"errors": 0.12438659681912709, "time-step": 570}, {"errors": 0.12438535428371934, "time-step": 571}, {"errors": 0.12438410942725525, "time-step": 572}, {"errors": 0.1243828622441534, "time-step": 573}, {"errors": 0.1243816127288201, "time-step": 574}, {"errors": 0.12438036087564959, "time-step": 575}, {"errors": 0.12437910667902394, "time-step": 576}, {"errors": 0.12437785013331286, "time-step": 577}, {"errors": 0.1243765912328739, "time-step": 578}, {"errors": 0.1243753299720523, "time-step": 579}, {"errors": 0.12437406634518107, "time-step": 580}, {"errors": 0.12437280034658066, "time-step": 581}, {"errors": 0.12437153197055939, "time-step": 582}, {"errors": 0.12437026121141304, "time-step": 583}, {"errors": 0.12436898806342502, "time-step": 584}, {"errors": 0.12436771252086626, "time-step": 585}, {"errors": 0.12436643457799522, "time-step": 586}, {"errors": 0.12436515422905792, "time-step": 587}, {"errors": 0.1243638714682877, "time-step": 588}, {"errors": 0.1243625862899054, "time-step": 589}, {"errors": 0.12436129868811935, "time-step": 590}, {"errors": 0.12436000865712513, "time-step": 591}, {"errors": 0.12435871619110574, "time-step": 592}, {"errors": 0.12435742128423144, "time-step": 593}, {"errors": 0.1243561239306599, "time-step": 594}, {"errors": 0.12435482412453588, "time-step": 595}, {"errors": 0.12435352185999154, "time-step": 596}, {"errors": 0.12435221713114616, "time-step": 597}, {"errors": 0.12435090993210622, "time-step": 598}, {"errors": 0.12434960025696529, "time-step": 599}, {"errors": 0.12434828809980422, "time-step": 600}, {"errors": 0.1243469734546907, "time-step": 601}, {"errors": 0.12434565631567975, "time-step": 602}, {"errors": 0.12434433667681317, "time-step": 603}, {"errors": 0.12434301453212002, "time-step": 604}, {"errors": 0.1243416898756161, "time-step": 605}, {"errors": 0.1243403627013043, "time-step": 606}, {"errors": 0.12433903300317442, "time-step": 607}, {"errors": 0.12433770077520306, "time-step": 608}, {"errors": 0.12433636601135375, "time-step": 609}, {"errors": 0.12433502870557686, "time-step": 610}, {"errors": 0.12433368885180945, "time-step": 611}, {"errors": 0.12433234644397556, "time-step": 612}, {"errors": 0.12433100147598575, "time-step": 613}, {"errors": 0.12432965394173737, "time-step": 614}, {"errors": 0.12432830383511453, "time-step": 615}, {"errors": 0.12432695114998785, "time-step": 616}, {"errors": 0.12432559588021477, "time-step": 617}, {"errors": 0.12432423801963907, "time-step": 618}, {"errors": 0.12432287756209134, "time-step": 619}, {"errors": 0.12432151450138854, "time-step": 620}, {"errors": 0.12432014883133415, "time-step": 621}, {"errors": 0.12431878054571824, "time-step": 622}, {"errors": 0.1243174096383172, "time-step": 623}, {"errors": 0.12431603610289388, "time-step": 624}, {"errors": 0.12431465993319751, "time-step": 625}, {"errors": 0.12431328112296369, "time-step": 626}, {"errors": 0.12431189966591438, "time-step": 627}, {"errors": 0.1243105155557577, "time-step": 628}, {"errors": 0.1243091287861882, "time-step": 629}, {"errors": 0.12430773935088657, "time-step": 630}, {"errors": 0.12430634724351966, "time-step": 631}, {"errors": 0.12430495245774065, "time-step": 632}, {"errors": 0.12430355498718876, "time-step": 633}, {"errors": 0.12430215482548926, "time-step": 634}, {"errors": 0.12430075196625362, "time-step": 635}, {"errors": 0.12429934640307935, "time-step": 636}, {"errors": 0.12429793812954992, "time-step": 637}, {"errors": 0.12429652713923478, "time-step": 638}, {"errors": 0.1242951134256895, "time-step": 639}, {"errors": 0.12429369698245535, "time-step": 640}, {"errors": 0.12429227780305968, "time-step": 641}, {"errors": 0.12429085588101563, "time-step": 642}, {"errors": 0.1242894312098222, "time-step": 643}, {"errors": 0.12428800378296415, "time-step": 644}, {"errors": 0.1242865735939121, "time-step": 645}, {"errors": 0.12428514063612232, "time-step": 646}, {"errors": 0.12428370490303696, "time-step": 647}, {"errors": 0.12428226638808362, "time-step": 648}, {"errors": 0.12428082508467572, "time-step": 649}, {"errors": 0.12427938098621227, "time-step": 650}, {"errors": 0.12427793408607785, "time-step": 651}, {"errors": 0.12427648437764258, "time-step": 652}, {"errors": 0.12427503185426217, "time-step": 653}, {"errors": 0.1242735765092778, "time-step": 654}, {"errors": 0.12427211833601604, "time-step": 655}, {"errors": 0.12427065732778902, "time-step": 656}, {"errors": 0.12426919347789422, "time-step": 657}, {"errors": 0.12426772677961447, "time-step": 658}, {"errors": 0.12426625722621795, "time-step": 659}, {"errors": 0.12426478481095818, "time-step": 660}, {"errors": 0.12426330952707393, "time-step": 661}, {"errors": 0.12426183136778918, "time-step": 662}, {"errors": 0.1242603503263132, "time-step": 663}, {"errors": 0.12425886639584037, "time-step": 664}, {"errors": 0.12425737956955032, "time-step": 665}, {"errors": 0.12425588984060772, "time-step": 666}, {"errors": 0.1242543972021623, "time-step": 667}, {"errors": 0.12425290164734892, "time-step": 668}, {"errors": 0.12425140316928743, "time-step": 669}, {"errors": 0.1242499017610826, "time-step": 670}, {"errors": 0.12424839741582433, "time-step": 671}, {"errors": 0.12424689012658734, "time-step": 672}, {"errors": 0.12424537988643114, "time-step": 673}, {"errors": 0.12424386668840035, "time-step": 674}, {"errors": 0.12424235052552418, "time-step": 675}, {"errors": 0.12424083139081687, "time-step": 676}, {"errors": 0.12423930927727718, "time-step": 677}, {"errors": 0.12423778417788875, "time-step": 678}, {"errors": 0.12423625608561992, "time-step": 679}, {"errors": 0.12423472499342367, "time-step": 680}, {"errors": 0.12423319089423762, "time-step": 681}, {"errors": 0.124231653780984, "time-step": 682}, {"errors": 0.12423011364656955, "time-step": 683}, {"errors": 0.12422857048388568, "time-step": 684}, {"errors": 0.1242270242858082, "time-step": 685}, {"errors": 0.1242254750451974, "time-step": 686}, {"errors": 0.12422392275489808, "time-step": 687}, {"errors": 0.12422236740773938, "time-step": 688}, {"errors": 0.12422080899653484, "time-step": 689}, {"errors": 0.12421924751408231, "time-step": 690}, {"errors": 0.12421768295316404, "time-step": 691}, {"errors": 0.12421611530654644, "time-step": 692}, {"errors": 0.12421454456698025, "time-step": 693}, {"errors": 0.12421297072720038, "time-step": 694}, {"errors": 0.1242113937799259, "time-step": 695}, {"errors": 0.1242098137178601, "time-step": 696}, {"errors": 0.1242082305336903, "time-step": 697}, {"errors": 0.12420664422008794, "time-step": 698}, {"errors": 0.12420505476970845, "time-step": 699}, {"errors": 0.12420346217519138, "time-step": 700}, {"errors": 0.12420186642916016, "time-step": 701}, {"errors": 0.12420026752422218, "time-step": 702}, {"errors": 0.12419866545296876, "time-step": 703}, {"errors": 0.12419706020797514, "time-step": 704}, {"errors": 0.12419545178180029, "time-step": 705}, {"errors": 0.12419384016698712, "time-step": 706}, {"errors": 0.1241922253560622, "time-step": 707}, {"errors": 0.12419060734153588, "time-step": 708}, {"errors": 0.12418898611590232, "time-step": 709}, {"errors": 0.12418736167163918, "time-step": 710}, {"errors": 0.1241857340012079, "time-step": 711}, {"errors": 0.12418410309705344, "time-step": 712}, {"errors": 0.12418246895160441, "time-step": 713}, {"errors": 0.12418083155727291, "time-step": 714}, {"errors": 0.1241791909064546, "time-step": 715}, {"errors": 0.12417754699152848, "time-step": 716}, {"errors": 0.12417589980485713, "time-step": 717}, {"errors": 0.12417424933878646, "time-step": 718}, {"errors": 0.12417259558564575, "time-step": 719}, {"errors": 0.12417093853774769, "time-step": 720}, {"errors": 0.12416927818738817, "time-step": 721}, {"errors": 0.12416761452684641, "time-step": 722}, {"errors": 0.12416594754838481, "time-step": 723}, {"errors": 0.12416427724424905, "time-step": 724}, {"errors": 0.12416260360666787, "time-step": 725}, {"errors": 0.1241609266278532, "time-step": 726}, {"errors": 0.1241592463000001, "time-step": 727}, {"errors": 0.12415756261528657, "time-step": 728}, {"errors": 0.12415587556587379, "time-step": 729}, {"errors": 0.12415418514390578, "time-step": 730}, {"errors": 0.1241524913415096, "time-step": 731}, {"errors": 0.12415079415079525, "time-step": 732}, {"errors": 0.1241490935638555, "time-step": 733}, {"errors": 0.12414738957276616, "time-step": 734}, {"errors": 0.12414568216958569, "time-step": 735}, {"errors": 0.12414397134635535, "time-step": 736}, {"errors": 0.12414225709509924, "time-step": 737}, {"errors": 0.12414053940782407, "time-step": 738}, {"errors": 0.12413881827651932, "time-step": 739}, {"errors": 0.12413709369315702, "time-step": 740}, {"errors": 0.12413536564969187, "time-step": 741}, {"errors": 0.12413363413806112, "time-step": 742}, {"errors": 0.1241318991501845, "time-step": 743}, {"errors": 0.12413016067796437, "time-step": 744}, {"errors": 0.12412841871328542, "time-step": 745}, {"errors": 0.12412667324801485, "time-step": 746}, {"errors": 0.12412492427400224, "time-step": 747}, {"errors": 0.12412317178307947, "time-step": 748}, {"errors": 0.12412141576706082, "time-step": 749}, {"errors": 0.12411965621774283, "time-step": 750}, {"errors": 0.1241178931269043, "time-step": 751}, {"errors": 0.12411612648630616, "time-step": 752}, {"errors": 0.12411435628769171, "time-step": 753}, {"errors": 0.12411258252278617, "time-step": 754}, {"errors": 0.12411080518329706, "time-step": 755}, {"errors": 0.12410902426091383, "time-step": 756}, {"errors": 0.12410723974730806, "time-step": 757}, {"errors": 0.12410545163413328, "time-step": 758}, {"errors": 0.12410365991302498, "time-step": 759}, {"errors": 0.12410186457560063, "time-step": 760}, {"errors": 0.12410006561345957, "time-step": 761}, {"errors": 0.12409826301818297, "time-step": 762}, {"errors": 0.12409645678133385, "time-step": 763}, {"errors": 0.12409464689445703, "time-step": 764}, {"errors": 0.12409283334907896, "time-step": 765}, {"errors": 0.12409101613670799, "time-step": 766}, {"errors": 0.124089195248834, "time-step": 767}, {"errors": 0.1240873706769286, "time-step": 768}, {"errors": 0.1240855424124449, "time-step": 769}, {"errors": 0.1240837104468177, "time-step": 770}, {"errors": 0.12408187477146322, "time-step": 771}, {"errors": 0.12408003537777924, "time-step": 772}, {"errors": 0.12407819225714498, "time-step": 773}, {"errors": 0.12407634540092108, "time-step": 774}, {"errors": 0.12407449480044955, "time-step": 775}, {"errors": 0.12407264044705374, "time-step": 776}, {"errors": 0.12407078233203836, "time-step": 777}, {"errors": 0.12406892044668937, "time-step": 778}, {"errors": 0.1240670547822739, "time-step": 779}, {"errors": 0.12406518533004036, "time-step": 780}, {"errors": 0.12406331208121832, "time-step": 781}, {"errors": 0.12406143502701844, "time-step": 782}, {"errors": 0.12405955415863247, "time-step": 783}, {"errors": 0.12405766946723323, "time-step": 784}, {"errors": 0.12405578094397457, "time-step": 785}, {"errors": 0.12405388857999121, "time-step": 786}, {"errors": 0.124051992366399, "time-step": 787}, {"errors": 0.1240500922942945, "time-step": 788}, {"errors": 0.12404818835475527, "time-step": 789}, {"errors": 0.12404628053883965, "time-step": 790}, {"errors": 0.12404436883758674, "time-step": 791}, {"errors": 0.12404245324201646, "time-step": 792}, {"errors": 0.12404053374312937, "time-step": 793}, {"errors": 0.12403861033190675, "time-step": 794}, {"errors": 0.1240366829993105, "time-step": 795}, {"errors": 0.1240347517362832, "time-step": 796}, {"errors": 0.12403281653374794, "time-step": 797}, {"errors": 0.12403087738260826, "time-step": 798}, {"errors": 0.1240289342737483, "time-step": 799}, {"errors": 0.12402698719803264, "time-step": 800}, {"errors": 0.12402503614630618, "time-step": 801}, {"errors": 0.12402308110939433, "time-step": 802}, {"errors": 0.12402112207810277, "time-step": 803}, {"errors": 0.12401915904321749, "time-step": 804}, {"errors": 0.12401719199550468, "time-step": 805}, {"errors": 0.12401522092571088, "time-step": 806}, {"errors": 0.12401324582456272, "time-step": 807}, {"errors": 0.12401126668276702, "time-step": 808}, {"errors": 0.12400928349101072, "time-step": 809}, {"errors": 0.12400729623996076, "time-step": 810}, {"errors": 0.12400530492026421, "time-step": 811}, {"errors": 0.12400330952254807, "time-step": 812}, {"errors": 0.12400131003741932, "time-step": 813}, {"errors": 0.12399930645546489, "time-step": 814}, {"errors": 0.12399729876725155, "time-step": 815}, {"errors": 0.12399528696332589, "time-step": 816}, {"errors": 0.12399327103421436, "time-step": 817}, {"errors": 0.12399125097042316, "time-step": 818}, {"errors": 0.12398922676243818, "time-step": 819}, {"errors": 0.12398719840072506, "time-step": 820}, {"errors": 0.12398516587572905, "time-step": 821}, {"errors": 0.12398312917787499, "time-step": 822}, {"errors": 0.12398108829756735, "time-step": 823}, {"errors": 0.12397904322519006, "time-step": 824}, {"errors": 0.12397699395110667, "time-step": 825}, {"errors": 0.12397494046566007, "time-step": 826}, {"errors": 0.12397288275917254, "time-step": 827}, {"errors": 0.12397082082194583, "time-step": 828}, {"errors": 0.12396875464426105, "time-step": 829}, {"errors": 0.1239666842163785, "time-step": 830}, {"errors": 0.12396460952853781, "time-step": 831}, {"errors": 0.12396253057095788, "time-step": 832}, {"errors": 0.12396044733383661, "time-step": 833}, {"errors": 0.12395835980735125, "time-step": 834}, {"errors": 0.12395626798165807, "time-step": 835}, {"errors": 0.12395417184689236, "time-step": 836}, {"errors": 0.12395207139316855, "time-step": 837}, {"errors": 0.12394996661057993, "time-step": 838}, {"errors": 0.1239478574891988, "time-step": 839}, {"errors": 0.12394574401907639, "time-step": 840}, {"errors": 0.12394362619024274, "time-step": 841}, {"errors": 0.12394150399270676, "time-step": 842}, {"errors": 0.12393937741645614, "time-step": 843}, {"errors": 0.12393724645145732, "time-step": 844}, {"errors": 0.12393511108765543, "time-step": 845}, {"errors": 0.12393297131497426, "time-step": 846}, {"errors": 0.12393082712331631, "time-step": 847}, {"errors": 0.12392867850256262, "time-step": 848}, {"errors": 0.12392652544257274, "time-step": 849}, {"errors": 0.12392436793318476, "time-step": 850}, {"errors": 0.12392220596421531, "time-step": 851}, {"errors": 0.12392003952545932, "time-step": 852}, {"errors": 0.12391786860669021, "time-step": 853}, {"errors": 0.12391569319765974, "time-step": 854}, {"errors": 0.12391351328809797, "time-step": 855}, {"errors": 0.12391132886771315, "time-step": 856}, {"errors": 0.12390913992619193, "time-step": 857}, {"errors": 0.12390694645319898, "time-step": 858}, {"errors": 0.12390474843837727, "time-step": 859}, {"errors": 0.12390254587134777, "time-step": 860}, {"errors": 0.12390033874170953, "time-step": 861}, {"errors": 0.12389812703903971, "time-step": 862}, {"errors": 0.12389591075289336, "time-step": 863}, {"errors": 0.12389368987280355, "time-step": 864}, {"errors": 0.12389146438828123, "time-step": 865}, {"errors": 0.12388923428881524, "time-step": 866}, {"errors": 0.12388699956387221, "time-step": 867}, {"errors": 0.12388476020289657, "time-step": 868}, {"errors": 0.12388251619531053, "time-step": 869}, {"errors": 0.12388026753051393, "time-step": 870}, {"errors": 0.12387801419788436, "time-step": 871}, {"errors": 0.12387575618677701, "time-step": 872}, {"errors": 0.12387349348652464, "time-step": 873}, {"errors": 0.12387122608643754, "time-step": 874}, {"errors": 0.12386895397580347, "time-step": 875}, {"errors": 0.1238666771438878, "time-step": 876}, {"errors": 0.12386439557993315, "time-step": 877}, {"errors": 0.1238621092731596, "time-step": 878}, {"errors": 0.12385981821276457, "time-step": 879}, {"errors": 0.12385752238792273, "time-step": 880}, {"errors": 0.1238552217877861, "time-step": 881}, {"errors": 0.12385291640148378, "time-step": 882}, {"errors": 0.12385060621812218, "time-step": 883}, {"errors": 0.12384829122678476, "time-step": 884}, {"errors": 0.12384597141653209, "time-step": 885}, {"errors": 0.1238436467764018, "time-step": 886}, {"errors": 0.1238413172954085, "time-step": 887}, {"errors": 0.12383898296254384, "time-step": 888}, {"errors": 0.1238366437667763, "time-step": 889}, {"errors": 0.12383429969705133, "time-step": 890}, {"errors": 0.12383195074229116, "time-step": 891}, {"errors": 0.12382959689139485, "time-step": 892}, {"errors": 0.12382723813323823, "time-step": 893}, {"errors": 0.12382487445667385, "time-step": 894}, {"errors": 0.1238225058505309, "time-step": 895}, {"errors": 0.12382013230361524, "time-step": 896}, {"errors": 0.1238177538047093, "time-step": 897}, {"errors": 0.12381537034257212, "time-step": 898}, {"errors": 0.12381298190593919, "time-step": 899}, {"errors": 0.12381058848352246, "time-step": 900}, {"errors": 0.12380819006401036, "time-step": 901}, {"errors": 0.12380578663606769, "time-step": 902}, {"errors": 0.12380337818833559, "time-step": 903}, {"errors": 0.12380096470943144, "time-step": 904}, {"errors": 0.12379854618794901, "time-step": 905}, {"errors": 0.12379612261245818, "time-step": 906}, {"errors": 0.12379369397150503, "time-step": 907}, {"errors": 0.12379126025361176, "time-step": 908}, {"errors": 0.12378882144727679, "time-step": 909}, {"errors": 0.12378637754097435, "time-step": 910}, {"errors": 0.12378392852315487, "time-step": 911}, {"errors": 0.12378147438224468, "time-step": 912}, {"errors": 0.12377901510664609, "time-step": 913}, {"errors": 0.12377655068473713, "time-step": 914}, {"errors": 0.12377408110487186, "time-step": 915}, {"errors": 0.12377160635538004, "time-step": 916}, {"errors": 0.12376912642456717, "time-step": 917}, {"errors": 0.12376664130071455, "time-step": 918}, {"errors": 0.12376415097207899, "time-step": 919}, {"errors": 0.12376165542689309, "time-step": 920}, {"errors": 0.12375915465336493, "time-step": 921}, {"errors": 0.12375664863967817, "time-step": 922}, {"errors": 0.12375413737399202, "time-step": 923}, {"errors": 0.12375162084444105, "time-step": 924}, {"errors": 0.12374909903913522, "time-step": 925}, {"errors": 0.12374657194616007, "time-step": 926}, {"errors": 0.12374403955357616, "time-step": 927}, {"errors": 0.1237415018494196, "time-step": 928}, {"errors": 0.1237389588217016, "time-step": 929}, {"errors": 0.12373641045840864, "time-step": 930}, {"errors": 0.12373385674750231, "time-step": 931}, {"errors": 0.12373129767691929, "time-step": 932}, {"errors": 0.12372873323457143, "time-step": 933}, {"errors": 0.1237261634083455, "time-step": 934}, {"errors": 0.12372358818610332, "time-step": 935}, {"errors": 0.1237210075556816, "time-step": 936}, {"errors": 0.1237184215048921, "time-step": 937}, {"errors": 0.12371583002152114, "time-step": 938}, {"errors": 0.12371323309333014, "time-step": 939}, {"errors": 0.12371063070805517, "time-step": 940}, {"errors": 0.123708022853407, "time-step": 941}, {"errors": 0.12370540951707112, "time-step": 942}, {"errors": 0.12370279068670773, "time-step": 943}, {"errors": 0.12370016634995146, "time-step": 944}, {"errors": 0.12369753649441159, "time-step": 945}, {"errors": 0.12369490110767199, "time-step": 946}, {"errors": 0.1236922601772908, "time-step": 947}, {"errors": 0.12368961369080078, "time-step": 948}, {"errors": 0.12368696163570893, "time-step": 949}, {"errors": 0.1236843039994967, "time-step": 950}, {"errors": 0.12368164076961968, "time-step": 951}, {"errors": 0.1236789719335079, "time-step": 952}, {"errors": 0.1236762974785654, "time-step": 953}, {"errors": 0.12367361739217053, "time-step": 954}, {"errors": 0.1236709316616757, "time-step": 955}, {"errors": 0.1236682402744074, "time-step": 956}, {"errors": 0.12366554321766615, "time-step": 957}, {"errors": 0.12366284047872644, "time-step": 958}, {"errors": 0.12366013204483672, "time-step": 959}, {"errors": 0.12365741790321932, "time-step": 960}, {"errors": 0.1236546980410705, "time-step": 961}, {"errors": 0.12365197244556028, "time-step": 962}, {"errors": 0.12364924110383234, "time-step": 963}, {"errors": 0.12364650400300427, "time-step": 964}, {"errors": 0.12364376113016723, "time-step": 965}, {"errors": 0.12364101247238607, "time-step": 966}, {"errors": 0.1236382580166992, "time-step": 967}, {"errors": 0.1236354977501185, "time-step": 968}, {"errors": 0.12363273165962956, "time-step": 969}, {"errors": 0.12362995973219121, "time-step": 970}, {"errors": 0.12362718195473585, "time-step": 971}, {"errors": 0.12362439831416915, "time-step": 972}, {"errors": 0.12362160879737018, "time-step": 973}, {"errors": 0.12361881339119124, "time-step": 974}, {"errors": 0.1236160120824579, "time-step": 975}, {"errors": 0.12361320485796892, "time-step": 976}, {"errors": 0.12361039170449623, "time-step": 977}, {"errors": 0.12360757260878477, "time-step": 978}, {"errors": 0.12360474755755269, "time-step": 979}, {"errors": 0.12360191653749103, "time-step": 980}, {"errors": 0.12359907953526389, "time-step": 981}, {"errors": 0.12359623653750826, "time-step": 982}, {"errors": 0.12359338753083396, "time-step": 983}, {"errors": 0.12359053250182381, "time-step": 984}, {"errors": 0.12358767143703323, "time-step": 985}, {"errors": 0.12358480432299052, "time-step": 986}, {"errors": 0.12358193114619662, "time-step": 987}, {"errors": 0.1235790518931252, "time-step": 988}, {"errors": 0.1235761665502225, "time-step": 989}, {"errors": 0.1235732751039073, "time-step": 990}, {"errors": 0.12357037754057099, "time-step": 991}, {"errors": 0.12356747384657735, "time-step": 992}, {"errors": 0.12356456400826273, "time-step": 993}, {"errors": 0.12356164801193573, "time-step": 994}, {"errors": 0.12355872584387737, "time-step": 995}, {"errors": 0.12355579749034093, "time-step": 996}, {"errors": 0.12355286293755201, "time-step": 997}, {"errors": 0.12354992217170845, "time-step": 998}, {"errors": 0.12354697517898017, "time-step": 999}, {"errors": 0.12354402194550917, "time-step": 1000}, {"errors": 0.12354106245740976, "time-step": 1001}, {"errors": 0.12353809670076801, "time-step": 1002}, {"errors": 0.12353512466164215, "time-step": 1003}, {"errors": 0.12353214632606237, "time-step": 1004}, {"errors": 0.12352916168003061, "time-step": 1005}, {"errors": 0.12352617070952082, "time-step": 1006}, {"errors": 0.1235231734004786, "time-step": 1007}, {"errors": 0.12352016973882157, "time-step": 1008}, {"errors": 0.12351715971043875, "time-step": 1009}, {"errors": 0.1235141433011911, "time-step": 1010}, {"errors": 0.12351112049691107, "time-step": 1011}, {"errors": 0.12350809128340276, "time-step": 1012}, {"errors": 0.12350505564644171, "time-step": 1013}, {"errors": 0.1235020135717751, "time-step": 1014}, {"errors": 0.12349896504512142, "time-step": 1015}, {"errors": 0.12349591005217067, "time-step": 1016}, {"errors": 0.12349284857858417, "time-step": 1017}, {"errors": 0.12348978060999452, "time-step": 1018}, {"errors": 0.12348670613200566, "time-step": 1019}, {"errors": 0.12348362513019259, "time-step": 1020}, {"errors": 0.1234805375901018, "time-step": 1021}, {"errors": 0.12347744349725054, "time-step": 1022}, {"errors": 0.12347434283712744, "time-step": 1023}, {"errors": 0.123471235595192, "time-step": 1024}, {"errors": 0.12346812175687483, "time-step": 1025}, {"errors": 0.1234650013075774, "time-step": 1026}, {"errors": 0.12346187423267208, "time-step": 1027}, {"errors": 0.12345874051750222, "time-step": 1028}, {"errors": 0.12345560014738186, "time-step": 1029}, {"errors": 0.12345245310759587, "time-step": 1030}, {"errors": 0.1234492993833998, "time-step": 1031}, {"errors": 0.12344613896001994, "time-step": 1032}, {"errors": 0.12344297182265318, "time-step": 1033}, {"errors": 0.12343979795646697, "time-step": 1034}, {"errors": 0.12343661734659937, "time-step": 1035}, {"errors": 0.12343342997815882, "time-step": 1036}, {"errors": 0.12343023583622435, "time-step": 1037}, {"errors": 0.12342703490584533, "time-step": 1038}, {"errors": 0.12342382717204145, "time-step": 1039}, {"errors": 0.1234206126198028, "time-step": 1040}, {"errors": 0.12341739123408962, "time-step": 1041}, {"errors": 0.12341416299983253, "time-step": 1042}, {"errors": 0.12341092790193217, "time-step": 1043}, {"errors": 0.12340768592525941, "time-step": 1044}, {"errors": 0.12340443705465519, "time-step": 1045}, {"errors": 0.12340118127493047, "time-step": 1046}, {"errors": 0.12339791857086618, "time-step": 1047}, {"errors": 0.12339464892721327, "time-step": 1048}, {"errors": 0.12339137232869254, "time-step": 1049}, {"errors": 0.12338808875999469, "time-step": 1050}, {"errors": 0.12338479820578013, "time-step": 1051}, {"errors": 0.12338150065067915, "time-step": 1052}, {"errors": 0.12337819607929176, "time-step": 1053}, {"errors": 0.12337488447618752, "time-step": 1054}, {"errors": 0.1233715658259058, "time-step": 1055}, {"errors": 0.12336824011295534, "time-step": 1056}, {"errors": 0.1233649073218146, "time-step": 1057}, {"errors": 0.12336156743693144, "time-step": 1058}, {"errors": 0.12335822044272324, "time-step": 1059}, {"errors": 0.12335486632357665, "time-step": 1060}, {"errors": 0.12335150506384783, "time-step": 1061}, {"errors": 0.12334813664786205, "time-step": 1062}, {"errors": 0.1233447610599141, "time-step": 1063}, {"errors": 0.12334137828426778, "time-step": 1064}, {"errors": 0.1233379883051561, "time-step": 1065}, {"errors": 0.1233345911067813, "time-step": 1066}, {"errors": 0.12333118667331457, "time-step": 1067}, {"errors": 0.12332777498889622, "time-step": 1068}, {"errors": 0.12332435603763545, "time-step": 1069}, {"errors": 0.12332092980361054, "time-step": 1070}, {"errors": 0.12331749627086858, "time-step": 1071}, {"errors": 0.12331405542342547, "time-step": 1072}, {"errors": 0.12331060724526605, "time-step": 1073}, {"errors": 0.12330715172034375, "time-step": 1074}, {"errors": 0.12330368883258086, "time-step": 1075}, {"errors": 0.12330021856586823, "time-step": 1076}, {"errors": 0.12329674090406537, "time-step": 1077}, {"errors": 0.12329325583100043, "time-step": 1078}, {"errors": 0.12328976333047001, "time-step": 1079}, {"errors": 0.12328626338623917, "time-step": 1080}, {"errors": 0.12328275598204147, "time-step": 1081}, {"errors": 0.1232792411015789, "time-step": 1082}, {"errors": 0.12327571872852167, "time-step": 1083}, {"errors": 0.12327218884650834, "time-step": 1084}, {"errors": 0.12326865143914582, "time-step": 1085}, {"errors": 0.1232651064900091, "time-step": 1086}, {"errors": 0.12326155398264142, "time-step": 1087}, {"errors": 0.12325799390055409, "time-step": 1088}, {"errors": 0.1232544262272265, "time-step": 1089}, {"errors": 0.12325085094610608, "time-step": 1090}, {"errors": 0.1232472680406082, "time-step": 1091}, {"errors": 0.12324367749411622, "time-step": 1092}, {"errors": 0.12324007928998137, "time-step": 1093}, {"errors": 0.12323647341152268, "time-step": 1094}, {"errors": 0.12323285984202706, "time-step": 1095}, {"errors": 0.1232292385647491, "time-step": 1096}, {"errors": 0.12322560956291112, "time-step": 1097}, {"errors": 0.1232219728197031, "time-step": 1098}, {"errors": 0.12321832831828264, "time-step": 1099}, {"errors": 0.12321467604177488, "time-step": 1100}, {"errors": 0.12321101597327254, "time-step": 1101}, {"errors": 0.12320734809583576, "time-step": 1102}, {"errors": 0.12320367239249218, "time-step": 1103}, {"errors": 0.1231999888462367, "time-step": 1104}, {"errors": 0.12319629744003173, "time-step": 1105}, {"errors": 0.1231925981568068, "time-step": 1106}, {"errors": 0.12318889097945884, "time-step": 1107}, {"errors": 0.12318517589085189, "time-step": 1108}, {"errors": 0.12318145287381721, "time-step": 1109}, {"errors": 0.12317772191115309, "time-step": 1110}, {"errors": 0.12317398298562499, "time-step": 1111}, {"errors": 0.12317023607996533, "time-step": 1112}, {"errors": 0.12316648117687351, "time-step": 1113}, {"errors": 0.12316271825901588, "time-step": 1114}, {"errors": 0.12315894730902566, "time-step": 1115}, {"errors": 0.12315516830950289, "time-step": 1116}, {"errors": 0.1231513812430145, "time-step": 1117}, {"errors": 0.12314758609209404, "time-step": 1118}, {"errors": 0.12314378283924186, "time-step": 1119}, {"errors": 0.1231399714669249, "time-step": 1120}, {"errors": 0.1231361519575768, "time-step": 1121}, {"errors": 0.12313232429359766, "time-step": 1122}, {"errors": 0.12312848845735422, "time-step": 1123}, {"errors": 0.1231246444311796, "time-step": 1124}, {"errors": 0.12312079219737343, "time-step": 1125}, {"errors": 0.12311693173820171, "time-step": 1126}, {"errors": 0.12311306303589671, "time-step": 1127}, {"errors": 0.12310918607265706, "time-step": 1128}, {"errors": 0.12310530083064768, "time-step": 1129}, {"errors": 0.12310140729199964, "time-step": 1130}, {"errors": 0.1230975054388102, "time-step": 1131}, {"errors": 0.1230935952531427, "time-step": 1132}, {"errors": 0.12308967671702663, "time-step": 1133}, {"errors": 0.1230857498124574, "time-step": 1134}, {"errors": 0.12308181452139652, "time-step": 1135}, {"errors": 0.1230778708257714, "time-step": 1136}, {"errors": 0.12307391870747528, "time-step": 1137}, {"errors": 0.12306995814836734, "time-step": 1138}, {"errors": 0.12306598913027252, "time-step": 1139}, {"errors": 0.1230620116349815, "time-step": 1140}, {"errors": 0.12305802564425075, "time-step": 1141}, {"errors": 0.12305403113980232, "time-step": 1142}, {"errors": 0.123050028103324, "time-step": 1143}, {"errors": 0.12304601651646904, "time-step": 1144}, {"errors": 0.1230419963608563, "time-step": 1145}, {"errors": 0.12303796761807012, "time-step": 1146}, {"errors": 0.12303393026966031, "time-step": 1147}, {"errors": 0.12302988429714208, "time-step": 1148}, {"errors": 0.12302582968199596, "time-step": 1149}, {"errors": 0.12302176640566781, "time-step": 1150}, {"errors": 0.12301769444956882, "time-step": 1151}, {"errors": 0.12301361379507537, "time-step": 1152}, {"errors": 0.12300952442352904, "time-step": 1153}, {"errors": 0.12300542631623648, "time-step": 1154}, {"errors": 0.12300131945446956, "time-step": 1155}, {"errors": 0.1229972038194651, "time-step": 1156}, {"errors": 0.12299307939242497, "time-step": 1157}, {"errors": 0.12298894615451605, "time-step": 1158}, {"errors": 0.1229848040868701, "time-step": 1159}, {"errors": 0.12298065317058371, "time-step": 1160}, {"errors": 0.1229764933867184, "time-step": 1161}, {"errors": 0.12297232471630046, "time-step": 1162}, {"errors": 0.12296814714032088, "time-step": 1163}, {"errors": 0.12296396063973537, "time-step": 1164}, {"errors": 0.1229597651954644, "time-step": 1165}, {"errors": 0.12295556078839286, "time-step": 1166}, {"errors": 0.12295134739937048, "time-step": 1167}, {"errors": 0.12294712500921126, "time-step": 1168}, {"errors": 0.12294289359869388, "time-step": 1169}, {"errors": 0.12293865314856141, "time-step": 1170}, {"errors": 0.1229344036395213, "time-step": 1171}, {"errors": 0.12293014505224532, "time-step": 1172}, {"errors": 0.12292587736736973, "time-step": 1173}, {"errors": 0.12292160056549487, "time-step": 1174}, {"errors": 0.12291731462718544, "time-step": 1175}, {"errors": 0.12291301953297032, "time-step": 1176}, {"errors": 0.12290871526334246, "time-step": 1177}, {"errors": 0.12290440179875897, "time-step": 1178}, {"errors": 0.12290007911964113, "time-step": 1179}, {"errors": 0.122895747206374, "time-step": 1180}, {"errors": 0.12289140603930687, "time-step": 1181}, {"errors": 0.12288705559875279, "time-step": 1182}, {"errors": 0.1228826958649889, "time-step": 1183}, {"errors": 0.12287832681825592, "time-step": 1184}, {"errors": 0.12287394843875869, "time-step": 1185}, {"errors": 0.12286956070666556, "time-step": 1186}, {"errors": 0.12286516360210883, "time-step": 1187}, {"errors": 0.12286075710518432, "time-step": 1188}, {"errors": 0.12285634119595157, "time-step": 1189}, {"errors": 0.12285191585443375, "time-step": 1190}, {"errors": 0.12284748106061755, "time-step": 1191}, {"errors": 0.12284303679445327, "time-step": 1192}, {"errors": 0.12283858303585457, "time-step": 1193}, {"errors": 0.12283411976469863, "time-step": 1194}, {"errors": 0.12282964696082607, "time-step": 1195}, {"errors": 0.12282516460404073, "time-step": 1196}, {"errors": 0.12282067267410998, "time-step": 1197}, {"errors": 0.12281617115076426, "time-step": 1198}, {"errors": 0.12281166001369742, "time-step": 1199}, {"errors": 0.1228071392425664, "time-step": 1200}, {"errors": 0.12280260881699138, "time-step": 1201}, {"errors": 0.12279806871655566, "time-step": 1202}, {"errors": 0.12279351892080552, "time-step": 1203}, {"errors": 0.12278895940925036, "time-step": 1204}, {"errors": 0.12278439016136267, "time-step": 1205}, {"errors": 0.12277981115657768, "time-step": 1206}, {"errors": 0.12277522237429378, "time-step": 1207}, {"errors": 0.12277062379387207, "time-step": 1208}, {"errors": 0.12276601539463665, "time-step": 1209}, {"errors": 0.12276139715587431, "time-step": 1210}, {"errors": 0.1227567690568346, "time-step": 1211}, {"errors": 0.12275213107672989, "time-step": 1212}, {"errors": 0.12274748319473514, "time-step": 1213}, {"errors": 0.12274282538998812, "time-step": 1214}, {"errors": 0.1227381576415891, "time-step": 1215}, {"errors": 0.12273347992860084, "time-step": 1216}, {"errors": 0.12272879223004882, "time-step": 1217}, {"errors": 0.122724094524921, "time-step": 1218}, {"errors": 0.1227193867921676, "time-step": 1219}, {"errors": 0.12271466901070155, "time-step": 1220}, {"errors": 0.12270994115939794, "time-step": 1221}, {"errors": 0.12270520321709438, "time-step": 1222}, {"errors": 0.12270045516259066, "time-step": 1223}, {"errors": 0.12269569697464894, "time-step": 1224}, {"errors": 0.12269092863199355, "time-step": 1225}, {"errors": 0.12268615011331108, "time-step": 1226}, {"errors": 0.12268136139725029, "time-step": 1227}, {"errors": 0.12267656246242203, "time-step": 1228}, {"errors": 0.1226717532873993, "time-step": 1229}, {"errors": 0.12266693385071709, "time-step": 1230}, {"errors": 0.12266210413087245, "time-step": 1231}, {"errors": 0.12265726410632441, "time-step": 1232}, {"errors": 0.12265241375549399, "time-step": 1233}, {"errors": 0.12264755305676411, "time-step": 1234}, {"errors": 0.12264268198847952, "time-step": 1235}, {"errors": 0.12263780052894685, "time-step": 1236}, {"errors": 0.12263290865643459, "time-step": 1237}, {"errors": 0.12262800634917301, "time-step": 1238}, {"errors": 0.12262309358535396, "time-step": 1239}, {"errors": 0.12261817034313122, "time-step": 1240}, {"errors": 0.1226132366006201, "time-step": 1241}, {"errors": 0.12260829233589765, "time-step": 1242}, {"errors": 0.1226033375270024, "time-step": 1243}, {"errors": 0.12259837215193464, "time-step": 1244}, {"errors": 0.122593396188656, "time-step": 1245}, {"errors": 0.12258840961508977, "time-step": 1246}, {"errors": 0.12258341240912063, "time-step": 1247}, {"errors": 0.12257840454859474, "time-step": 1248}, {"errors": 0.12257338601131965, "time-step": 1249}, {"errors": 0.12256835677506436, "time-step": 1250}, {"errors": 0.12256331681755905, "time-step": 1251}, {"errors": 0.12255826611649544, "time-step": 1252}, {"errors": 0.12255320464952635, "time-step": 1253}, {"errors": 0.12254813239426593, "time-step": 1254}, {"errors": 0.12254304932828955, "time-step": 1255}, {"errors": 0.12253795542913373, "time-step": 1256}, {"errors": 0.12253285067429623, "time-step": 1257}, {"errors": 0.12252773504123585, "time-step": 1258}, {"errors": 0.12252260850737248, "time-step": 1259}, {"errors": 0.12251747105008723, "time-step": 1260}, {"errors": 0.12251232264672204, "time-step": 1261}, {"errors": 0.12250716327458006, "time-step": 1262}, {"errors": 0.12250199291092523, "time-step": 1263}, {"errors": 0.1224968115329826, "time-step": 1264}, {"errors": 0.12249161911793802, "time-step": 1265}, {"errors": 0.12248641564293833, "time-step": 1266}, {"errors": 0.1224812010850912, "time-step": 1267}, {"errors": 0.12247597542146509, "time-step": 1268}, {"errors": 0.12247073862908936, "time-step": 1269}, {"errors": 0.12246549068495406, "time-step": 1270}, {"errors": 0.12246023156601005, "time-step": 1271}, {"errors": 0.12245496124916896, "time-step": 1272}, {"errors": 0.12244967971130297, "time-step": 1273}, {"errors": 0.12244438692924511, "time-step": 1274}, {"errors": 0.12243908287978894, "time-step": 1275}, {"errors": 0.12243376753968871, "time-step": 1276}, {"errors": 0.1224284408856592, "time-step": 1277}, {"errors": 0.12242310289437586, "time-step": 1278}, {"errors": 0.12241775354247457, "time-step": 1279}, {"errors": 0.12241239280655188, "time-step": 1280}, {"errors": 0.12240702066316465, "time-step": 1281}, {"errors": 0.12240163708883034, "time-step": 1282}, {"errors": 0.12239624206002689, "time-step": 1283}, {"errors": 0.12239083555319254, "time-step": 1284}, {"errors": 0.122385417544726, "time-step": 1285}, {"errors": 0.12237998801098642, "time-step": 1286}, {"errors": 0.12237454692829319, "time-step": 1287}, {"errors": 0.12236909427292611, "time-step": 1288}, {"errors": 0.12236363002112528, "time-step": 1289}, {"errors": 0.12235815414909108, "time-step": 1290}, {"errors": 0.12235266663298416, "time-step": 1291}, {"errors": 0.12234716744892546, "time-step": 1292}, {"errors": 0.12234165657299605, "time-step": 1293}, {"errors": 0.1223361339812373, "time-step": 1294}, {"errors": 0.12233059964965076, "time-step": 1295}, {"errors": 0.12232505355419807, "time-step": 1296}, {"errors": 0.12231949567080112, "time-step": 1297}, {"errors": 0.1223139259753419, "time-step": 1298}, {"errors": 0.1223083444436624, "time-step": 1299}, {"errors": 0.12230275105156485, "time-step": 1300}, {"errors": 0.12229714577481156, "time-step": 1301}, {"errors": 0.12229152858912475, "time-step": 1302}, {"errors": 0.12228589947018678, "time-step": 1303}, {"errors": 0.12228025839364004, "time-step": 1304}, {"errors": 0.12227460533508691, "time-step": 1305}, {"errors": 0.12226894027008972, "time-step": 1306}, {"errors": 0.12226326317417086, "time-step": 1307}, {"errors": 0.12225757402281254, "time-step": 1308}, {"errors": 0.12225187279145709, "time-step": 1309}, {"errors": 0.12224615945550663, "time-step": 1310}, {"errors": 0.1222404339903233, "time-step": 1311}, {"errors": 0.122234696371229, "time-step": 1312}, {"errors": 0.12222894657350566, "time-step": 1313}, {"errors": 0.12222318457239509, "time-step": 1314}, {"errors": 0.12221741034309881, "time-step": 1315}, {"errors": 0.12221162386077829, "time-step": 1316}, {"errors": 0.12220582510055487, "time-step": 1317}, {"errors": 0.12220001403750964, "time-step": 1318}, {"errors": 0.12219419064668358, "time-step": 1319}, {"errors": 0.12218835490307745, "time-step": 1320}, {"errors": 0.12218250678165173, "time-step": 1321}, {"errors": 0.1221766462573268, "time-step": 1322}, {"errors": 0.12217077330498277, "time-step": 1323}, {"errors": 0.12216488789945953, "time-step": 1324}, {"errors": 0.12215899001555666, "time-step": 1325}, {"errors": 0.12215307962803358, "time-step": 1326}, {"errors": 0.12214715671160947, "time-step": 1327}, {"errors": 0.1221412212409631, "time-step": 1328}, {"errors": 0.12213527319073314, "time-step": 1329}, {"errors": 0.12212931253551794, "time-step": 1330}, {"errors": 0.1221233392498755, "time-step": 1331}, {"errors": 0.12211735330832355, "time-step": 1332}, {"errors": 0.12211135468533967, "time-step": 1333}, {"errors": 0.12210534335536094, "time-step": 1334}, {"errors": 0.12209931929278425, "time-step": 1335}, {"errors": 0.12209328247196627, "time-step": 1336}, {"errors": 0.12208723286722316, "time-step": 1337}, {"errors": 0.12208117045283094, "time-step": 1338}, {"errors": 0.12207509520302526, "time-step": 1339}, {"errors": 0.12206900709200158, "time-step": 1340}, {"errors": 0.12206290609391479, "time-step": 1341}, {"errors": 0.12205679218287971, "time-step": 1342}, {"errors": 0.12205066533297079, "time-step": 1343}, {"errors": 0.12204452551822212, "time-step": 1344}, {"errors": 0.12203837271262753, "time-step": 1345}, {"errors": 0.12203220689014056, "time-step": 1346}, {"errors": 0.12202602802467438, "time-step": 1347}, {"errors": 0.12201983609010197, "time-step": 1348}, {"errors": 0.12201363106025592, "time-step": 1349}, {"errors": 0.12200741290892861, "time-step": 1350}, {"errors": 0.12200118160987204, "time-step": 1351}, {"errors": 0.12199493713679799, "time-step": 1352}, {"errors": 0.121988679463378, "time-step": 1353}, {"errors": 0.12198240856324331, "time-step": 1354}, {"errors": 0.12197612440998488, "time-step": 1355}, {"errors": 0.12196982697715344, "time-step": 1356}, {"errors": 0.12196351623825946, "time-step": 1357}, {"errors": 0.12195719216677325, "time-step": 1358}, {"errors": 0.1219508547361248, "time-step": 1359}, {"errors": 0.12194450391970393, "time-step": 1360}, {"errors": 0.12193813969086029, "time-step": 1361}, {"errors": 0.1219317620229032, "time-step": 1362}, {"errors": 0.12192537088910203, "time-step": 1363}, {"errors": 0.12191896626268581, "time-step": 1364}, {"errors": 0.12191254811684349, "time-step": 1365}, {"errors": 0.12190611642472379, "time-step": 1366}, {"errors": 0.12189967115943545, "time-step": 1367}, {"errors": 0.121893212294047, "time-step": 1368}, {"errors": 0.1218867398015869, "time-step": 1369}, {"errors": 0.1218802536550435, "time-step": 1370}, {"errors": 0.1218737538273652, "time-step": 1371}, {"errors": 0.12186724029146026, "time-step": 1372}, {"errors": 0.12186071302019695, "time-step": 1373}, {"errors": 0.12185417198640354, "time-step": 1374}, {"errors": 0.12184761716286827, "time-step": 1375}, {"errors": 0.12184104852233953, "time-step": 1376}, {"errors": 0.12183446603752565, "time-step": 1377}, {"errors": 0.1218278696810951, "time-step": 1378}, {"errors": 0.12182125942567648, "time-step": 1379}, {"errors": 0.1218146352438585, "time-step": 1380}, {"errors": 0.12180799710818993, "time-step": 1381}, {"errors": 0.12180134499117985, "time-step": 1382}, {"errors": 0.12179467886529749, "time-step": 1383}, {"errors": 0.12178799870297233, "time-step": 1384}, {"errors": 0.1217813044765941, "time-step": 1385}, {"errors": 0.12177459615851277, "time-step": 1386}, {"errors": 0.12176787372103866, "time-step": 1387}, {"errors": 0.12176113713644246, "time-step": 1388}, {"errors": 0.12175438637695526, "time-step": 1389}, {"errors": 0.12174762141476844, "time-step": 1390}, {"errors": 0.12174084222203391, "time-step": 1391}, {"errors": 0.12173404877086402, "time-step": 1392}, {"errors": 0.12172724103333168, "time-step": 1393}, {"errors": 0.12172041898147029, "time-step": 1394}, {"errors": 0.12171358258727374, "time-step": 1395}, {"errors": 0.12170673182269676, "time-step": 1396}, {"errors": 0.12169986665965447, "time-step": 1397}, {"errors": 0.12169298707002285, "time-step": 1398}, {"errors": 0.12168609302563853, "time-step": 1399}, {"errors": 0.12167918449829888, "time-step": 1400}, {"errors": 0.1216722614597622, "time-step": 1401}, {"errors": 0.12166532388174753, "time-step": 1402}, {"errors": 0.12165837173593476, "time-step": 1403}, {"errors": 0.12165140499396482, "time-step": 1404}, {"errors": 0.12164442362743949, "time-step": 1405}, {"errors": 0.12163742760792173, "time-step": 1406}, {"errors": 0.12163041690693539, "time-step": 1407}, {"errors": 0.12162339149596554, "time-step": 1408}, {"errors": 0.12161635134645843, "time-step": 1409}, {"errors": 0.12160929642982135, "time-step": 1410}, {"errors": 0.12160222671742303, "time-step": 1411}, {"errors": 0.12159514218059342, "time-step": 1412}, {"errors": 0.12158804279062385, "time-step": 1413}, {"errors": 0.121580928518767, "time-step": 1414}, {"errors": 0.12157379933623715, "time-step": 1415}, {"errors": 0.12156665521420987, "time-step": 1416}, {"errors": 0.12155949612382258, "time-step": 1417}, {"errors": 0.12155232203617405, "time-step": 1418}, {"errors": 0.12154513292232494, "time-step": 1419}, {"errors": 0.12153792875329752, "time-step": 1420}, {"errors": 0.12153070950007597, "time-step": 1421}, {"errors": 0.1215234751336062, "time-step": 1422}, {"errors": 0.12151622562479616, "time-step": 1423}, {"errors": 0.12150896094451571, "time-step": 1424}, {"errors": 0.12150168106359677, "time-step": 1425}, {"errors": 0.12149438595283342, "time-step": 1426}, {"errors": 0.1214870755829818, "time-step": 1427}, {"errors": 0.12147974992476035, "time-step": 1428}, {"errors": 0.12147240894884989, "time-step": 1429}, {"errors": 0.12146505262589355, "time-step": 1430}, {"errors": 0.12145768092649681, "time-step": 1431}, {"errors": 0.12145029382122781, "time-step": 1432}, {"errors": 0.12144289128061725, "time-step": 1433}, {"errors": 0.12143547327515843, "time-step": 1434}, {"errors": 0.12142803977530739, "time-step": 1435}, {"errors": 0.12142059075148302, "time-step": 1436}, {"errors": 0.12141312617406708, "time-step": 1437}, {"errors": 0.12140564601340424, "time-step": 1438}, {"errors": 0.12139815023980229, "time-step": 1439}, {"errors": 0.12139063882353203, "time-step": 1440}, {"errors": 0.12138311173482756, "time-step": 1441}, {"errors": 0.12137556894388621, "time-step": 1442}, {"errors": 0.12136801042086863, "time-step": 1443}, {"errors": 0.12136043613589902, "time-step": 1444}, {"errors": 0.12135284605906503, "time-step": 1445}, {"errors": 0.12134524016041791, "time-step": 1446}, {"errors": 0.12133761840997265, "time-step": 1447}, {"errors": 0.12132998077770804, "time-step": 1448}, {"errors": 0.12132232723356676, "time-step": 1449}, {"errors": 0.1213146577474554, "time-step": 1450}, {"errors": 0.12130697228924468, "time-step": 1451}, {"errors": 0.12129927082876946, "time-step": 1452}, {"errors": 0.1212915533358288, "time-step": 1453}, {"errors": 0.12128381978018621, "time-step": 1454}, {"errors": 0.12127607013156952, "time-step": 1455}, {"errors": 0.12126830435967126, "time-step": 1456}, {"errors": 0.12126052243414842, "time-step": 1457}, {"errors": 0.1212527243246229, "time-step": 1458}, {"errors": 0.12124491000068138, "time-step": 1459}, {"errors": 0.12123707943187546, "time-step": 1460}, {"errors": 0.12122923258772186, "time-step": 1461}, {"errors": 0.12122136943770243, "time-step": 1462}, {"errors": 0.12121348995126424, "time-step": 1463}, {"errors": 0.12120559409781984, "time-step": 1464}, {"errors": 0.1211976818467472, "time-step": 1465}, {"errors": 0.12118975316738995, "time-step": 1466}, {"errors": 0.12118180802905737, "time-step": 1467}, {"errors": 0.12117384640102462, "time-step": 1468}, {"errors": 0.12116586825253277, "time-step": 1469}, {"errors": 0.12115787355278891, "time-step": 1470}, {"errors": 0.12114986227096645, "time-step": 1471}, {"errors": 0.12114183437620499, "time-step": 1472}, {"errors": 0.12113378983761061, "time-step": 1473}, {"errors": 0.12112572862425586, "time-step": 1474}, {"errors": 0.12111765070517998, "time-step": 1475}, {"errors": 0.12110955604938915, "time-step": 1476}, {"errors": 0.12110144462585623, "time-step": 1477}, {"errors": 0.12109331640352135, "time-step": 1478}, {"errors": 0.12108517135129165, "time-step": 1479}, {"errors": 0.12107700943804177, "time-step": 1480}, {"errors": 0.12106883063261362, "time-step": 1481}, {"errors": 0.12106063490381674, "time-step": 1482}, {"errors": 0.1210524222204285, "time-step": 1483}, {"errors": 0.12104419255119395, "time-step": 1484}, {"errors": 0.12103594586482633, "time-step": 1485}, {"errors": 0.12102768213000681, "time-step": 1486}, {"errors": 0.12101940131538501, "time-step": 1487}, {"errors": 0.12101110338957885, "time-step": 1488}, {"errors": 0.12100278832117489, "time-step": 1489}, {"errors": 0.12099445607872841, "time-step": 1490}, {"errors": 0.1209861066307635, "time-step": 1491}, {"errors": 0.12097773994577332, "time-step": 1492}, {"errors": 0.12096935599222018, "time-step": 1493}, {"errors": 0.12096095473853569, "time-step": 1494}, {"errors": 0.1209525361531209, "time-step": 1495}, {"errors": 0.12094410020434664, "time-step": 1496}, {"errors": 0.12093564686055333, "time-step": 1497}, {"errors": 0.12092717609005149, "time-step": 1498}, {"errors": 0.12091868786112173, "time-step": 1499}, {"errors": 0.12091018214201486, "time-step": 1500}, {"errors": 0.12090165890095217, "time-step": 1501}, {"errors": 0.12089311810612569, "time-step": 1502}, {"errors": 0.12088455972569792, "time-step": 1503}, {"errors": 0.12087598372780264, "time-step": 1504}, {"errors": 0.12086739008054453, "time-step": 1505}, {"errors": 0.12085877875199962, "time-step": 1506}, {"errors": 0.12085014971021552, "time-step": 1507}, {"errors": 0.12084150292321125, "time-step": 1508}, {"errors": 0.12083283835897793, "time-step": 1509}, {"errors": 0.12082415598547842, "time-step": 1510}, {"errors": 0.120815455770648, "time-step": 1511}, {"errors": 0.12080673768239417, "time-step": 1512}, {"errors": 0.12079800168859704, "time-step": 1513}, {"errors": 0.12078924775710949, "time-step": 1514}, {"errors": 0.12078047585575727, "time-step": 1515}, {"errors": 0.12077168595233931, "time-step": 1516}, {"errors": 0.12076287801462787, "time-step": 1517}, {"errors": 0.12075405201036868, "time-step": 1518}, {"errors": 0.12074520790728122, "time-step": 1519}, {"errors": 0.12073634567305887, "time-step": 1520}, {"errors": 0.12072746527536918, "time-step": 1521}, {"errors": 0.12071856668185392, "time-step": 1522}, {"errors": 0.12070964986012944, "time-step": 1523}, {"errors": 0.12070071477778682, "time-step": 1524}, {"errors": 0.12069176140239202, "time-step": 1525}, {"errors": 0.12068278970148626, "time-step": 1526}, {"errors": 0.12067379964258601, "time-step": 1527}, {"errors": 0.12066479119318341, "time-step": 1528}, {"errors": 0.1206557643207463, "time-step": 1529}, {"errors": 0.12064671899271863, "time-step": 1530}, {"errors": 0.12063765517652045, "time-step": 1531}, {"errors": 0.12062857283954843, "time-step": 1532}, {"errors": 0.12061947194917574, "time-step": 1533}, {"errors": 0.12061035247275262, "time-step": 1534}, {"errors": 0.12060121437760636, "time-step": 1535}, {"errors": 0.1205920576310416, "time-step": 1536}, {"errors": 0.12058288220034055, "time-step": 1537}, {"errors": 0.12057368805276342, "time-step": 1538}, {"errors": 0.12056447515554827, "time-step": 1539}, {"errors": 0.1205552434759116, "time-step": 1540}, {"errors": 0.12054599298104843, "time-step": 1541}, {"errors": 0.12053672363813261, "time-step": 1542}, {"errors": 0.12052743541431687, "time-step": 1543}, {"errors": 0.12051812827673344, "time-step": 1544}, {"errors": 0.12050880219249395, "time-step": 1545}, {"errors": 0.12049945712868981, "time-step": 1546}, {"errors": 0.12049009305239253, "time-step": 1547}, {"errors": 0.12048070993065393, "time-step": 1548}, {"errors": 0.12047130773050632, "time-step": 1549}, {"errors": 0.12046188641896281, "time-step": 1550}, {"errors": 0.12045244596301763, "time-step": 1551}, {"errors": 0.12044298632964635, "time-step": 1552}, {"errors": 0.12043350748580618, "time-step": 1553}, {"errors": 0.12042400939843612, "time-step": 1554}, {"errors": 0.12041449203445737, "time-step": 1555}, {"errors": 0.12040495536077354, "time-step": 1556}, {"errors": 0.12039539934427096, "time-step": 1557}, {"errors": 0.12038582395181899, "time-step": 1558}, {"errors": 0.12037622915027005, "time-step": 1559}, {"errors": 0.12036661490646025, "time-step": 1560}, {"errors": 0.12035698118720956, "time-step": 1561}, {"errors": 0.12034732795932201, "time-step": 1562}, {"errors": 0.12033765518958595, "time-step": 1563}, {"errors": 0.12032796284477455, "time-step": 1564}, {"errors": 0.1203182508916459, "time-step": 1565}, {"errors": 0.12030851929694338, "time-step": 1566}, {"errors": 0.12029876802739599, "time-step": 1567}, {"errors": 0.12028899704971857, "time-step": 1568}, {"errors": 0.12027920633061218, "time-step": 1569}, {"errors": 0.12026939583676438, "time-step": 1570}, {"errors": 0.12025956553484947, "time-step": 1571}, {"errors": 0.12024971539152893, "time-step": 1572}, {"errors": 0.12023984537345168, "time-step": 1573}, {"errors": 0.12022995544725434, "time-step": 1574}, {"errors": 0.12022004557956165, "time-step": 1575}, {"errors": 0.12021011573698664, "time-step": 1576}, {"errors": 0.12020016588613111, "time-step": 1577}, {"errors": 0.12019019599358591, "time-step": 1578}, {"errors": 0.12018020602593124, "time-step": 1579}, {"errors": 0.12017019594973695, "time-step": 1580}, {"errors": 0.12016016573156296, "time-step": 1581}, {"errors": 0.12015011533795952, "time-step": 1582}, {"errors": 0.12014004473546766, "time-step": 1583}, {"errors": 0.12012995389061928, "time-step": 1584}, {"errors": 0.12011984276993791, "time-step": 1585}, {"errors": 0.12010971133993856, "time-step": 1586}, {"errors": 0.12009955956712848, "time-step": 1587}, {"errors": 0.12008938741800732, "time-step": 1588}, {"errors": 0.12007919485906746, "time-step": 1589}, {"errors": 0.12006898185679446, "time-step": 1590}, {"errors": 0.12005874837766738, "time-step": 1591}, {"errors": 0.12004849438815918, "time-step": 1592}, {"errors": 0.12003821985473694, "time-step": 1593}, {"errors": 0.1200279247438624, "time-step": 1594}, {"errors": 0.1200176090219923, "time-step": 1595}, {"errors": 0.12000727265557859, "time-step": 1596}, {"errors": 0.11999691561106904, "time-step": 1597}, {"errors": 0.11998653785490755, "time-step": 1598}, {"errors": 0.11997613935353427, "time-step": 1599}, {"errors": 0.11996572007338638, "time-step": 1600}, {"errors": 0.11995527998089828, "time-step": 1601}, {"errors": 0.1199448190425019, "time-step": 1602}, {"errors": 0.11993433722462726, "time-step": 1603}, {"errors": 0.11992383449370281, "time-step": 1604}, {"errors": 0.1199133108161557, "time-step": 1605}, {"errors": 0.11990276615841233, "time-step": 1606}, {"errors": 0.11989220048689876, "time-step": 1607}, {"errors": 0.11988161376804096, "time-step": 1608}, {"errors": 0.11987100596826541, "time-step": 1609}, {"errors": 0.11986037705399934, "time-step": 1610}, {"errors": 0.11984972699167128, "time-step": 1611}, {"errors": 0.11983905574771135, "time-step": 1612}, {"errors": 0.11982836328855179, "time-step": 1613}, {"errors": 0.1198176495806273, "time-step": 1614}, {"errors": 0.11980691459037557, "time-step": 1615}, {"errors": 0.11979615828423752, "time-step": 1616}, {"errors": 0.11978538062865793, "time-step": 1617}, {"errors": 0.1197745815900858, "time-step": 1618}, {"errors": 0.11976376113497471, "time-step": 1619}, {"errors": 0.11975291922978334, "time-step": 1620}, {"errors": 0.11974205584097596, "time-step": 1621}, {"errors": 0.1197311709350227, "time-step": 1622}, {"errors": 0.11972026447840015, "time-step": 1623}, {"errors": 0.11970933643759178, "time-step": 1624}, {"errors": 0.11969838677908838, "time-step": 1625}, {"errors": 0.11968741546938853, "time-step": 1626}, {"errors": 0.11967642247499896, "time-step": 1627}, {"errors": 0.1196654077624352, "time-step": 1628}, {"errors": 0.11965437129822183, "time-step": 1629}, {"errors": 0.11964331304889309, "time-step": 1630}, {"errors": 0.1196322329809934, "time-step": 1631}, {"errors": 0.11962113106107766, "time-step": 1632}, {"errors": 0.11961000725571183, "time-step": 1633}, {"errors": 0.1195988615314734, "time-step": 1634}, {"errors": 0.1195876938549518, "time-step": 1635}, {"errors": 0.11957650419274915, "time-step": 1636}, {"errors": 0.11956529251148039, "time-step": 1637}, {"errors": 0.11955405877777386, "time-step": 1638}, {"errors": 0.1195428029582721, "time-step": 1639}, {"errors": 0.1195315250196319, "time-step": 1640}, {"errors": 0.11952022492852507, "time-step": 1641}, {"errors": 0.11950890265163899, "time-step": 1642}, {"errors": 0.11949755815567689, "time-step": 1643}, {"errors": 0.1194861914073585, "time-step": 1644}, {"errors": 0.11947480237342062, "time-step": 1645}, {"errors": 0.11946339102061748, "time-step": 1646}, {"errors": 0.11945195731572134, "time-step": 1647}, {"errors": 0.1194405012255231, "time-step": 1648}, {"errors": 0.11942902271683262, "time-step": 1649}, {"errors": 0.11941752175647935, "time-step": 1650}, {"errors": 0.11940599831131311, "time-step": 1651}, {"errors": 0.11939445234820403, "time-step": 1652}, {"errors": 0.11938288383404372, "time-step": 1653}, {"errors": 0.1193712927357454, "time-step": 1654}, {"errors": 0.11935967902024464, "time-step": 1655}, {"errors": 0.11934804265449979, "time-step": 1656}, {"errors": 0.11933638360549254, "time-step": 1657}, {"errors": 0.11932470184022873, "time-step": 1658}, {"errors": 0.11931299732573838, "time-step": 1659}, {"errors": 0.11930127002907684, "time-step": 1660}, {"errors": 0.11928951991732485, "time-step": 1661}, {"errors": 0.11927774695758947, "time-step": 1662}, {"errors": 0.1192659511170044, "time-step": 1663}, {"errors": 0.11925413236273072, "time-step": 1664}, {"errors": 0.1192422906619574, "time-step": 1665}, {"errors": 0.11923042598190185, "time-step": 1666}, {"errors": 0.11921853828981047, "time-step": 1667}, {"errors": 0.11920662755295938, "time-step": 1668}, {"errors": 0.1191946937386549, "time-step": 1669}, {"errors": 0.11918273681423412, "time-step": 1670}, {"errors": 0.11917075674706547, "time-step": 1671}, {"errors": 0.11915875350454957, "time-step": 1672}, {"errors": 0.11914672705411938, "time-step": 1673}, {"errors": 0.11913467736324125, "time-step": 1674}, {"errors": 0.11912260439941522, "time-step": 1675}, {"errors": 0.11911050813017579, "time-step": 1676}, {"errors": 0.11909838852309254, "time-step": 1677}, {"errors": 0.1190862455457705, "time-step": 1678}, {"errors": 0.11907407916585117, "time-step": 1679}, {"errors": 0.11906188935101272, "time-step": 1680}, {"errors": 0.11904967606897107, "time-step": 1681}, {"errors": 0.11903743928747995, "time-step": 1682}, {"errors": 0.11902517897433218, "time-step": 1683}, {"errors": 0.11901289509735972, "time-step": 1684}, {"errors": 0.1190005876244347, "time-step": 1685}, {"errors": 0.11898825652346985, "time-step": 1686}, {"errors": 0.11897590176241926, "time-step": 1687}, {"errors": 0.11896352330927892, "time-step": 1688}, {"errors": 0.11895112113208753, "time-step": 1689}, {"errors": 0.11893869519892697, "time-step": 1690}, {"errors": 0.11892624547792302, "time-step": 1691}, {"errors": 0.11891377193724614, "time-step": 1692}, {"errors": 0.11890127454511193, "time-step": 1693}, {"errors": 0.11888875326978196, "time-step": 1694}, {"errors": 0.11887620807956434, "time-step": 1695}, {"errors": 0.11886363894281443, "time-step": 1696}, {"errors": 0.11885104582793554, "time-step": 1697}, {"errors": 0.1188384287033796, "time-step": 1698}, {"errors": 0.11882578753764775, "time-step": 1699}, {"errors": 0.1188131222992911, "time-step": 1700}, {"errors": 0.11880043295691146, "time-step": 1701}, {"errors": 0.11878771947916206, "time-step": 1702}, {"errors": 0.118774981834748, "time-step": 1703}, {"errors": 0.11876221999242714, "time-step": 1704}, {"errors": 0.11874943392101098, "time-step": 1705}, {"errors": 0.11873662358936493, "time-step": 1706}, {"errors": 0.11872378896640928, "time-step": 1707}, {"errors": 0.11871093002112004, "time-step": 1708}, {"errors": 0.11869804672252926, "time-step": 1709}, {"errors": 0.1186851390397262, "time-step": 1710}, {"errors": 0.11867220694185765, "time-step": 1711}, {"errors": 0.11865925039812891, "time-step": 1712}, {"errors": 0.11864626937780434, "time-step": 1713}, {"errors": 0.11863326385020834, "time-step": 1714}, {"errors": 0.11862023378472575, "time-step": 1715}, {"errors": 0.1186071791508029, "time-step": 1716}, {"errors": 0.11859409991794806, "time-step": 1717}, {"errors": 0.11858099605573248, "time-step": 1718}, {"errors": 0.11856786753379084, "time-step": 1719}, {"errors": 0.11855471432182214, "time-step": 1720}, {"errors": 0.11854153638959056, "time-step": 1721}, {"errors": 0.11852833370692596, "time-step": 1722}, {"errors": 0.11851510624372491, "time-step": 1723}, {"errors": 0.11850185396995117, "time-step": 1724}, {"errors": 0.11848857685563663, "time-step": 1725}, {"errors": 0.11847527487088211, "time-step": 1726}, {"errors": 0.11846194798585798, "time-step": 1727}, {"errors": 0.11844859617080498, "time-step": 1728}, {"errors": 0.11843521939603513, "time-step": 1729}, {"errors": 0.11842181763193228, "time-step": 1730}, {"errors": 0.11840839084895308, "time-step": 1731}, {"errors": 0.1183949390176277, "time-step": 1732}, {"errors": 0.11838146210856042, "time-step": 1733}, {"errors": 0.11836796009243084, "time-step": 1734}, {"errors": 0.11835443293999437, "time-step": 1735}, {"errors": 0.118340880622083, "time-step": 1736}, {"errors": 0.11832730310960622, "time-step": 1737}, {"errors": 0.1183137003735518, "time-step": 1738}, {"errors": 0.11830007238498663, "time-step": 1739}, {"errors": 0.11828641911505738, "time-step": 1740}, {"errors": 0.11827274053499143, "time-step": 1741}, {"errors": 0.11825903661609768, "time-step": 1742}, {"errors": 0.11824530732976729, "time-step": 1743}, {"errors": 0.11823155264747463, "time-step": 1744}, {"errors": 0.11821777254077795, "time-step": 1745}, {"errors": 0.1182039669813202, "time-step": 1746}, {"errors": 0.11819013594083011, "time-step": 1747}, {"errors": 0.11817627939112262, "time-step": 1748}, {"errors": 0.11816239730410008, "time-step": 1749}, {"errors": 0.1181484896517529, "time-step": 1750}, {"errors": 0.1181345564061603, "time-step": 1751}, {"errors": 0.11812059753949139, "time-step": 1752}, {"errors": 0.11810661302400582, "time-step": 1753}, {"errors": 0.1180926028320547, "time-step": 1754}, {"errors": 0.11807856693608144, "time-step": 1755}, {"errors": 0.11806450530862259, "time-step": 1756}, {"errors": 0.11805041792230872, "time-step": 1757}, {"errors": 0.11803630474986518, "time-step": 1758}, {"errors": 0.11802216576411315, "time-step": 1759}, {"errors": 0.11800800093797027, "time-step": 1760}, {"errors": 0.11799381024445163, "time-step": 1761}, {"errors": 0.1179795936566707, "time-step": 1762}, {"errors": 0.11796535114783999, "time-step": 1763}, {"errors": 0.11795108269127211, "time-step": 1764}, {"errors": 0.11793678826038065, "time-step": 1765}, {"errors": 0.11792246782868085, "time-step": 1766}, {"errors": 0.11790812136979066, "time-step": 1767}, {"errors": 0.11789374885743166, "time-step": 1768}, {"errors": 0.1178793502654297, "time-step": 1769}, {"errors": 0.11786492556771608, "time-step": 1770}, {"errors": 0.11785047473832812, "time-step": 1771}, {"errors": 0.11783599775141047, "time-step": 1772}, {"errors": 0.11782149458121552, "time-step": 1773}, {"errors": 0.11780696520210468, "time-step": 1774}, {"errors": 0.11779240958854909, "time-step": 1775}, {"errors": 0.11777782771513054, "time-step": 1776}, {"errors": 0.11776321955654231, "time-step": 1777}, {"errors": 0.11774858508759031, "time-step": 1778}, {"errors": 0.1177339242831937, "time-step": 1779}, {"errors": 0.11771923711838603, "time-step": 1780}, {"errors": 0.1177045235683159, "time-step": 1781}, {"errors": 0.11768978360824814, "time-step": 1782}, {"errors": 0.11767501721356445, "time-step": 1783}, {"errors": 0.11766022435976467, "time-step": 1784}, {"errors": 0.11764540502246731, "time-step": 1785}, {"errors": 0.11763055917741069, "time-step": 1786}, {"errors": 0.1176156868004539, "time-step": 1787}, {"errors": 0.11760078786757758, "time-step": 1788}, {"errors": 0.11758586235488486, "time-step": 1789}, {"errors": 0.11757091023860243, "time-step": 1790}, {"errors": 0.1175559314950813, "time-step": 1791}, {"errors": 0.11754092610079792, "time-step": 1792}, {"errors": 0.11752589403235483, "time-step": 1793}, {"errors": 0.11751083526648193, "time-step": 1794}, {"errors": 0.11749574978003717, "time-step": 1795}, {"errors": 0.11748063755000754, "time-step": 1796}, {"errors": 0.1174654985535101, "time-step": 1797}, {"errors": 0.11745033276779288, "time-step": 1798}, {"errors": 0.11743514017023562, "time-step": 1799}, {"errors": 0.11741992073835122, "time-step": 1800}, {"errors": 0.11740467444978608, "time-step": 1801}, {"errors": 0.11738940128232142, "time-step": 1802}, {"errors": 0.11737410121387422, "time-step": 1803}, {"errors": 0.11735877422249802, "time-step": 1804}, {"errors": 0.11734342028638389, "time-step": 1805}, {"errors": 0.1173280393838616, "time-step": 1806}, {"errors": 0.11731263149340022, "time-step": 1807}, {"errors": 0.1172971965936094, "time-step": 1808}, {"errors": 0.11728173466324021, "time-step": 1809}, {"errors": 0.11726624568118596, "time-step": 1810}, {"errors": 0.11725072962648342, "time-step": 1811}, {"errors": 0.1172351864783136, "time-step": 1812}, {"errors": 0.11721961621600271, "time-step": 1813}, {"errors": 0.11720401881902323, "time-step": 1814}, {"errors": 0.11718839426699486, "time-step": 1815}, {"errors": 0.11717274253968529, "time-step": 1816}, {"errors": 0.1171570636170115, "time-step": 1817}, {"errors": 0.11714135747904045, "time-step": 1818}, {"errors": 0.11712562410599023, "time-step": 1819}, {"errors": 0.11710986347823077, "time-step": 1820}, {"errors": 0.11709407557628522, "time-step": 1821}, {"errors": 0.11707826038083055, "time-step": 1822}, {"errors": 0.11706241787269869, "time-step": 1823}, {"errors": 0.11704654803287745, "time-step": 1824}, {"errors": 0.1170306508425116, "time-step": 1825}, {"errors": 0.11701472628290369, "time-step": 1826}, {"errors": 0.11699877433551513, "time-step": 1827}, {"errors": 0.11698279498196709, "time-step": 1828}, {"errors": 0.11696678820404163, "time-step": 1829}, {"errors": 0.11695075398368249, "time-step": 1830}, {"errors": 0.11693469230299611, "time-step": 1831}, {"errors": 0.1169186031442527, "time-step": 1832}, {"errors": 0.11690248648988719, "time-step": 1833}, {"errors": 0.11688634232250011, "time-step": 1834}, {"errors": 0.11687017062485863, "time-step": 1835}, {"errors": 0.11685397137989773, "time-step": 1836}, {"errors": 0.11683774457072071, "time-step": 1837}, {"errors": 0.11682149018060067, "time-step": 1838}, {"errors": 0.11680520819298121, "time-step": 1839}, {"errors": 0.11678889859147748, "time-step": 1840}, {"errors": 0.11677256135987714, "time-step": 1841}, {"errors": 0.11675619648214135, "time-step": 1842}, {"errors": 0.11673980394240585, "time-step": 1843}, {"errors": 0.11672338372498173, "time-step": 1844}, {"errors": 0.11670693581435648, "time-step": 1845}, {"errors": 0.1166904601951953, "time-step": 1846}, {"errors": 0.11667395685234147, "time-step": 1847}, {"errors": 0.11665742577081778, "time-step": 1848}, {"errors": 0.11664086693582744, "time-step": 1849}, {"errors": 0.1166242803327549, "time-step": 1850}, {"errors": 0.11660766594716704, "time-step": 1851}, {"errors": 0.11659102376481387, "time-step": 1852}, {"errors": 0.11657435377162986, "time-step": 1853}, {"errors": 0.1165576559537346, "time-step": 1854}, {"errors": 0.11654093029743394, "time-step": 1855}, {"errors": 0.11652417678922097, "time-step": 1856}, {"errors": 0.1165073954157769, "time-step": 1857}, {"errors": 0.11649058616397209, "time-step": 1858}, {"errors": 0.11647374902086709, "time-step": 1859}, {"errors": 0.11645688397371345, "time-step": 1860}, {"errors": 0.11643999100995484, "time-step": 1861}, {"errors": 0.11642307011722791, "time-step": 1862}, {"errors": 0.11640612128336342, "time-step": 1863}, {"errors": 0.11638914449638699, "time-step": 1864}, {"errors": 0.11637213974452026, "time-step": 1865}, {"errors": 0.11635510701618176, "time-step": 1866}, {"errors": 0.11633804629998776, "time-step": 1867}, {"errors": 0.11632095758475361, "time-step": 1868}, {"errors": 0.11630384085949425, "time-step": 1869}, {"errors": 0.11628669611342538, "time-step": 1870}, {"errors": 0.11626952333596458, "time-step": 1871}, {"errors": 0.1162523225167319, "time-step": 1872}, {"errors": 0.11623509364555121, "time-step": 1873}, {"errors": 0.11621783671245081, "time-step": 1874}, {"errors": 0.11620055170766458, "time-step": 1875}, {"errors": 0.11618323862163296, "time-step": 1876}, {"errors": 0.11616589744500377, "time-step": 1877}, {"errors": 0.11614852816863314, "time-step": 1878}, {"errors": 0.11613113078358664, "time-step": 1879}, {"errors": 0.11611370528114015, "time-step": 1880}, {"errors": 0.11609625165278062, "time-step": 1881}, {"errors": 0.11607876989020723, "time-step": 1882}, {"errors": 0.11606125998533229, "time-step": 1883}, {"errors": 0.11604372193028209, "time-step": 1884}, {"errors": 0.1160261557173979, "time-step": 1885}, {"errors": 0.11600856133923691, "time-step": 1886}, {"errors": 0.11599093878857311, "time-step": 1887}, {"errors": 0.11597328805839822, "time-step": 1888}, {"errors": 0.11595560914192268, "time-step": 1889}, {"errors": 0.11593790203257648, "time-step": 1890}, {"errors": 0.11592016672401016, "time-step": 1891}, {"errors": 0.11590240321009565, "time-step": 1892}, {"errors": 0.11588461148492732, "time-step": 1893}, {"errors": 0.11586679154282273, "time-step": 1894}, {"errors": 0.1158489433783235, "time-step": 1895}, {"errors": 0.11583106698619655, "time-step": 1896}, {"errors": 0.1158131623614346, "time-step": 1897}, {"errors": 0.11579522949925725, "time-step": 1898}, {"errors": 0.11577726839511204, "time-step": 1899}, {"errors": 0.11575927904467495, "time-step": 1900}, {"errors": 0.1157412614438516, "time-step": 1901}, {"errors": 0.11572321558877813, "time-step": 1902}, {"errors": 0.11570514147582187, "time-step": 1903}, {"errors": 0.11568703910158243, "time-step": 1904}, {"errors": 0.11566890846289249, "time-step": 1905}, {"errors": 0.11565074955681873, "time-step": 1906}, {"errors": 0.11563256238066252, "time-step": 1907}, {"errors": 0.1156143469319611, "time-step": 1908}, {"errors": 0.11559610320848812, "time-step": 1909}, {"errors": 0.11557783120825471, "time-step": 1910}, {"errors": 0.11555953092951027, "time-step": 1911}, {"errors": 0.11554120237074325, "time-step": 1912}, {"errors": 0.11552284553068223, "time-step": 1913}, {"errors": 0.11550446040829643, "time-step": 1914}, {"errors": 0.1154860470027968, "time-step": 1915}, {"errors": 0.11546760531363673, "time-step": 1916}, {"errors": 0.11544913534051307, "time-step": 1917}, {"errors": 0.11543063708336662, "time-step": 1918}, {"errors": 0.11541211054238332, "time-step": 1919}, {"errors": 0.11539355571799471, "time-step": 1920}, {"errors": 0.11537497261087916, "time-step": 1921}, {"errors": 0.11535636122196227, "time-step": 1922}, {"errors": 0.11533772155241798, "time-step": 1923}, {"errors": 0.1153190536036691, "time-step": 1924}, {"errors": 0.11530035737738839, "time-step": 1925}, {"errors": 0.11528163287549922, "time-step": 1926}, {"errors": 0.11526288010017627, "time-step": 1927}, {"errors": 0.11524409905384642, "time-step": 1928}, {"errors": 0.11522528973918952, "time-step": 1929}, {"errors": 0.11520645215913916, "time-step": 1930}, {"errors": 0.11518758631688336, "time-step": 1931}, {"errors": 0.11516869221586543, "time-step": 1932}, {"errors": 0.1151497698597847, "time-step": 1933}, {"errors": 0.11513081925259723, "time-step": 1934}, {"errors": 0.11511184039851666, "time-step": 1935}, {"errors": 0.1150928333020147, "time-step": 1936}, {"errors": 0.11507379796782226, "time-step": 1937}, {"errors": 0.11505473440092986, "time-step": 1938}, {"errors": 0.11503564260658838, "time-step": 1939}, {"errors": 0.11501652259031003, "time-step": 1940}, {"errors": 0.11499737435786875, "time-step": 1941}, {"errors": 0.11497819791530112, "time-step": 1942}, {"errors": 0.11495899326890695, "time-step": 1943}, {"errors": 0.11493976042525006, "time-step": 1944}, {"errors": 0.11492049939115892, "time-step": 1945}, {"errors": 0.11490121017372738, "time-step": 1946}, {"errors": 0.11488189278031521, "time-step": 1947}, {"errors": 0.1148625472185491, "time-step": 1948}, {"errors": 0.11484317349632278, "time-step": 1949}, {"errors": 0.11482377162179824, "time-step": 1950}, {"errors": 0.11480434160340611, "time-step": 1951}, {"errors": 0.11478488344984628, "time-step": 1952}, {"errors": 0.11476539717008866, "time-step": 1953}, {"errors": 0.1147458827733736, "time-step": 1954}, {"errors": 0.11472634026921294, "time-step": 1955}, {"errors": 0.11470676966739016, "time-step": 1956}, {"errors": 0.11468717097796115, "time-step": 1957}, {"errors": 0.1146675442112551, "time-step": 1958}, {"errors": 0.11464788937787468, "time-step": 1959}, {"errors": 0.11462820648869682, "time-step": 1960}, {"errors": 0.11460849555487336, "time-step": 1961}, {"errors": 0.11458875658783152, "time-step": 1962}, {"errors": 0.1145689895992745, "time-step": 1963}, {"errors": 0.11454919460118215, "time-step": 1964}, {"errors": 0.11452937160581128, "time-step": 1965}, {"errors": 0.11450952062569653, "time-step": 1966}, {"errors": 0.11448964167365064, "time-step": 1967}, {"errors": 0.11446973476276509, "time-step": 1968}, {"errors": 0.1144497999064108, "time-step": 1969}, {"errors": 0.11442983711823826, "time-step": 1970}, {"errors": 0.11440984641217841, "time-step": 1971}, {"errors": 0.11438982780244299, "time-step": 1972}, {"errors": 0.11436978130352501, "time-step": 1973}, {"errors": 0.11434970693019933, "time-step": 1974}, {"errors": 0.11432960469752312, "time-step": 1975}, {"errors": 0.11430947462083621, "time-step": 1976}, {"errors": 0.11428931671576179, "time-step": 1977}, {"errors": 0.1142691309982066, "time-step": 1978}, {"errors": 0.11424891748436164, "time-step": 1979}, {"errors": 0.11422867619070248, "time-step": 1980}, {"errors": 0.11420840713398965, "time-step": 1981}, {"errors": 0.11418811033126916, "time-step": 1982}, {"errors": 0.1141677857998729, "time-step": 1983}, {"errors": 0.11414743355741896, "time-step": 1984}, {"errors": 0.11412705362181223, "time-step": 1985}, {"errors": 0.11410664601124457, "time-step": 1986}, {"errors": 0.11408621074419531, "time-step": 1987}, {"errors": 0.11406574783943163, "time-step": 1988}, {"errors": 0.11404525731600895, "time-step": 1989}, {"errors": 0.11402473919327114, "time-step": 1990}, {"errors": 0.1140041934908511, "time-step": 1991}, {"errors": 0.11398362022867088, "time-step": 1992}, {"errors": 0.11396301942694217, "time-step": 1993}, {"errors": 0.11394239110616654, "time-step": 1994}, {"errors": 0.11392173528713576, "time-step": 1995}, {"errors": 0.1139010519909322, "time-step": 1996}, {"errors": 0.11388034123892901, "time-step": 1997}, {"errors": 0.11385960305279043, "time-step": 1998}, {"errors": 0.11383883745447218, "time-step": 1999}, {"errors": 0.11381804446622155, "time-step": 2000}, {"errors": 0.11379722411057774, "time-step": 2001}, {"errors": 0.1137763764103722, "time-step": 2002}, {"errors": 0.11375550138872875, "time-step": 2003}, {"errors": 0.11373459906906394, "time-step": 2004}, {"errors": 0.11371366947508699, "time-step": 2005}, {"errors": 0.11369271263080044, "time-step": 2006}, {"errors": 0.11367172856050001, "time-step": 2007}, {"errors": 0.11365071728877482, "time-step": 2008}, {"errors": 0.11362967884050783, "time-step": 2009}, {"errors": 0.11360861324087573, "time-step": 2010}, {"errors": 0.11358752051534923, "time-step": 2011}, {"errors": 0.11356640068969324, "time-step": 2012}, {"errors": 0.113545253789967, "time-step": 2013}, {"errors": 0.11352407984252409, "time-step": 2014}, {"errors": 0.11350287887401278, "time-step": 2015}, {"errors": 0.11348165091137594, "time-step": 2016}, {"errors": 0.11346039598185134, "time-step": 2017}, {"errors": 0.1134391141129715, "time-step": 2018}, {"errors": 0.1134178053325641, "time-step": 2019}, {"errors": 0.11339646966875169, "time-step": 2020}, {"errors": 0.11337510714995205, "time-step": 2021}, {"errors": 0.11335371780487812, "time-step": 2022}, {"errors": 0.11333230166253803, "time-step": 2023}, {"errors": 0.11331085875223526, "time-step": 2024}, {"errors": 0.11328938910356838, "time-step": 2025}, {"errors": 0.11326789274643147, "time-step": 2026}, {"errors": 0.11324636971101378, "time-step": 2027}, {"errors": 0.11322482002779996, "time-step": 2028}, {"errors": 0.11320324372756978, "time-step": 2029}, {"errors": 0.11318164084139841, "time-step": 2030}, {"errors": 0.11316001140065618, "time-step": 2031}, {"errors": 0.11313835543700859, "time-step": 2032}, {"errors": 0.1131166729824162, "time-step": 2033}, {"errors": 0.11309496406913466, "time-step": 2034}, {"errors": 0.11307322872971465, "time-step": 2035}, {"errors": 0.11305146699700153, "time-step": 2036}, {"errors": 0.11302967890413557, "time-step": 2037}, {"errors": 0.11300786448455169, "time-step": 2038}, {"errors": 0.11298602377197928, "time-step": 2039}, {"errors": 0.11296415680044206, "time-step": 2040}, {"errors": 0.11294226360425824, "time-step": 2041}, {"errors": 0.11292034421803986, "time-step": 2042}, {"errors": 0.11289839867669305, "time-step": 2043}, {"errors": 0.11287642701541771, "time-step": 2044}, {"errors": 0.11285442926970712, "time-step": 2045}, {"errors": 0.11283240547534819, "time-step": 2046}, {"errors": 0.11281035566842072, "time-step": 2047}, {"errors": 0.1127882798852976, "time-step": 2048}, {"errors": 0.11276617816264443, "time-step": 2049}, {"errors": 0.11274405053741918, "time-step": 2050}, {"errors": 0.11272189704687208, "time-step": 2051}, {"errors": 0.11269971772854526, "time-step": 2052}, {"errors": 0.11267751262027262, "time-step": 2053}, {"errors": 0.11265528176017922, "time-step": 2054}, {"errors": 0.11263302518668139, "time-step": 2055}, {"errors": 0.11261074293848615, "time-step": 2056}, {"errors": 0.11258843505459093, "time-step": 2057}, {"errors": 0.11256610157428329, "time-step": 2058}, {"errors": 0.11254374253714063, "time-step": 2059}, {"errors": 0.11252135798302966, "time-step": 2060}, {"errors": 0.11249894795210613, "time-step": 2061}, {"errors": 0.11247651248481452, "time-step": 2062}, {"errors": 0.11245405162188754, "time-step": 2063}, {"errors": 0.11243156540434575, "time-step": 2064}, {"errors": 0.11240905387349728, "time-step": 2065}, {"errors": 0.11238651707093718, "time-step": 2066}, {"errors": 0.11236395503854715, "time-step": 2067}, {"errors": 0.11234136781849513, "time-step": 2068}, {"errors": 0.11231875545323455, "time-step": 2069}, {"errors": 0.11229611798550435, "time-step": 2070}, {"errors": 0.1122734554583279, "time-step": 2071}, {"errors": 0.11225076791501315, "time-step": 2072}, {"errors": 0.11222805539915164, "time-step": 2073}, {"errors": 0.1122053179546181, "time-step": 2074}, {"errors": 0.11218255562557017, "time-step": 2075}, {"errors": 0.11215976845644748, "time-step": 2076}, {"errors": 0.11213695649197143, "time-step": 2077}, {"errors": 0.11211411977714439, "time-step": 2078}, {"errors": 0.11209125835724928, "time-step": 2079}, {"errors": 0.11206837227784894, "time-step": 2080}, {"errors": 0.11204546158478558, "time-step": 2081}, {"errors": 0.11202252632417997, "time-step": 2082}, {"errors": 0.11199956654243115, "time-step": 2083}, {"errors": 0.11197658228621557, "time-step": 2084}, {"errors": 0.11195357360248653, "time-step": 2085}, {"errors": 0.11193054053847346, "time-step": 2086}, {"errors": 0.11190748314168139, "time-step": 2087}, {"errors": 0.11188440145989013, "time-step": 2088}, {"errors": 0.11186129554115368, "time-step": 2089}, {"errors": 0.11183816543379949, "time-step": 2090}, {"errors": 0.11181501118642774, "time-step": 2091}, {"errors": 0.11179183284791078, "time-step": 2092}, {"errors": 0.11176863046739208, "time-step": 2093}, {"errors": 0.11174540409428571, "time-step": 2094}, {"errors": 0.11172215377827577, "time-step": 2095}, {"errors": 0.11169887956931507, "time-step": 2096}, {"errors": 0.11167558151762494, "time-step": 2097}, {"errors": 0.11165225967369408, "time-step": 2098}, {"errors": 0.11162891408827792, "time-step": 2099}, {"errors": 0.1116055448123977, "time-step": 2100}, {"errors": 0.11158215189733978, "time-step": 2101}, {"errors": 0.11155873539465468, "time-step": 2102}, {"errors": 0.11153529535615639, "time-step": 2103}, {"errors": 0.11151183183392133, "time-step": 2104}, {"errors": 0.11148834488028767, "time-step": 2105}, {"errors": 0.11146483454785416, "time-step": 2106}, {"errors": 0.11144130088947973, "time-step": 2107}, {"errors": 0.11141774395828213, "time-step": 2108}, {"errors": 0.11139416380763714, "time-step": 2109}, {"errors": 0.11137056049117791, "time-step": 2110}, {"errors": 0.11134693406279353, "time-step": 2111}, {"errors": 0.11132328457662867, "time-step": 2112}, {"errors": 0.11129961208708217, "time-step": 2113}, {"errors": 0.1112759166488062, "time-step": 2114}, {"errors": 0.1112521983167055, "time-step": 2115}, {"errors": 0.11122845714593604, "time-step": 2116}, {"errors": 0.11120469319190426, "time-step": 2117}, {"errors": 0.11118090651026602, "time-step": 2118}, {"errors": 0.1111570971569256, "time-step": 2119}, {"errors": 0.11113326518803446, "time-step": 2120}, {"errors": 0.11110941065999058, "time-step": 2121}, {"errors": 0.11108553362943707, "time-step": 2122}, {"errors": 0.11106163415326126, "time-step": 2123}, {"errors": 0.11103771228859366, "time-step": 2124}, {"errors": 0.11101376809280673, "time-step": 2125}, {"errors": 0.11098980162351396, "time-step": 2126}, {"errors": 0.11096581293856858, "time-step": 2127}, {"errors": 0.11094180209606276, "time-step": 2128}, {"errors": 0.11091776915432602, "time-step": 2129}, {"errors": 0.11089371417192445, "time-step": 2130}, {"errors": 0.11086963720765958, "time-step": 2131}, {"errors": 0.11084553832056696, "time-step": 2132}, {"errors": 0.11082141756991515, "time-step": 2133}, {"errors": 0.11079727501520463, "time-step": 2134}, {"errors": 0.11077311071616648, "time-step": 2135}, {"errors": 0.11074892473276116, "time-step": 2136}, {"errors": 0.11072471712517742, "time-step": 2137}, {"errors": 0.11070048795383111, "time-step": 2138}, {"errors": 0.11067623727936372, "time-step": 2139}, {"errors": 0.11065196516264136, "time-step": 2140}, {"errors": 0.1106276716647536, "time-step": 2141}, {"errors": 0.11060335684701178, "time-step": 2142}, {"errors": 0.11057902077094822, "time-step": 2143}, {"errors": 0.11055466349831478, "time-step": 2144}, {"errors": 0.11053028509108145, "time-step": 2145}, {"errors": 0.11050588561143516, "time-step": 2146}, {"errors": 0.11048146512177853, "time-step": 2147}, {"errors": 0.1104570236847285, "time-step": 2148}, {"errors": 0.11043256136311494, "time-step": 2149}, {"errors": 0.11040807821997944, "time-step": 2150}, {"errors": 0.1103835743185739, "time-step": 2151}, {"errors": 0.11035904972235916, "time-step": 2152}, {"errors": 0.11033450449500369, "time-step": 2153}, {"errors": 0.11030993870038217, "time-step": 2154}, {"errors": 0.11028535240257423, "time-step": 2155}, {"errors": 0.11026074566586286, "time-step": 2156}, {"errors": 0.11023611855473321, "time-step": 2157}, {"errors": 0.11021147113387106, "time-step": 2158}, {"errors": 0.11018680346816144, "time-step": 2159}, {"errors": 0.11016211562268727, "time-step": 2160}, {"errors": 0.11013740766272778, "time-step": 2161}, {"errors": 0.11011267965375729, "time-step": 2162}, {"errors": 0.11008793166144355, "time-step": 2163}, {"errors": 0.11006316375164633, "time-step": 2164}, {"errors": 0.1100383759904161, "time-step": 2165}, {"errors": 0.11001356844399235, "time-step": 2166}, {"errors": 0.10998874117880224, "time-step": 2167}, {"errors": 0.10996389426145911, "time-step": 2168}, {"errors": 0.10993902775876083, "time-step": 2169}, {"errors": 0.10991414173768858, "time-step": 2170}, {"errors": 0.10988923626540502, "time-step": 2171}, {"errors": 0.10986431140925298, "time-step": 2172}, {"errors": 0.10983936723675379, "time-step": 2173}, {"errors": 0.1098144038156059, "time-step": 2174}, {"errors": 0.1097894212136832, "time-step": 2175}, {"errors": 0.10976441949903347, "time-step": 2176}, {"errors": 0.1097393987398769, "time-step": 2177}, {"errors": 0.10971435900460452, "time-step": 2178}, {"errors": 0.10968930036177649, "time-step": 2179}, {"errors": 0.10966422288012068, "time-step": 2180}, {"errors": 0.10963912662853095, "time-step": 2181}, {"errors": 0.10961401167606556, "time-step": 2182}, {"errors": 0.10958887809194584, "time-step": 2183}, {"errors": 0.10956372594555405, "time-step": 2184}, {"errors": 0.10953855530643229, "time-step": 2185}, {"errors": 0.10951336624428053, "time-step": 2186}, {"errors": 0.10948815882895507, "time-step": 2187}, {"errors": 0.10946293313046701, "time-step": 2188}, {"errors": 0.10943768921898037, "time-step": 2189}, {"errors": 0.10941242716481073, "time-step": 2190}, {"errors": 0.10938714703842337, "time-step": 2191}, {"errors": 0.10936184891043157, "time-step": 2192}, {"errors": 0.10933653285159513, "time-step": 2193}, {"errors": 0.10931119893281846, "time-step": 2194}, {"errors": 0.10928584722514913, "time-step": 2195}, {"errors": 0.1092604777997759, "time-step": 2196}, {"errors": 0.10923509072802745, "time-step": 2197}, {"errors": 0.10920968608137016, "time-step": 2198}, {"errors": 0.10918426393140672, "time-step": 2199}, {"errors": 0.10915882434987444, "time-step": 2200}, {"errors": 0.10913336740864321, "time-step": 2201}, {"errors": 0.10910789317971427, "time-step": 2202}, {"errors": 0.10908240173521805, "time-step": 2203}, {"errors": 0.10905689314741258, "time-step": 2204}, {"errors": 0.10903136748868186, "time-step": 2205}, {"errors": 0.10900582483153387, "time-step": 2206}, {"errors": 0.10898026524859904, "time-step": 2207}, {"errors": 0.10895468881262842, "time-step": 2208}, {"errors": 0.10892909559649183, "time-step": 2209}, {"errors": 0.10890348567317626, "time-step": 2210}, {"errors": 0.1088778591157839, "time-step": 2211}, {"errors": 0.1088522159975305, "time-step": 2212}, {"errors": 0.10882655639174357, "time-step": 2213}, {"errors": 0.10880088037186056, "time-step": 2214}, {"errors": 0.10877518801142716, "time-step": 2215}, {"errors": 0.10874947938409525, "time-step": 2216}, {"errors": 0.1087237545636214, "time-step": 2217}, {"errors": 0.10869801362386494, "time-step": 2218}, {"errors": 0.10867225663878613, "time-step": 2219}, {"errors": 0.1086464836824444, "time-step": 2220}, {"errors": 0.10862069482899644, "time-step": 2221}, {"errors": 0.10859489015269448, "time-step": 2222}, {"errors": 0.10856906972788442, "time-step": 2223}, {"errors": 0.10854323362900407, "time-step": 2224}, {"errors": 0.10851738193058116, "time-step": 2225}, {"errors": 0.1084915147072317, "time-step": 2226}, {"errors": 0.108465632033658, "time-step": 2227}, {"errors": 0.10843973398464686, "time-step": 2228}, {"errors": 0.1084138206350678, "time-step": 2229}, {"errors": 0.1083878920598711, "time-step": 2230}, {"errors": 0.108361948334086, "time-step": 2231}, {"errors": 0.10833598953281887, "time-step": 2232}, {"errors": 0.10831001573125137, "time-step": 2233}, {"errors": 0.10828402700463848, "time-step": 2234}, {"errors": 0.10825802342830679, "time-step": 2235}, {"errors": 0.10823200507765246, "time-step": 2236}, {"errors": 0.10820597202813952, "time-step": 2237}, {"errors": 0.10817992435529791, "time-step": 2238}, {"errors": 0.10815386213472164, "time-step": 2239}, {"errors": 0.10812778544206689, "time-step": 2240}, {"errors": 0.10810169435305009, "time-step": 2241}, {"errors": 0.1080755889434462, "time-step": 2242}, {"errors": 0.10804946928908671, "time-step": 2243}, {"errors": 0.10802333546585774, "time-step": 2244}, {"errors": 0.1079971875496982, "time-step": 2245}, {"errors": 0.10797102561659787, "time-step": 2246}, {"errors": 0.10794484974259562, "time-step": 2247}, {"errors": 0.1079186600037774, "time-step": 2248}, {"errors": 0.10789245647627435, "time-step": 2249}, {"errors": 0.10786623923626104, "time-step": 2250}, {"errors": 0.10784000835995343, "time-step": 2251}, {"errors": 0.10781376392360704, "time-step": 2252}, {"errors": 0.10778750600351514, "time-step": 2253}, {"errors": 0.1077612346760066, "time-step": 2254}, {"errors": 0.10773495001744433, "time-step": 2255}, {"errors": 0.10770865210422303, "time-step": 2256}, {"errors": 0.10768234101276768, "time-step": 2257}, {"errors": 0.10765601681953131, "time-step": 2258}, {"errors": 0.10762967960099329, "time-step": 2259}, {"errors": 0.10760332943365736, "time-step": 2260}, {"errors": 0.10757696639404965, "time-step": 2261}, {"errors": 0.10755059055871703, "time-step": 2262}, {"errors": 0.107524202004225, "time-step": 2263}, {"errors": 0.10749780080715576, "time-step": 2264}, {"errors": 0.10747138704410646, "time-step": 2265}, {"errors": 0.10744496079168733, "time-step": 2266}, {"errors": 0.10741852212651944, "time-step": 2267}, {"errors": 0.10739207112523337, "time-step": 2268}, {"errors": 0.1073656078644667, "time-step": 2269}, {"errors": 0.1073391324208626, "time-step": 2270}, {"errors": 0.10731264487106759, "time-step": 2271}, {"errors": 0.10728614529173001, "time-step": 2272}, {"errors": 0.10725963375949765, "time-step": 2273}, {"errors": 0.10723311035101621, "time-step": 2274}, {"errors": 0.10720657514292739, "time-step": 2275}, {"errors": 0.10718002821186678, "time-step": 2276}, {"errors": 0.10715346963446222, "time-step": 2277}, {"errors": 0.1071268994873317, "time-step": 2278}, {"errors": 0.10710031784708168, "time-step": 2279}, {"errors": 0.10707372479030487, "time-step": 2280}, {"errors": 0.10704712039357886, "time-step": 2281}, {"errors": 0.10702050473346364, "time-step": 2282}, {"errors": 0.10699387788650021, "time-step": 2283}, {"errors": 0.10696723992920851, "time-step": 2284}, {"errors": 0.10694059093808536, "time-step": 2285}, {"errors": 0.10691393098960295, "time-step": 2286}, {"errors": 0.10688726016020662, "time-step": 2287}, {"errors": 0.10686057852631327, "time-step": 2288}, {"errors": 0.10683388616430922, "time-step": 2289}, {"errors": 0.10680718315054863, "time-step": 2290}, {"errors": 0.10678046956135132, "time-step": 2291}, {"errors": 0.10675374547300118, "time-step": 2292}, {"errors": 0.10672701096174422, "time-step": 2293}, {"errors": 0.10670026610378655, "time-step": 2294}, {"errors": 0.10667351097529282, "time-step": 2295}, {"errors": 0.10664674565238408, "time-step": 2296}, {"errors": 0.10661997021113613, "time-step": 2297}, {"errors": 0.10659318472757759, "time-step": 2298}, {"errors": 0.10656638927768804, "time-step": 2299}, {"errors": 0.10653958393739621, "time-step": 2300}, {"errors": 0.10651276878257815, "time-step": 2301}, {"errors": 0.10648594388905541, "time-step": 2302}, {"errors": 0.10645910933259306, "time-step": 2303}, {"errors": 0.10643226518889812, "time-step": 2304}, {"errors": 0.10640541153361743, "time-step": 2305}, {"errors": 0.10637854844233618, "time-step": 2306}, {"errors": 0.10635167599057582, "time-step": 2307}, {"errors": 0.10632479425379227, "time-step": 2308}, {"errors": 0.10629790330737418, "time-step": 2309}, {"errors": 0.10627100322664124, "time-step": 2310}, {"errors": 0.10624409408684204, "time-step": 2311}, {"errors": 0.10621717596315267, "time-step": 2312}, {"errors": 0.10619024893067461, "time-step": 2313}, {"errors": 0.10616331306443308, "time-step": 2314}, {"errors": 0.10613636843937535, "time-step": 2315}, {"errors": 0.10610941513036862, "time-step": 2316}, {"errors": 0.1060824532121987, "time-step": 2317}, {"errors": 0.1060554827595678, "time-step": 2318}, {"errors": 0.10602850384709311, "time-step": 2319}, {"errors": 0.10600151654930479, "time-step": 2320}, {"errors": 0.10597452094064434, "time-step": 2321}, {"errors": 0.10594751709546285, "time-step": 2322}, {"errors": 0.10592050508801912, "time-step": 2323}, {"errors": 0.10589348499247814, "time-step": 2324}, {"errors": 0.105866456882909, "time-step": 2325}, {"errors": 0.10583942083328357, "time-step": 2326}, {"errors": 0.10581237691747444, "time-step": 2327}, {"errors": 0.10578532520925346, "time-step": 2328}, {"errors": 0.10575826578228961, "time-step": 2329}, {"errors": 0.10573119871014786, "time-step": 2330}, {"errors": 0.1057041240662869, "time-step": 2331}, {"errors": 0.10567704192405789, "time-step": 2332}, {"errors": 0.10564995235670235, "time-step": 2333}, {"errors": 0.1056228554373509, "time-step": 2334}, {"errors": 0.10559575123902105, "time-step": 2335}, {"errors": 0.10556863983461615, "time-step": 2336}, {"errors": 0.10554152129692315, "time-step": 2337}, {"errors": 0.1055143956986111, "time-step": 2338}, {"errors": 0.1054872631122297, "time-step": 2339}, {"errors": 0.10546012361020736, "time-step": 2340}, {"errors": 0.10543297726484974, "time-step": 2341}, {"errors": 0.1054058241483379, "time-step": 2342}, {"errors": 0.10537866433272688, "time-step": 2343}, {"errors": 0.1053514978899439, "time-step": 2344}, {"errors": 0.10532432489178686, "time-step": 2345}, {"errors": 0.10529714540992244, "time-step": 2346}, {"errors": 0.105269959515885, "time-step": 2347}, {"errors": 0.10524276728107437, "time-step": 2348}, {"errors": 0.10521556877675467, "time-step": 2349}, {"errors": 0.10518836407405258, "time-step": 2350}, {"errors": 0.1051611532439555, "time-step": 2351}, {"errors": 0.10513393635731061, "time-step": 2352}, {"errors": 0.10510671348482245, "time-step": 2353}, {"errors": 0.10507948469705206, "time-step": 2354}, {"errors": 0.10505225006441499, "time-step": 2355}, {"errors": 0.1050250096571799, "time-step": 2356}, {"errors": 0.10499776354546697, "time-step": 2357}, {"errors": 0.10497051179924642, "time-step": 2358}, {"errors": 0.10494325448833686, "time-step": 2359}, {"errors": 0.10491599168240379, "time-step": 2360}, {"errors": 0.10488872345095802, "time-step": 2361}, {"errors": 0.10486144986335452, "time-step": 2362}, {"errors": 0.10483417098879022, "time-step": 2363}, {"errors": 0.10480688689630316, "time-step": 2364}, {"errors": 0.10477959765477053, "time-step": 2365}, {"errors": 0.10475230333290764, "time-step": 2366}, {"errors": 0.1047250039992659, "time-step": 2367}, {"errors": 0.10469769972223171, "time-step": 2368}, {"errors": 0.10467039057002489, "time-step": 2369}, {"errors": 0.10464307661069719, "time-step": 2370}, {"errors": 0.10461575791213093, "time-step": 2371}, {"errors": 0.10458843454203742, "time-step": 2372}, {"errors": 0.1045611065679555, "time-step": 2373}, {"errors": 0.10453377405725037, "time-step": 2374}, {"errors": 0.10450643707711185, "time-step": 2375}, {"errors": 0.10447909569455309, "time-step": 2376}, {"errors": 0.10445174997640923, "time-step": 2377}, {"errors": 0.1044243999893358, "time-step": 2378}, {"errors": 0.10439704579980758, "time-step": 2379}, {"errors": 0.10436968747411701, "time-step": 2380}, {"errors": 0.1043423250783729, "time-step": 2381}, {"errors": 0.10431495867849902, "time-step": 2382}, {"errors": 0.10428758834023269, "time-step": 2383}, {"errors": 0.10426021412912356, "time-step": 2384}, {"errors": 0.10423283611053213, "time-step": 2385}, {"errors": 0.10420545434962852, "time-step": 2386}, {"errors": 0.10417806891139095, "time-step": 2387}, {"errors": 0.10415067986060467, "time-step": 2388}, {"errors": 0.10412328726186035, "time-step": 2389}, {"errors": 0.10409589117955308, "time-step": 2390}, {"errors": 0.10406849167788079, "time-step": 2391}, {"errors": 0.10404108882084306, "time-step": 2392}, {"errors": 0.10401368267223998, "time-step": 2393}, {"errors": 0.1039862732956706, "time-step": 2394}, {"errors": 0.10395886075453178, "time-step": 2395}, {"errors": 0.10393144511201707, "time-step": 2396}, {"errors": 0.10390402643111514, "time-step": 2397}, {"errors": 0.10387660477460893, "time-step": 2398}, {"errors": 0.1038491802050739, "time-step": 2399}, {"errors": 0.1038217527848774, "time-step": 2400}, {"errors": 0.10379432257617698, "time-step": 2401}, {"errors": 0.10376688964091925, "time-step": 2402}, {"errors": 0.10373945404083887, "time-step": 2403}, {"errors": 0.10371201583745726, "time-step": 2404}, {"errors": 0.10368457509208134, "time-step": 2405}, {"errors": 0.1036571318658023, "time-step": 2406}, {"errors": 0.10362968621949466, "time-step": 2407}, {"errors": 0.10360223821381483, "time-step": 2408}, {"errors": 0.10357478790920013, "time-step": 2409}, {"errors": 0.10354733536586765, "time-step": 2410}, {"errors": 0.10351988064381296, "time-step": 2411}, {"errors": 0.10349242380280907, "time-step": 2412}, {"errors": 0.10346496490240539, "time-step": 2413}, {"errors": 0.1034375040019263, "time-step": 2414}, {"errors": 0.10341004116047053, "time-step": 2415}, {"errors": 0.10338257643690961, "time-step": 2416}, {"errors": 0.10335510988988705, "time-step": 2417}, {"errors": 0.10332764157781701, "time-step": 2418}, {"errors": 0.1033001715588836, "time-step": 2419}, {"errors": 0.10327269989103945, "time-step": 2420}, {"errors": 0.10324522663200483, "time-step": 2421}, {"errors": 0.10321775183926649, "time-step": 2422}, {"errors": 0.10319027557007679, "time-step": 2423}, {"errors": 0.10316279788145244, "time-step": 2424}, {"errors": 0.10313531883017381, "time-step": 2425}, {"errors": 0.1031078384727834, "time-step": 2426}, {"errors": 0.10308035686558538, "time-step": 2427}, {"errors": 0.10305287406464418, "time-step": 2428}, {"errors": 0.1030253901257838, "time-step": 2429}, {"errors": 0.10299790510458655, "time-step": 2430}, {"errors": 0.10297041905639227, "time-step": 2431}, {"errors": 0.10294293203629726, "time-step": 2432}, {"errors": 0.10291544409915342, "time-step": 2433}, {"errors": 0.10288795529956724, "time-step": 2434}, {"errors": 0.10286046569189874, "time-step": 2435}, {"errors": 0.10283297533026076, "time-step": 2436}, {"errors": 0.10280548426851788, "time-step": 2437}, {"errors": 0.10277799256028565, "time-step": 2438}, {"errors": 0.10275050025892941, "time-step": 2439}, {"errors": 0.1027230074175637, "time-step": 2440}, {"errors": 0.10269551408905114, "time-step": 2441}, {"errors": 0.1026680203260017, "time-step": 2442}, {"errors": 0.10264052618077169, "time-step": 2443}, {"errors": 0.10261303170546299, "time-step": 2444}, {"errors": 0.10258553695192224, "time-step": 2445}, {"errors": 0.10255804197173973, "time-step": 2446}, {"errors": 0.10253054681624882, "time-step": 2447}, {"errors": 0.10250305153652522, "time-step": 2448}, {"errors": 0.10247555618338558, "time-step": 2449}, {"errors": 0.10244806080738741, "time-step": 2450}, {"errors": 0.10242056545882766, "time-step": 2451}, {"errors": 0.1023930701877424, "time-step": 2452}, {"errors": 0.10236557504390559, "time-step": 2453}, {"errors": 0.1023380800768287, "time-step": 2454}, {"errors": 0.10231058533575961, "time-step": 2455}, {"errors": 0.10228309086968201, "time-step": 2456}, {"errors": 0.10225559672731466, "time-step": 2457}, {"errors": 0.10222810295711049, "time-step": 2458}, {"errors": 0.102200609607256, "time-step": 2459}, {"errors": 0.10217311672567043, "time-step": 2460}, {"errors": 0.1021456243600052, "time-step": 2461}, {"errors": 0.10211813255764282, "time-step": 2462}, {"errors": 0.10209064136569672, "time-step": 2463}, {"errors": 0.10206315083100997, "time-step": 2464}, {"errors": 0.10203566100015506, "time-step": 2465}, {"errors": 0.10200817191943296, "time-step": 2466}, {"errors": 0.10198068363487234, "time-step": 2467}, {"errors": 0.1019531961922293, "time-step": 2468}, {"errors": 0.10192570963698636, "time-step": 2469}, {"errors": 0.10189822401435182, "time-step": 2470}, {"errors": 0.10187073936925932, "time-step": 2471}, {"errors": 0.10184325574636696, "time-step": 2472}, {"errors": 0.10181577319005694, "time-step": 2473}, {"errors": 0.1017882917444346, "time-step": 2474}, {"errors": 0.10176081145332812, "time-step": 2475}, {"errors": 0.1017333323602877, "time-step": 2476}, {"errors": 0.10170585450858502, "time-step": 2477}, {"errors": 0.10167837794121276, "time-step": 2478}, {"errors": 0.10165090270088384, "time-step": 2479}, {"errors": 0.10162342883003089, "time-step": 2480}, {"errors": 0.10159595637080583, "time-step": 2481}, {"errors": 0.10156848536507912, "time-step": 2482}, {"errors": 0.10154101585443913, "time-step": 2483}, {"errors": 0.10151354788019198, "time-step": 2484}, {"errors": 0.10148608148336066, "time-step": 2485}, {"errors": 0.10145861670468462, "time-step": 2486}, {"errors": 0.10143115358461902, "time-step": 2487}, {"errors": 0.10140369216333475, "time-step": 2488}, {"errors": 0.10137623248071735, "time-step": 2489}, {"errors": 0.10134877457636682, "time-step": 2490}, {"errors": 0.10132131848959709, "time-step": 2491}, {"errors": 0.10129386425943544, "time-step": 2492}, {"errors": 0.10126641192462203, "time-step": 2493}, {"errors": 0.10123896152360971, "time-step": 2494}, {"errors": 0.10121151309456292, "time-step": 2495}, {"errors": 0.10118406667535798, "time-step": 2496}, {"errors": 0.10115662230358227, "time-step": 2497}, {"errors": 0.10112918001653358, "time-step": 2498}, {"errors": 0.10110173985122006, "time-step": 2499}, {"errors": 0.10107430184435964, "time-step": 2500}, {"errors": 0.10104686603237965, "time-step": 2501}, {"errors": 0.10101943245141631, "time-step": 2502}, {"errors": 0.10099200113731421, "time-step": 2503}, {"errors": 0.10096457212562643, "time-step": 2504}, {"errors": 0.10093714545161352, "time-step": 2505}, {"errors": 0.10090972115024349, "time-step": 2506}, {"errors": 0.10088229925619133, "time-step": 2507}, {"errors": 0.10085487980383864, "time-step": 2508}, {"errors": 0.10082746282727323, "time-step": 2509}, {"errors": 0.10080004836028886, "time-step": 2510}, {"errors": 0.10077263643638473, "time-step": 2511}, {"errors": 0.10074522708876538, "time-step": 2512}, {"errors": 0.10071782035034006, "time-step": 2513}, {"errors": 0.1006904162537227, "time-step": 2514}, {"errors": 0.10066301483123116, "time-step": 2515}, {"errors": 0.10063561611488758, "time-step": 2516}, {"errors": 0.10060822013641726, "time-step": 2517}, {"errors": 0.10058082692724912, "time-step": 2518}, {"errors": 0.10055343651851484, "time-step": 2519}, {"errors": 0.10052604894104882, "time-step": 2520}, {"errors": 0.10049866422538796, "time-step": 2521}, {"errors": 0.10047128240177115, "time-step": 2522}, {"errors": 0.10044390350013926, "time-step": 2523}, {"errors": 0.10041652755013458, "time-step": 2524}, {"errors": 0.10038915458110094, "time-step": 2525}, {"errors": 0.10036178462208298, "time-step": 2526}, {"errors": 0.10033441770182638, "time-step": 2527}, {"errors": 0.10030705384877746, "time-step": 2528}, {"errors": 0.10027969309108253, "time-step": 2529}, {"errors": 0.10025233545658851, "time-step": 2530}, {"errors": 0.10022498097284194, "time-step": 2531}, {"errors": 0.100197629667089, "time-step": 2532}, {"errors": 0.10017028156627567, "time-step": 2533}, {"errors": 0.10014293669704685, "time-step": 2534}, {"errors": 0.10011559508574669, "time-step": 2535}, {"errors": 0.10008825675841831, "time-step": 2536}, {"errors": 0.10006092174080344, "time-step": 2537}, {"errors": 0.1000335900583423, "time-step": 2538}, {"errors": 0.10000626173617364, "time-step": 2539}, {"errors": 0.09997893679913412, "time-step": 2540}, {"errors": 0.09995161527175878, "time-step": 2541}, {"errors": 0.09992429717828026, "time-step": 2542}, {"errors": 0.09989698254262902, "time-step": 2543}, {"errors": 0.09986967138843306, "time-step": 2544}, {"errors": 0.0998423637390179, "time-step": 2545}, {"errors": 0.0998150596174063, "time-step": 2546}, {"errors": 0.09978775904631823, "time-step": 2547}, {"errors": 0.09976046204817077, "time-step": 2548}, {"errors": 0.0997331686450777, "time-step": 2549}, {"errors": 0.09970587885884993, "time-step": 2550}, {"errors": 0.09967859271099505, "time-step": 2551}, {"errors": 0.09965131022271698, "time-step": 2552}, {"errors": 0.09962403141491652, "time-step": 2553}, {"errors": 0.09959675630819073, "time-step": 2554}, {"errors": 0.09956948492283302, "time-step": 2555}, {"errors": 0.09954221727883317, "time-step": 2556}, {"errors": 0.09951495339587707, "time-step": 2557}, {"errors": 0.09948769329334674, "time-step": 2558}, {"errors": 0.09946043699032027, "time-step": 2559}, {"errors": 0.09943318450557186, "time-step": 2560}, {"errors": 0.09940593585757149, "time-step": 2561}, {"errors": 0.09937869106448516, "time-step": 2562}, {"errors": 0.09935145014417465, "time-step": 2563}, {"errors": 0.09932421311419769, "time-step": 2564}, {"errors": 0.09929697999180762, "time-step": 2565}, {"errors": 0.09926975079395359, "time-step": 2566}, {"errors": 0.09924252553728061, "time-step": 2567}, {"errors": 0.09921530423812913, "time-step": 2568}, {"errors": 0.09918808691253561, "time-step": 2569}, {"errors": 0.09916087357623188, "time-step": 2570}, {"errors": 0.09913366424464569, "time-step": 2571}, {"errors": 0.0991064589329003, "time-step": 2572}, {"errors": 0.09907925765581468, "time-step": 2573}, {"errors": 0.09905206042790352, "time-step": 2574}, {"errors": 0.09902486726337713, "time-step": 2575}, {"errors": 0.09899767817614166, "time-step": 2576}, {"errors": 0.09897049317979878, "time-step": 2577}, {"errors": 0.0989433122876461, "time-step": 2578}, {"errors": 0.09891613551267692, "time-step": 2579}, {"errors": 0.09888896286758032, "time-step": 2580}, {"errors": 0.09886179436474124, "time-step": 2581}, {"errors": 0.09883463001624056, "time-step": 2582}, {"errors": 0.09880746983385508, "time-step": 2583}, {"errors": 0.09878031382905751, "time-step": 2584}, {"errors": 0.09875316201301665, "time-step": 2585}, {"errors": 0.09872601439659737, "time-step": 2586}, {"errors": 0.09869887099036075, "time-step": 2587}, {"errors": 0.09867173180456393, "time-step": 2588}, {"errors": 0.09864459684916055, "time-step": 2589}, {"errors": 0.09861746613380042, "time-step": 2590}, {"errors": 0.09859033966782982, "time-step": 2591}, {"errors": 0.09856321746029167, "time-step": 2592}, {"errors": 0.09853609951992531, "time-step": 2593}, {"errors": 0.09850898585516688, "time-step": 2594}, {"errors": 0.09848187647414916, "time-step": 2595}, {"errors": 0.0984547713847019, "time-step": 2596}, {"errors": 0.09842767059435188, "time-step": 2597}, {"errors": 0.09840057411032277, "time-step": 2598}, {"errors": 0.09837348193953549, "time-step": 2599}, {"errors": 0.09834639408860828, "time-step": 2600}, {"errors": 0.09831931056385662, "time-step": 2601}, {"errors": 0.09829223137129375, "time-step": 2602}, {"errors": 0.09826515651663019, "time-step": 2603}, {"errors": 0.0982380860052745, "time-step": 2604}, {"errors": 0.09821101984233292, "time-step": 2605}, {"errors": 0.09818395803260974, "time-step": 2606}, {"errors": 0.09815690058060739, "time-step": 2607}, {"errors": 0.09812984749052647, "time-step": 2608}, {"errors": 0.09810279876626612, "time-step": 2609}, {"errors": 0.09807575441142383, "time-step": 2610}, {"errors": 0.0980487144292959, "time-step": 2611}, {"errors": 0.09802167882287727, "time-step": 2612}, {"errors": 0.09799464759486212, "time-step": 2613}, {"errors": 0.09796762074764351, "time-step": 2614}, {"errors": 0.0979405982833138, "time-step": 2615}, {"errors": 0.09791358020366489, "time-step": 2616}, {"errors": 0.09788656651018812, "time-step": 2617}, {"errors": 0.09785955720407463, "time-step": 2618}, {"errors": 0.09783255228621551, "time-step": 2619}, {"errors": 0.0978055517572019, "time-step": 2620}, {"errors": 0.09777855561732512, "time-step": 2621}, {"errors": 0.09775156386657699, "time-step": 2622}, {"errors": 0.09772457650464983, "time-step": 2623}, {"errors": 0.09769759353093684, "time-step": 2624}, {"errors": 0.09767061494453204, "time-step": 2625}, {"errors": 0.09764364074423063, "time-step": 2626}, {"errors": 0.09761667092852915, "time-step": 2627}, {"errors": 0.0975897054956256, "time-step": 2628}, {"errors": 0.09756274444341959, "time-step": 2629}, {"errors": 0.09753578776951277, "time-step": 2630}, {"errors": 0.0975088354712087, "time-step": 2631}, {"errors": 0.09748188754551321, "time-step": 2632}, {"errors": 0.0974549439891347, "time-step": 2633}, {"errors": 0.09742800479848418, "time-step": 2634}, {"errors": 0.09740106996967532, "time-step": 2635}, {"errors": 0.09737413949852519, "time-step": 2636}, {"errors": 0.09734721338055383, "time-step": 2637}, {"errors": 0.09732029161098485, "time-step": 2638}, {"errors": 0.09729337418474557, "time-step": 2639}, {"errors": 0.09726646109646711, "time-step": 2640}, {"errors": 0.09723955234048476, "time-step": 2641}, {"errors": 0.09721264791083807, "time-step": 2642}, {"errors": 0.0971857478012711, "time-step": 2643}, {"errors": 0.09715885200523272, "time-step": 2644}, {"errors": 0.09713196051587661, "time-step": 2645}, {"errors": 0.0971050733260618, "time-step": 2646}, {"errors": 0.09707819042835267, "time-step": 2647}, {"errors": 0.09705131181501911, "time-step": 2648}, {"errors": 0.09702443747803695, "time-step": 2649}, {"errors": 0.09699756740908805, "time-step": 2650}, {"errors": 0.0969707015995607, "time-step": 2651}, {"errors": 0.0969438400405494, "time-step": 2652}, {"errors": 0.0969169827228557, "time-step": 2653}, {"errors": 0.09689012963698805, "time-step": 2654}, {"errors": 0.09686328077316211, "time-step": 2655}, {"errors": 0.09683643612130091, "time-step": 2656}, {"errors": 0.09680959567103525, "time-step": 2657}, {"errors": 0.09678275941170385, "time-step": 2658}, {"errors": 0.09675592733235353, "time-step": 2659}, {"errors": 0.09672909942173952, "time-step": 2660}, {"errors": 0.09670227566832579, "time-step": 2661}, {"errors": 0.09667545606028499, "time-step": 2662}, {"errors": 0.09664864058549899, "time-step": 2663}, {"errors": 0.09662182923155901, "time-step": 2664}, {"errors": 0.09659502198576586, "time-step": 2665}, {"errors": 0.09656821883513018, "time-step": 2666}, {"errors": 0.09654141976637273, "time-step": 2667}, {"errors": 0.0965146247659245, "time-step": 2668}, {"errors": 0.09648783381992718, "time-step": 2669}, {"errors": 0.09646104691423316, "time-step": 2670}, {"errors": 0.09643426403440598, "time-step": 2671}, {"errors": 0.09640748516572042, "time-step": 2672}, {"errors": 0.09638071029316299, "time-step": 2673}, {"errors": 0.09635393940143175, "time-step": 2674}, {"errors": 0.09632717247493706, "time-step": 2675}, {"errors": 0.09630040949780137, "time-step": 2676}, {"errors": 0.09627365045386, "time-step": 2677}, {"errors": 0.0962468953266607, "time-step": 2678}, {"errors": 0.09622014409946454, "time-step": 2679}, {"errors": 0.09619339675524585, "time-step": 2680}, {"errors": 0.09616665327669251, "time-step": 2681}, {"errors": 0.09613991364620625, "time-step": 2682}, {"errors": 0.09611317784590281, "time-step": 2683}, {"errors": 0.09608644585761231, "time-step": 2684}, {"errors": 0.09605971766287932, "time-step": 2685}, {"errors": 0.09603299324296352, "time-step": 2686}, {"errors": 0.0960062725788394, "time-step": 2687}, {"errors": 0.0959795556511969, "time-step": 2688}, {"errors": 0.09595284244044153, "time-step": 2689}, {"errors": 0.09592613292669461, "time-step": 2690}, {"errors": 0.09589942708979364, "time-step": 2691}, {"errors": 0.09587272490929247, "time-step": 2692}, {"errors": 0.09584602636446135, "time-step": 2693}, {"errors": 0.09581933143428778, "time-step": 2694}, {"errors": 0.09579264009747598, "time-step": 2695}, {"errors": 0.09576595233244783, "time-step": 2696}, {"errors": 0.09573926811734257, "time-step": 2697}, {"errors": 0.09571258743001756, "time-step": 2698}, {"errors": 0.09568591024804814, "time-step": 2699}, {"errors": 0.09565923654872799, "time-step": 2700}, {"errors": 0.09563256630906963, "time-step": 2701}, {"errors": 0.0956058995058042, "time-step": 2702}, {"errors": 0.09557923611538216, "time-step": 2703}, {"errors": 0.0955525761139733, "time-step": 2704}, {"errors": 0.09552591947746703, "time-step": 2705}, {"errors": 0.09549926618147261, "time-step": 2706}, {"errors": 0.09547261620131967, "time-step": 2707}, {"errors": 0.09544596951205782, "time-step": 2708}, {"errors": 0.09541932608845774, "time-step": 2709}, {"errors": 0.09539268590501071, "time-step": 2710}, {"errors": 0.09536604893592922, "time-step": 2711}, {"errors": 0.09533941515514724, "time-step": 2712}, {"errors": 0.09531278453632022, "time-step": 2713}, {"errors": 0.09528615705282556, "time-step": 2714}, {"errors": 0.0952595326777629, "time-step": 2715}, {"errors": 0.09523291138395393, "time-step": 2716}, {"errors": 0.0952062931439433, "time-step": 2717}, {"errors": 0.09517967792999835, "time-step": 2718}, {"errors": 0.09515306571410953, "time-step": 2719}, {"errors": 0.09512645646799066, "time-step": 2720}, {"errors": 0.09509985016307912, "time-step": 2721}, {"errors": 0.09507324677053616, "time-step": 2722}, {"errors": 0.09504664626124701, "time-step": 2723}, {"errors": 0.09502004860582133, "time-step": 2724}, {"errors": 0.0949934537745932, "time-step": 2725}, {"errors": 0.0949668617376215, "time-step": 2726}, {"errors": 0.09494027246469026, "time-step": 2727}, {"errors": 0.09491368592530855, "time-step": 2728}, {"errors": 0.09488710208871112, "time-step": 2729}, {"errors": 0.09486052092385835, "time-step": 2730}, {"errors": 0.09483394239943652, "time-step": 2731}, {"errors": 0.09480736648385821, "time-step": 2732}, {"errors": 0.0947807931452623, "time-step": 2733}, {"errors": 0.0947542223515144, "time-step": 2734}, {"errors": 0.09472765407020699, "time-step": 2735}, {"errors": 0.0947010882686595, "time-step": 2736}, {"errors": 0.09467452491391891, "time-step": 2737}, {"errors": 0.09464796397275961, "time-step": 2738}, {"errors": 0.09462140541168373, "time-step": 2739}, {"errors": 0.09459484919692146, "time-step": 2740}, {"errors": 0.09456829529443127, "time-step": 2741}, {"errors": 0.09454174366989984, "time-step": 2742}, {"errors": 0.09451519428874271, "time-step": 2743}, {"errors": 0.09448864711610426, "time-step": 2744}, {"errors": 0.09446210211685782, "time-step": 2745}, {"errors": 0.09443555925560612, "time-step": 2746}, {"errors": 0.09440901849668144, "time-step": 2747}, {"errors": 0.09438247980414566, "time-step": 2748}, {"errors": 0.09435594314179066, "time-step": 2749}, {"errors": 0.09432940847313848, "time-step": 2750}, {"errors": 0.09430287576144142, "time-step": 2751}, {"errors": 0.09427634496968249, "time-step": 2752}, {"errors": 0.09424981606057514, "time-step": 2753}, {"errors": 0.0942232889965642, "time-step": 2754}, {"errors": 0.09419676373982534, "time-step": 2755}, {"errors": 0.09417024025226571, "time-step": 2756}, {"errors": 0.09414371849552394, "time-step": 2757}, {"errors": 0.09411719843097055, "time-step": 2758}, {"errors": 0.09409068001970781, "time-step": 2759}, {"errors": 0.09406416322257036, "time-step": 2760}, {"errors": 0.0940376480001249, "time-step": 2761}, {"errors": 0.09401113431267087, "time-step": 2762}, {"errors": 0.09398462212024032, "time-step": 2763}, {"errors": 0.09395811138259819, "time-step": 2764}, {"errors": 0.0939316020592425, "time-step": 2765}, {"errors": 0.09390509410940459, "time-step": 2766}, {"errors": 0.09387858749204916, "time-step": 2767}, {"errors": 0.09385208216587451, "time-step": 2768}, {"errors": 0.09382557808931286, "time-step": 2769}, {"errors": 0.09379907522053019, "time-step": 2770}, {"errors": 0.09377257351742692, "time-step": 2771}, {"errors": 0.09374607293763752, "time-step": 2772}, {"errors": 0.09371957343853109, "time-step": 2773}, {"errors": 0.0936930749772113, "time-step": 2774}, {"errors": 0.09366657751051669, "time-step": 2775}, {"errors": 0.09364008099502076, "time-step": 2776}, {"errors": 0.09361358538703227, "time-step": 2777}, {"errors": 0.09358709064259502, "time-step": 2778}, {"errors": 0.09356059671748854, "time-step": 2779}, {"errors": 0.09353410356722792, "time-step": 2780}, {"errors": 0.09350761114706391, "time-step": 2781}, {"errors": 0.0934811194119833, "time-step": 2782}, {"errors": 0.09345462831670892, "time-step": 2783}, {"errors": 0.09342813781569989, "time-step": 2784}, {"errors": 0.09340164786315155, "time-step": 2785}, {"errors": 0.09337515841299593, "time-step": 2786}, {"errors": 0.0933486694189016, "time-step": 2787}, {"errors": 0.0933221808342741, "time-step": 2788}, {"errors": 0.09329569261225562, "time-step": 2789}, {"errors": 0.09326920470572574, "time-step": 2790}, {"errors": 0.09324271706730097, "time-step": 2791}, {"errors": 0.09321622964933539, "time-step": 2792}, {"errors": 0.09318974240392043, "time-step": 2793}, {"errors": 0.09316325528288516, "time-step": 2794}, {"errors": 0.09313676823779635, "time-step": 2795}, {"errors": 0.09311028121995861, "time-step": 2796}, {"errors": 0.09308379418041454, "time-step": 2797}, {"errors": 0.09305730706994483, "time-step": 2798}, {"errors": 0.09303081983906844, "time-step": 2799}, {"errors": 0.09300433243804246, "time-step": 2800}, {"errors": 0.09297784481686264, "time-step": 2801}, {"errors": 0.09295135692526305, "time-step": 2802}, {"errors": 0.09292486871271657, "time-step": 2803}, {"errors": 0.09289838012843486, "time-step": 2804}, {"errors": 0.09287189112136829, "time-step": 2805}, {"errors": 0.09284540164020626, "time-step": 2806}, {"errors": 0.0928189116333773, "time-step": 2807}, {"errors": 0.09279242104904895, "time-step": 2808}, {"errors": 0.09276592983512816, "time-step": 2809}, {"errors": 0.09273943793926116, "time-step": 2810}, {"errors": 0.09271294530883348, "time-step": 2811}, {"errors": 0.0926864518909704, "time-step": 2812}, {"errors": 0.09265995763253665, "time-step": 2813}, {"errors": 0.09263346248013671, "time-step": 2814}, {"errors": 0.09260696638011476, "time-step": 2815}, {"errors": 0.09258046927855491, "time-step": 2816}, {"errors": 0.09255397112128123, "time-step": 2817}, {"errors": 0.09252747185385762, "time-step": 2818}, {"errors": 0.09250097142158814, "time-step": 2819}, {"errors": 0.09247446976951713, "time-step": 2820}, {"errors": 0.09244796684242883, "time-step": 2821}, {"errors": 0.09242146258484799, "time-step": 2822}, {"errors": 0.0923949569410396, "time-step": 2823}, {"errors": 0.09236844985500908, "time-step": 2824}, {"errors": 0.09234194127050217, "time-step": 2825}, {"errors": 0.09231543113100531, "time-step": 2826}, {"errors": 0.09228891937974534, "time-step": 2827}, {"errors": 0.09226240595968979, "time-step": 2828}, {"errors": 0.09223589081354674, "time-step": 2829}, {"errors": 0.09220937388376513, "time-step": 2830}, {"errors": 0.0921828551125344, "time-step": 2831}, {"errors": 0.092156334441785, "time-step": 2832}, {"errors": 0.09212981181318806, "time-step": 2833}, {"errors": 0.09210328716815566, "time-step": 2834}, {"errors": 0.09207676044784066, "time-step": 2835}, {"errors": 0.09205023159313686, "time-step": 2836}, {"errors": 0.09202370054467907, "time-step": 2837}, {"errors": 0.09199716724284304, "time-step": 2838}, {"errors": 0.09197063162774544, "time-step": 2839}, {"errors": 0.09194409363924408, "time-step": 2840}, {"errors": 0.09191755321693774, "time-step": 2841}, {"errors": 0.0918910103001662, "time-step": 2842}, {"errors": 0.09186446482801039, "time-step": 2843}, {"errors": 0.09183791673929224, "time-step": 2844}, {"errors": 0.09181136597257486, "time-step": 2845}, {"errors": 0.09178481246616238, "time-step": 2846}, {"errors": 0.09175825615810007, "time-step": 2847}, {"errors": 0.09173169698617423, "time-step": 2848}, {"errors": 0.09170513488791229, "time-step": 2849}, {"errors": 0.09167856980058275, "time-step": 2850}, {"errors": 0.09165200166119533, "time-step": 2851}, {"errors": 0.09162543040650059, "time-step": 2852}, {"errors": 0.09159885597299045, "time-step": 2853}, {"errors": 0.09157227829689757, "time-step": 2854}, {"errors": 0.09154569731419594, "time-step": 2855}, {"errors": 0.09151911296060045, "time-step": 2856}, {"errors": 0.09149252517156695, "time-step": 2857}, {"errors": 0.09146593388229234, "time-step": 2858}, {"errors": 0.09143933902771445, "time-step": 2859}, {"errors": 0.09141274054251217, "time-step": 2860}, {"errors": 0.09138613836110504, "time-step": 2861}, {"errors": 0.09135953241765368, "time-step": 2862}, {"errors": 0.0913329226460595, "time-step": 2863}, {"errors": 0.09130630897996461, "time-step": 2864}, {"errors": 0.0912796913527521, "time-step": 2865}, {"errors": 0.09125306969754554, "time-step": 2866}, {"errors": 0.09122644394720938, "time-step": 2867}, {"errors": 0.09119981403434856, "time-step": 2868}, {"errors": 0.09117317989130869, "time-step": 2869}, {"errors": 0.09114654145017591, "time-step": 2870}, {"errors": 0.09111989864277678, "time-step": 2871}, {"errors": 0.09109325140067831, "time-step": 2872}, {"errors": 0.09106659965518804, "time-step": 2873}, {"errors": 0.0910399433373536, "time-step": 2874}, {"errors": 0.09101328237796297, "time-step": 2875}, {"errors": 0.09098661670754431, "time-step": 2876}, {"errors": 0.090959946256366, "time-step": 2877}, {"errors": 0.09093327095443623, "time-step": 2878}, {"errors": 0.09090659073150341, "time-step": 2879}, {"errors": 0.0908799055170558, "time-step": 2880}, {"errors": 0.09085321524032142, "time-step": 2881}, {"errors": 0.0908265198302681, "time-step": 2882}, {"errors": 0.09079981921560351, "time-step": 2883}, {"errors": 0.09077311332477457, "time-step": 2884}, {"errors": 0.09074640208596799, "time-step": 2885}, {"errors": 0.09071968542710986, "time-step": 2886}, {"errors": 0.09069296327586557, "time-step": 2887}, {"errors": 0.09066623555963982, "time-step": 2888}, {"errors": 0.09063950220557632, "time-step": 2889}, {"errors": 0.09061276314055808, "time-step": 2890}, {"errors": 0.09058601829120695, "time-step": 2891}, {"errors": 0.09055926758388366, "time-step": 2892}, {"errors": 0.09053251094468767, "time-step": 2893}, {"errors": 0.09050574829945723, "time-step": 2894}, {"errors": 0.09047897957376909, "time-step": 2895}, {"errors": 0.09045220469293841, "time-step": 2896}, {"errors": 0.09042542358201881, "time-step": 2897}, {"errors": 0.09039863616580208, "time-step": 2898}, {"errors": 0.09037184236881823, "time-step": 2899}, {"errors": 0.0903450421153352, "time-step": 2900}, {"errors": 0.09031823532935879, "time-step": 2901}, {"errors": 0.09029142193463274, "time-step": 2902}, {"errors": 0.09026460185463839, "time-step": 2903}, {"errors": 0.09023777501259451, "time-step": 2904}, {"errors": 0.09021094133145749, "time-step": 2905}, {"errors": 0.09018410073392086, "time-step": 2906}, {"errors": 0.09015725314241543, "time-step": 2907}, {"errors": 0.09013039847910895, "time-step": 2908}, {"errors": 0.09010353666590615, "time-step": 2909}, {"errors": 0.0900766676244486, "time-step": 2910}, {"errors": 0.09004979127611437, "time-step": 2911}, {"errors": 0.0900229075420181, "time-step": 2912}, {"errors": 0.08999601634301088, "time-step": 2913}, {"errors": 0.08996911759968002, "time-step": 2914}, {"errors": 0.0899422112323488, "time-step": 2915}, {"errors": 0.08991529716107655, "time-step": 2916}, {"errors": 0.08988837530565845, "time-step": 2917}, {"errors": 0.08986144558562534, "time-step": 2918}, {"errors": 0.0898345079202435, "time-step": 2919}, {"errors": 0.08980756222851469, "time-step": 2920}, {"errors": 0.08978060842917575, "time-step": 2921}, {"errors": 0.08975364644069883, "time-step": 2922}, {"errors": 0.08972667618129074, "time-step": 2923}, {"errors": 0.08969969756889326, "time-step": 2924}, {"errors": 0.08967271052118267, "time-step": 2925}, {"errors": 0.08964571495556972, "time-step": 2926}, {"errors": 0.08961871078919967, "time-step": 2927}, {"errors": 0.08959169793895164, "time-step": 2928}, {"errors": 0.0895646763214388, "time-step": 2929}, {"errors": 0.08953764585300832, "time-step": 2930}, {"errors": 0.08951060644974082, "time-step": 2931}, {"errors": 0.08948355802745057, "time-step": 2932}, {"errors": 0.08945650050168517, "time-step": 2933}, {"errors": 0.08942943378772525, "time-step": 2934}, {"errors": 0.08940235780058461, "time-step": 2935}, {"errors": 0.08937527245500985, "time-step": 2936}, {"errors": 0.08934817766548014, "time-step": 2937}, {"errors": 0.0893210733462074, "time-step": 2938}, {"errors": 0.08929395941113555, "time-step": 2939}, {"errors": 0.08926683577394091, "time-step": 2940}, {"errors": 0.08923970234803176, "time-step": 2941}, {"errors": 0.08921255904654812, "time-step": 2942}, {"errors": 0.08918540578236178, "time-step": 2943}, {"errors": 0.08915824246807583, "time-step": 2944}, {"errors": 0.08913106901602483, "time-step": 2945}, {"errors": 0.0891038853382744, "time-step": 2946}, {"errors": 0.08907669134662108, "time-step": 2947}, {"errors": 0.08904948695259227, "time-step": 2948}, {"errors": 0.08902227206744585, "time-step": 2949}, {"errors": 0.08899504660217025, "time-step": 2950}, {"errors": 0.08896781046748403, "time-step": 2951}, {"errors": 0.08894056357383587, "time-step": 2952}, {"errors": 0.08891330583140433, "time-step": 2953}, {"errors": 0.08888603715009775, "time-step": 2954}, {"errors": 0.08885875743955393, "time-step": 2955}, {"errors": 0.08883146660913997, "time-step": 2956}, {"errors": 0.08880416456795226, "time-step": 2957}, {"errors": 0.08877685122481616, "time-step": 2958}, {"errors": 0.08874952648828571, "time-step": 2959}, {"errors": 0.08872219026664388, "time-step": 2960}, {"errors": 0.0886948424679018, "time-step": 2961}, {"errors": 0.08866748299979907, "time-step": 2962}, {"errors": 0.08864011176980328, "time-step": 2963}, {"errors": 0.08861272868511003, "time-step": 2964}, {"errors": 0.0885853336526426, "time-step": 2965}, {"errors": 0.08855792657905193, "time-step": 2966}, {"errors": 0.08853050737071622, "time-step": 2967}, {"errors": 0.08850307593374093, "time-step": 2968}, {"errors": 0.08847563217395873, "time-step": 2969}, {"errors": 0.08844817599692882, "time-step": 2970}, {"errors": 0.08842070730793739, "time-step": 2971}, {"errors": 0.08839322601199692, "time-step": 2972}, {"errors": 0.08836573201384643, "time-step": 2973}, {"errors": 0.0883382252179509, "time-step": 2974}, {"errors": 0.0883107055285014, "time-step": 2975}, {"errors": 0.08828317284941486, "time-step": 2976}, {"errors": 0.08825562708433371, "time-step": 2977}, {"errors": 0.08822806813662602, "time-step": 2978}, {"errors": 0.08820049590938506, "time-step": 2979}, {"errors": 0.08817291030542927, "time-step": 2980}, {"errors": 0.08814531122730207, "time-step": 2981}, {"errors": 0.08811769857727161, "time-step": 2982}, {"errors": 0.0880900722573308, "time-step": 2983}, {"errors": 0.08806243216919693, "time-step": 2984}, {"errors": 0.08803477821431166, "time-step": 2985}, {"errors": 0.0880071102938407, "time-step": 2986}, {"errors": 0.08797942830867389, "time-step": 2987}, {"errors": 0.08795173215942483, "time-step": 2988}, {"errors": 0.08792402174643088, "time-step": 2989}, {"errors": 0.08789629696975274, "time-step": 2990}, {"errors": 0.0878685577291746, "time-step": 2991}, {"errors": 0.08784080392420396, "time-step": 2992}, {"errors": 0.08781303545407129, "time-step": 2993}, {"errors": 0.08778525221772987, "time-step": 2994}, {"errors": 0.08775745411385603, "time-step": 2995}, {"errors": 0.08772964104084854, "time-step": 2996}, {"errors": 0.08770181289682871, "time-step": 2997}, {"errors": 0.08767396957964022, "time-step": 2998}, {"errors": 0.08764611098684894, "time-step": 2999}, {"errors": 0.08761823701574281, "time-step": 3000}, {"errors": 0.08759034756333195, "time-step": 3001}, {"errors": 0.08756244252634794, "time-step": 3002}, {"errors": 0.08753452180124432, "time-step": 3003}, {"errors": 0.08750658528419614, "time-step": 3004}, {"errors": 0.08747863287109989, "time-step": 3005}, {"errors": 0.08745066445757338, "time-step": 3006}, {"errors": 0.08742267993895578, "time-step": 3007}, {"errors": 0.08739467921030708, "time-step": 3008}, {"errors": 0.08736666216640866, "time-step": 3009}, {"errors": 0.08733862870176241, "time-step": 3010}, {"errors": 0.08731057871059131, "time-step": 3011}, {"errors": 0.08728251208683895, "time-step": 3012}, {"errors": 0.08725442872416936, "time-step": 3013}, {"errors": 0.08722632851596734, "time-step": 3014}, {"errors": 0.08719821135533783, "time-step": 3015}, {"errors": 0.08717007713510638, "time-step": 3016}, {"errors": 0.0871419257478186, "time-step": 3017}, {"errors": 0.08711375708574035, "time-step": 3018}, {"errors": 0.08708557104085748, "time-step": 3019}, {"errors": 0.0870573675048761, "time-step": 3020}, {"errors": 0.08702914636922202, "time-step": 3021}, {"errors": 0.08700090752504118, "time-step": 3022}, {"errors": 0.08697265086319915, "time-step": 3023}, {"errors": 0.0869443762742815, "time-step": 3024}, {"errors": 0.08691608364859335, "time-step": 3025}, {"errors": 0.0868877728761597, "time-step": 3026}, {"errors": 0.08685944384672513, "time-step": 3027}, {"errors": 0.08683109644975376, "time-step": 3028}, {"errors": 0.08680273057442951, "time-step": 3029}, {"errors": 0.08677434610965562, "time-step": 3030}, {"errors": 0.08674594294405512, "time-step": 3031}, {"errors": 0.08671752096597046, "time-step": 3032}, {"errors": 0.08668908006346367, "time-step": 3033}, {"errors": 0.08666062012431619, "time-step": 3034}, {"errors": 0.0866321410360291, "time-step": 3035}, {"errors": 0.08660364268582293, "time-step": 3036}, {"errors": 0.08657512496063799, "time-step": 3037}, {"errors": 0.08654658774713378, "time-step": 3038}, {"errors": 0.08651803093168972, "time-step": 3039}, {"errors": 0.08648945440040465, "time-step": 3040}, {"errors": 0.08646085803909709, "time-step": 3041}, {"errors": 0.08643224173330541, "time-step": 3042}, {"errors": 0.08640360536828756, "time-step": 3043}, {"errors": 0.08637494882902136, "time-step": 3044}, {"errors": 0.08634627200020445, "time-step": 3045}, {"errors": 0.0863175747662545, "time-step": 3046}, {"errors": 0.08628885701130914, "time-step": 3047}, {"errors": 0.08626011861922597, "time-step": 3048}, {"errors": 0.08623135947358296, "time-step": 3049}, {"errors": 0.08620257945767823, "time-step": 3050}, {"errors": 0.08617377845453036, "time-step": 3051}, {"errors": 0.08614495634687828, "time-step": 3052}, {"errors": 0.08611611301718174, "time-step": 3053}, {"errors": 0.08608724834762098, "time-step": 3054}, {"errors": 0.08605836222009733, "time-step": 3055}, {"errors": 0.08602945451623287, "time-step": 3056}, {"errors": 0.08600052511737112, "time-step": 3057}, {"errors": 0.08597157390457663, "time-step": 3058}, {"errors": 0.0859426007586356, "time-step": 3059}, {"errors": 0.08591360556005588, "time-step": 3060}, {"errors": 0.08588458818906697, "time-step": 3061}, {"errors": 0.08585554852562065, "time-step": 3062}, {"errors": 0.0858264864493907, "time-step": 3063}, {"errors": 0.08579740183977333, "time-step": 3064}, {"errors": 0.08576829457588755, "time-step": 3065}, {"errors": 0.0857391645365751, "time-step": 3066}, {"errors": 0.08571001160040084, "time-step": 3067}, {"errors": 0.08568083564565296, "time-step": 3068}, {"errors": 0.08565163655034325, "time-step": 3069}, {"errors": 0.08562241419220737, "time-step": 3070}, {"errors": 0.08559316844870507, "time-step": 3071}, {"errors": 0.08556389919702052, "time-step": 3072}, {"errors": 0.08553460631406266, "time-step": 3073}, {"errors": 0.08550528967646535, "time-step": 3074}, {"errors": 0.08547594916058768, "time-step": 3075}, {"errors": 0.08544658464251459, "time-step": 3076}, {"errors": 0.08541719599805674, "time-step": 3077}, {"errors": 0.08538778310275132, "time-step": 3078}, {"errors": 0.085358345831862, "time-step": 3079}, {"errors": 0.08532888406037961, "time-step": 3080}, {"errors": 0.08529939766302227, "time-step": 3081}, {"errors": 0.085269886514236, "time-step": 3082}, {"errors": 0.08524035048819499, "time-step": 3083}, {"errors": 0.0852107894588019, "time-step": 3084}, {"errors": 0.08518120329968851, "time-step": 3085}, {"errors": 0.08515159188421603, "time-step": 3086}, {"errors": 0.0851219550854756, "time-step": 3087}, {"errors": 0.08509229277628866, "time-step": 3088}, {"errors": 0.08506260482920747, "time-step": 3089}, {"errors": 0.08503289111651563, "time-step": 3090}, {"errors": 0.08500315151022844, "time-step": 3091}, {"errors": 0.08497338588209374, "time-step": 3092}, {"errors": 0.08494359410359181, "time-step": 3093}, {"errors": 0.08491377604593664, "time-step": 3094}, {"errors": 0.0848839315800759, "time-step": 3095}, {"errors": 0.08485406057669176, "time-step": 3096}, {"errors": 0.08482416290620147, "time-step": 3097}, {"errors": 0.08479423843875782, "time-step": 3098}, {"errors": 0.08476428704424988, "time-step": 3099}, {"errors": 0.08473430859230352, "time-step": 3100}, {"errors": 0.08470430295228198, "time-step": 3101}, {"errors": 0.08467426999328663, "time-step": 3102}, {"errors": 0.08464420958415765, "time-step": 3103}, {"errors": 0.08461412159347459, "time-step": 3104}, {"errors": 0.08458400588955707, "time-step": 3105}, {"errors": 0.08455386234046545, "time-step": 3106}, {"errors": 0.08452369081400174, "time-step": 3107}, {"errors": 0.08449349117771011, "time-step": 3108}, {"errors": 0.08446326329887768, "time-step": 3109}, {"errors": 0.08443300704453534, "time-step": 3110}, {"errors": 0.08440272228145848, "time-step": 3111}, {"errors": 0.08437240887616786, "time-step": 3112}, {"errors": 0.08434206669493025, "time-step": 3113}, {"errors": 0.08431169560375945, "time-step": 3114}, {"errors": 0.08428129546841688, "time-step": 3115}, {"errors": 0.08425086615441281, "time-step": 3116}, {"errors": 0.08422040752700677, "time-step": 3117}, {"errors": 0.08418991945120888, "time-step": 3118}, {"errors": 0.08415940179178044, "time-step": 3119}, {"errors": 0.08412885441323492, "time-step": 3120}, {"errors": 0.08409827717983906, "time-step": 3121}, {"errors": 0.08406766995561367, "time-step": 3122}, {"errors": 0.0840370326043346, "time-step": 3123}, {"errors": 0.08400636498953384, "time-step": 3124}, {"errors": 0.08397566697450037, "time-step": 3125}, {"errors": 0.08394493842228132, "time-step": 3126}, {"errors": 0.0839141791956831, "time-step": 3127}, {"errors": 0.08388338915727224, "time-step": 3128}, {"errors": 0.08385256816937647, "time-step": 3129}, {"errors": 0.08382171609408613, "time-step": 3130}, {"errors": 0.08379083279325497, "time-step": 3131}, {"errors": 0.08375991812850145, "time-step": 3132}, {"errors": 0.08372897196120976, "time-step": 3133}, {"errors": 0.08369799415253133, "time-step": 3134}, {"errors": 0.08366698456338553, "time-step": 3135}, {"errors": 0.08363594305446129, "time-step": 3136}, {"errors": 0.08360486948621815, "time-step": 3137}, {"errors": 0.08357376371888758, "time-step": 3138}, {"errors": 0.08354262561247427, "time-step": 3139}, {"errors": 0.08351145502675739, "time-step": 3140}, {"errors": 0.08348025182129187, "time-step": 3141}, {"errors": 0.08344901585540984, "time-step": 3142}, {"errors": 0.08341774698822202, "time-step": 3143}, {"errors": 0.08338644507861878, "time-step": 3144}, {"errors": 0.08335510998527208, "time-step": 3145}, {"errors": 0.08332374156663641, "time-step": 3146}, {"errors": 0.08329233968095043, "time-step": 3147}, {"errors": 0.08326090418623852, "time-step": 3148}, {"errors": 0.08322943494031214, "time-step": 3149}, {"errors": 0.08319793180077134, "time-step": 3150}, {"errors": 0.08316639462500647, "time-step": 3151}, {"errors": 0.08313482327019947, "time-step": 3152}, {"errors": 0.08310321759332562, "time-step": 3153}, {"errors": 0.0830715774511552, "time-step": 3154}, {"errors": 0.08303990270025491, "time-step": 3155}, {"errors": 0.08300819319698965, "time-step": 3156}, {"errors": 0.08297644879752425, "time-step": 3157}, {"errors": 0.082944669357825, "time-step": 3158}, {"errors": 0.08291285473366149, "time-step": 3159}, {"errors": 0.08288100478060834, "time-step": 3160}, {"errors": 0.08284911935404693, "time-step": 3161}, {"errors": 0.08281719830916724, "time-step": 3162}, {"errors": 0.08278524150096955, "time-step": 3163}, {"errors": 0.08275324878426644, "time-step": 3164}, {"errors": 0.08272122001368457, "time-step": 3165}, {"errors": 0.0826891550436666, "time-step": 3166}, {"errors": 0.08265705372847296, "time-step": 3167}, {"errors": 0.08262491592218404, "time-step": 3168}, {"errors": 0.08259274147870205, "time-step": 3169}, {"errors": 0.08256053025175285, "time-step": 3170}, {"errors": 0.08252828209488824, "time-step": 3171}, {"errors": 0.08249599686148776, "time-step": 3172}, {"errors": 0.0824636744047609, "time-step": 3173}, {"errors": 0.0824313145777492, "time-step": 3174}, {"errors": 0.08239891723332833, "time-step": 3175}, {"errors": 0.08236648222421013, "time-step": 3176}, {"errors": 0.08233400940294502, "time-step": 3177}, {"errors": 0.08230149862192393, "time-step": 3178}, {"errors": 0.08226894973338084, "time-step": 3179}, {"errors": 0.08223636258939476, "time-step": 3180}, {"errors": 0.08220373704189211, "time-step": 3181}, {"errors": 0.08217107294264904, "time-step": 3182}, {"errors": 0.08213837014329378, "time-step": 3183}, {"errors": 0.082105628495309, "time-step": 3184}, {"errors": 0.08207284785003402, "time-step": 3185}, {"errors": 0.08204002805866772, "time-step": 3186}, {"errors": 0.08200716897227037, "time-step": 3187}, {"errors": 0.08197427044176653, "time-step": 3188}, {"errors": 0.0819413323179474, "time-step": 3189}, {"errors": 0.08190835445147342, "time-step": 3190}, {"errors": 0.08187533669287674, "time-step": 3191}, {"errors": 0.08184227889256385, "time-step": 3192}, {"errors": 0.08180918090081829, "time-step": 3193}, {"errors": 0.08177604256780327, "time-step": 3194}, {"errors": 0.08174286374356404, "time-step": 3195}, {"errors": 0.08170964427803118, "time-step": 3196}, {"errors": 0.08167638402102281, "time-step": 3197}, {"errors": 0.08164308282224766, "time-step": 3198}, {"errors": 0.0816097405313077, "time-step": 3199}, {"errors": 0.08157635699770122, "time-step": 3200}, {"errors": 0.08154293207082522, "time-step": 3201}, {"errors": 0.08150946559997888, "time-step": 3202}, {"errors": 0.081475957434366, "time-step": 3203}, {"errors": 0.08144240742309819, "time-step": 3204}, {"errors": 0.08140881541519776, "time-step": 3205}, {"errors": 0.08137518125960082, "time-step": 3206}, {"errors": 0.08134150480516017, "time-step": 3207}, {"errors": 0.08130778590064856, "time-step": 3208}, {"errors": 0.08127402439476163, "time-step": 3209}, {"errors": 0.08124022013612114, "time-step": 3210}, {"errors": 0.08120637297327808, "time-step": 3211}, {"errors": 0.08117248275471589, "time-step": 3212}, {"errors": 0.08113854932885364, "time-step": 3213}, {"errors": 0.08110457254404946, "time-step": 3214}, {"errors": 0.08107055224860352, "time-step": 3215}, {"errors": 0.08103648829076165, "time-step": 3216}, {"errors": 0.08100238051871865, "time-step": 3217}, {"errors": 0.08096822878062138, "time-step": 3218}, {"errors": 0.08093403292457255, "time-step": 3219}, {"errors": 0.08089979279863407, "time-step": 3220}, {"errors": 0.08086550825083025, "time-step": 3221}, {"errors": 0.08083117912915182, "time-step": 3222}, {"errors": 0.08079680528155903, "time-step": 3223}, {"errors": 0.08076238655598539, "time-step": 3224}, {"errors": 0.08072792280034137, "time-step": 3225}, {"errors": 0.08069341386251797, "time-step": 3226}, {"errors": 0.08065885959039021, "time-step": 3227}, {"errors": 0.08062425983182124, "time-step": 3228}, {"errors": 0.0805896144346657, "time-step": 3229}, {"errors": 0.08055492324677369, "time-step": 3230}, {"errors": 0.0805201861159946, "time-step": 3231}, {"errors": 0.0804854028901807, "time-step": 3232}, {"errors": 0.08045057341719139, "time-step": 3233}, {"errors": 0.08041569754489683, "time-step": 3234}, {"errors": 0.08038077512118187, "time-step": 3235}, {"errors": 0.08034580599395028, "time-step": 3236}, {"errors": 0.08031079001112834, "time-step": 3237}, {"errors": 0.0802757270206693, "time-step": 3238}, {"errors": 0.08024061687055725, "time-step": 3239}, {"errors": 0.08020545940881121, "time-step": 3240}, {"errors": 0.08017025448348912, "time-step": 3241}, {"errors": 0.08013500194269242, "time-step": 3242}, {"errors": 0.08009970163456992, "time-step": 3243}, {"errors": 0.08006435340732201, "time-step": 3244}, {"errors": 0.08002895710920516, "time-step": 3245}, {"errors": 0.07999351258853615, "time-step": 3246}, {"errors": 0.07995801969369615, "time-step": 3247}, {"errors": 0.07992247827313545, "time-step": 3248}, {"errors": 0.07988688817537769, "time-step": 3249}, {"errors": 0.07985124924902415, "time-step": 3250}, {"errors": 0.07981556134275852, "time-step": 3251}, {"errors": 0.07977982430535119, "time-step": 3252}, {"errors": 0.07974403798566373, "time-step": 3253}, {"errors": 0.07970820223265379, "time-step": 3254}, {"errors": 0.07967231689537921, "time-step": 3255}, {"errors": 0.07963638182300299, "time-step": 3256}, {"errors": 0.07960039686479789, "time-step": 3257}, {"errors": 0.07956436187015106, "time-step": 3258}, {"errors": 0.07952827668856885, "time-step": 3259}, {"errors": 0.0794921411696814, "time-step": 3260}, {"errors": 0.07945595516324772, "time-step": 3261}, {"errors": 0.07941971851916022, "time-step": 3262}, {"errors": 0.07938343108744976, "time-step": 3263}, {"errors": 0.07934709271829041, "time-step": 3264}, {"errors": 0.07931070326200446, "time-step": 3265}, {"errors": 0.07927426256906736, "time-step": 3266}, {"errors": 0.07923777049011266, "time-step": 3267}, {"errors": 0.07920122687593714, "time-step": 3268}, {"errors": 0.07916463157750567, "time-step": 3269}, {"errors": 0.0791279844459564, "time-step": 3270}, {"errors": 0.07909128533260593, "time-step": 3271}, {"errors": 0.07905453408895438, "time-step": 3272}, {"errors": 0.07901773056669051, "time-step": 3273}, {"errors": 0.07898087461769702, "time-step": 3274}, {"errors": 0.07894396609405582, "time-step": 3275}, {"errors": 0.07890700484805314, "time-step": 3276}, {"errors": 0.07886999073218492, "time-step": 3277}, {"errors": 0.07883292359916225, "time-step": 3278}, {"errors": 0.07879580330191646, "time-step": 3279}, {"errors": 0.07875862969360481, "time-step": 3280}, {"errors": 0.07872140262761562, "time-step": 3281}, {"errors": 0.078684121957574, "time-step": 3282}, {"errors": 0.07864678753734705, "time-step": 3283}, {"errors": 0.07860939922104965, "time-step": 3284}, {"errors": 0.07857195686304971, "time-step": 3285}, {"errors": 0.07853446031797406, "time-step": 3286}, {"errors": 0.07849690944071375, "time-step": 3287}, {"errors": 0.07845930408642973, "time-step": 3288}, {"errors": 0.07842164411055878, "time-step": 3289}, {"errors": 0.07838392936881877, "time-step": 3290}, {"errors": 0.07834615971721459, "time-step": 3291}, {"errors": 0.07830833501204401, "time-step": 3292}, {"errors": 0.0782704551099032, "time-step": 3293}, {"errors": 0.07823251986769264, "time-step": 3294}, {"errors": 0.07819452914262301, "time-step": 3295}, {"errors": 0.07815648279222084, "time-step": 3296}, {"errors": 0.07811838067433459, "time-step": 3297}, {"errors": 0.07808022264714037, "time-step": 3298}, {"errors": 0.07804200856914795, "time-step": 3299}, {"errors": 0.07800373829920688, "time-step": 3300}, {"errors": 0.0779654116965121, "time-step": 3301}, {"errors": 0.0779270286206103, "time-step": 3302}, {"errors": 0.07788858893140557, "time-step": 3303}, {"errors": 0.07785009248916591, "time-step": 3304}, {"errors": 0.07781153915452901, "time-step": 3305}, {"errors": 0.07777292878850832, "time-step": 3306}, {"errors": 0.07773426125249938, "time-step": 3307}, {"errors": 0.07769553640828569, "time-step": 3308}, {"errors": 0.07765675411804525, "time-step": 3309}, {"errors": 0.0776179142443564, "time-step": 3310}, {"errors": 0.07757901665020417, "time-step": 3311}, {"errors": 0.07754006119898667, "time-step": 3312}, {"errors": 0.07750104775452113, "time-step": 3313}, {"errors": 0.07746197618105022, "time-step": 3314}, {"errors": 0.07742284634324847, "time-step": 3315}, {"errors": 0.07738365810622855, "time-step": 3316}, {"errors": 0.07734441133554751, "time-step": 3317}, {"errors": 0.07730510589721327, "time-step": 3318}, {"errors": 0.07726574165769098, "time-step": 3319}, {"errors": 0.07722631848390936, "time-step": 3320}, {"errors": 0.07718683624326711, "time-step": 3321}, {"errors": 0.07714729480363966, "time-step": 3322}, {"errors": 0.07710769403338502, "time-step": 3323}, {"errors": 0.07706803380135091, "time-step": 3324}, {"errors": 0.07702831397688086, "time-step": 3325}, {"errors": 0.07698853442982076, "time-step": 3326}, {"errors": 0.07694869503052555, "time-step": 3327}, {"errors": 0.07690879564986564, "time-step": 3328}, {"errors": 0.07686883615923348, "time-step": 3329}, {"errors": 0.0768288164305501, "time-step": 3330}, {"errors": 0.07678873633627195, "time-step": 3331}, {"errors": 0.07674859574939717, "time-step": 3332}, {"errors": 0.07670839454347224, "time-step": 3333}, {"errors": 0.076668132592599, "time-step": 3334}, {"errors": 0.07662780977144082, "time-step": 3335}, {"errors": 0.07658742595522955, "time-step": 3336}, {"errors": 0.07654698101977198, "time-step": 3337}, {"errors": 0.0765064748414568, "time-step": 3338}, {"errors": 0.07646590729726108, "time-step": 3339}, {"errors": 0.07642527826475687, "time-step": 3340}, {"errors": 0.07638458762211847, "time-step": 3341}, {"errors": 0.07634383524812832, "time-step": 3342}, {"errors": 0.07630302102218445, "time-step": 3343}, {"errors": 0.07626214482430696, "time-step": 3344}, {"errors": 0.0762212065351445, "time-step": 3345}, {"errors": 0.07618020603598155, "time-step": 3346}, {"errors": 0.0761391432087449, "time-step": 3347}, {"errors": 0.07609801793601029, "time-step": 3348}, {"errors": 0.07605683010100955, "time-step": 3349}, {"errors": 0.07601557958763697, "time-step": 3350}, {"errors": 0.07597426628045648, "time-step": 3351}, {"errors": 0.07593289006470827, "time-step": 3352}, {"errors": 0.07589145082631549, "time-step": 3353}, {"errors": 0.07584994845189115, "time-step": 3354}, {"errors": 0.07580838282874502, "time-step": 3355}, {"errors": 0.07576675384489037, "time-step": 3356}, {"errors": 0.07572506138905064, "time-step": 3357}, {"errors": 0.07568330535066645, "time-step": 3358}, {"errors": 0.07564148561990239, "time-step": 3359}, {"errors": 0.07559960208765358, "time-step": 3360}, {"errors": 0.07555765464555297, "time-step": 3361}, {"errors": 0.07551564318597767, "time-step": 3362}, {"errors": 0.07547356760205606, "time-step": 3363}, {"errors": 0.0754314277876744, "time-step": 3364}, {"errors": 0.07538922363748388, "time-step": 3365}, {"errors": 0.07534695504690714, "time-step": 3366}, {"errors": 0.07530462191214546, "time-step": 3367}, {"errors": 0.07526222413018496, "time-step": 3368}, {"errors": 0.07521976159880411, "time-step": 3369}, {"errors": 0.07517723421657982, "time-step": 3370}, {"errors": 0.07513464188289493, "time-step": 3371}, {"errors": 0.0750919844979443, "time-step": 3372}, {"errors": 0.07504926196274204, "time-step": 3373}, {"errors": 0.07500647417912812, "time-step": 3374}, {"errors": 0.07496362104977507, "time-step": 3375}, {"errors": 0.07492070247819488, "time-step": 3376}, {"errors": 0.0748777183687456, "time-step": 3377}, {"errors": 0.07483466862663807, "time-step": 3378}, {"errors": 0.07479155315794264, "time-step": 3379}, {"errors": 0.07474837186959604, "time-step": 3380}, {"errors": 0.07470512466940779, "time-step": 3381}, {"errors": 0.07466181146606715, "time-step": 3382}, {"errors": 0.07461843216914954, "time-step": 3383}, {"errors": 0.07457498668912349, "time-step": 3384}, {"errors": 0.07453147493735685, "time-step": 3385}, {"errors": 0.07448789682612392, "time-step": 3386}, {"errors": 0.0744442522686117, "time-step": 3387}, {"errors": 0.07440054117892661, "time-step": 3388}, {"errors": 0.07435676347210102, "time-step": 3389}, {"errors": 0.07431291906409992, "time-step": 3390}, {"errors": 0.07426900787182736, "time-step": 3391}, {"errors": 0.07422502981313293, "time-step": 3392}, {"errors": 0.07418098480681845, "time-step": 3393}, {"errors": 0.07413687277264429, "time-step": 3394}, {"errors": 0.07409269363133592, "time-step": 3395}, {"errors": 0.07404844730459023, "time-step": 3396}, {"errors": 0.07400413371508228, "time-step": 3397}, {"errors": 0.07395975278647118, "time-step": 3398}, {"errors": 0.07391530444340705, "time-step": 3399}, {"errors": 0.073870788611537, "time-step": 3400}, {"errors": 0.07382620521751138, "time-step": 3401}, {"errors": 0.0737815541889906, "time-step": 3402}, {"errors": 0.07373683545465085, "time-step": 3403}, {"errors": 0.07369204894419067, "time-step": 3404}, {"errors": 0.07364719458833716, "time-step": 3405}, {"errors": 0.07360227231885214, "time-step": 3406}, {"errors": 0.07355728206853826, "time-step": 3407}, {"errors": 0.07351222377124536, "time-step": 3408}, {"errors": 0.07346709736187629, "time-step": 3409}, {"errors": 0.07342190277639335, "time-step": 3410}, {"errors": 0.07337663995182414, "time-step": 3411}, {"errors": 0.07333130882626769, "time-step": 3412}, {"errors": 0.07328590933890032, "time-step": 3413}, {"errors": 0.07324044142998193, "time-step": 3414}, {"errors": 0.07319490504086146, "time-step": 3415}, {"errors": 0.07314930011398328, "time-step": 3416}, {"errors": 0.07310362659289299, "time-step": 3417}, {"errors": 0.07305788442224287, "time-step": 3418}, {"errors": 0.0730120735477982, "time-step": 3419}, {"errors": 0.07296619391644282, "time-step": 3420}, {"errors": 0.07292024547618475, "time-step": 3421}, {"errors": 0.07287422817616215, "time-step": 3422}, {"errors": 0.07282814196664882, "time-step": 3423}, {"errors": 0.0727819867990599, "time-step": 3424}, {"errors": 0.07273576262595749, "time-step": 3425}, {"errors": 0.07268946940105625, "time-step": 3426}, {"errors": 0.07264310707922875, "time-step": 3427}, {"errors": 0.07259667561651112, "time-step": 3428}, {"errors": 0.07255017497010852, "time-step": 3429}, {"errors": 0.07250360509840048, "time-step": 3430}, {"errors": 0.07245696596094622, "time-step": 3431}, {"errors": 0.07241025751849008, "time-step": 3432}, {"errors": 0.0723634797329667, "time-step": 3433}, {"errors": 0.07231663256750655, "time-step": 3434}, {"errors": 0.0722697159864407, "time-step": 3435}, {"errors": 0.07222272995530635, "time-step": 3436}, {"errors": 0.07217567444085182, "time-step": 3437}, {"errors": 0.07212854941104152, "time-step": 3438}, {"errors": 0.07208135483506117, "time-step": 3439}, {"errors": 0.07203409068332278, "time-step": 3440}, {"errors": 0.07198675692746945, "time-step": 3441}, {"errors": 0.07193935354038028, "time-step": 3442}, {"errors": 0.07189188049617551, "time-step": 3443}, {"errors": 0.07184433777022112, "time-step": 3444}, {"errors": 0.07179672533913332, "time-step": 3445}, {"errors": 0.07174904318078393, "time-step": 3446}, {"errors": 0.07170129127430441, "time-step": 3447}, {"errors": 0.071653469600091, "time-step": 3448}, {"errors": 0.07160557813980886, "time-step": 3449}, {"errors": 0.07155761687639683, "time-step": 3450}, {"errors": 0.07150958579407207, "time-step": 3451}, {"errors": 0.071461484878334, "time-step": 3452}, {"errors": 0.07141331411596932, "time-step": 3453}, {"errors": 0.07136507349505582, "time-step": 3454}, {"errors": 0.07131676300496691, "time-step": 3455}, {"errors": 0.07126838263637587, "time-step": 3456}, {"errors": 0.07121993238125998, "time-step": 3457}, {"errors": 0.07117141223290452, "time-step": 3458}, {"errors": 0.07112282218590726, "time-step": 3459}, {"errors": 0.071074162236182, "time-step": 3460}, {"errors": 0.07102543238096284, "time-step": 3461}, {"errors": 0.07097663261880816, "time-step": 3462}, {"errors": 0.07092776294960423, "time-step": 3463}, {"errors": 0.07087882337456933, "time-step": 3464}, {"errors": 0.07082981389625734, "time-step": 3465}, {"errors": 0.0707807345185615, "time-step": 3466}, {"errors": 0.07073158524671815, "time-step": 3467}, {"errors": 0.07068236608731016, "time-step": 3468}, {"errors": 0.07063307704827085, "time-step": 3469}, {"errors": 0.07058371813888696, "time-step": 3470}, {"errors": 0.07053428936980266, "time-step": 3471}, {"errors": 0.07048479075302255, "time-step": 3472}, {"errors": 0.0704352223019152, "time-step": 3473}, {"errors": 0.07038558403121642, "time-step": 3474}, {"errors": 0.07033587595703235, "time-step": 3475}, {"errors": 0.07028609809684291, "time-step": 3476}, {"errors": 0.07023625046950469, "time-step": 3477}, {"errors": 0.07018633309525404, "time-step": 3478}, {"errors": 0.07013634599571023, "time-step": 3479}, {"errors": 0.07008628919387817, "time-step": 3480}, {"errors": 0.07003616271415172, "time-step": 3481}, {"errors": 0.06998596658231604, "time-step": 3482}, {"errors": 0.06993570082555059, "time-step": 3483}, {"errors": 0.06988536547243215, "time-step": 3484}, {"errors": 0.06983496055293695, "time-step": 3485}, {"errors": 0.06978448609844376, "time-step": 3486}, {"errors": 0.06973394214173613, "time-step": 3487}, {"errors": 0.06968332871700511, "time-step": 3488}, {"errors": 0.06963264585985166, "time-step": 3489}, {"errors": 0.06958189360728884, "time-step": 3490}, {"errors": 0.06953107199774447, "time-step": 3491}, {"errors": 0.06948018107106323, "time-step": 3492}, {"errors": 0.06942922086850888, "time-step": 3493}, {"errors": 0.06937819143276638, "time-step": 3494}, {"errors": 0.06932709280794419, "time-step": 3495}, {"errors": 0.06927592503957615, "time-step": 3496}, {"errors": 0.06922468817462342, "time-step": 3497}, {"errors": 0.06917338226147668, "time-step": 3498}, {"errors": 0.06912200734995769, "time-step": 3499}, {"errors": 0.0690705634913214, "time-step": 3500}, {"errors": 0.06901905073825752, "time-step": 3501}, {"errors": 0.06896746914489223, "time-step": 3502}, {"errors": 0.06891581876678994, "time-step": 3503}, {"errors": 0.06886409966095494, "time-step": 3504}, {"errors": 0.0688123118858325, "time-step": 3505}, {"errors": 0.0687604555013111, "time-step": 3506}, {"errors": 0.06870853056872306, "time-step": 3507}, {"errors": 0.06865653715084641, "time-step": 3508}, {"errors": 0.06860447531190603, "time-step": 3509}, {"errors": 0.06855234511757508, "time-step": 3510}, {"errors": 0.06850014663497565, "time-step": 3511}, {"errors": 0.06844787993268066, "time-step": 3512}, {"errors": 0.06839554508071428, "time-step": 3513}, {"errors": 0.0683431421505534, "time-step": 3514}, {"errors": 0.0682906712151283, "time-step": 3515}, {"errors": 0.06823813234882388, "time-step": 3516}, {"errors": 0.06818552562748002, "time-step": 3517}, {"errors": 0.06813285112839276, "time-step": 3518}, {"errors": 0.06808010893031505, "time-step": 3519}, {"errors": 0.06802729911345727, "time-step": 3520}, {"errors": 0.06797442175948781, "time-step": 3521}, {"errors": 0.06792147695153389, "time-step": 3522}, {"errors": 0.06786846477418175, "time-step": 3523}, {"errors": 0.06781538531347737, "time-step": 3524}, {"errors": 0.06776223865692688, "time-step": 3525}, {"errors": 0.06770902489349657, "time-step": 3526}, {"errors": 0.06765574411361364, "time-step": 3527}, {"errors": 0.06760239640916613, "time-step": 3528}, {"errors": 0.06754898187350307, "time-step": 3529}, {"errors": 0.06749550060143489, "time-step": 3530}, {"errors": 0.06744195268923328, "time-step": 3531}, {"errors": 0.0673883382346312, "time-step": 3532}, {"errors": 0.06733465733682292, "time-step": 3533}, {"errors": 0.06728091009646385, "time-step": 3534}, {"errors": 0.06722709661567053, "time-step": 3535}, {"errors": 0.06717321699802023, "time-step": 3536}, {"errors": 0.06711927134855086, "time-step": 3537}, {"errors": 0.06706525977376063, "time-step": 3538}, {"errors": 0.06701118238160757, "time-step": 3539}, {"errors": 0.06695703928150937, "time-step": 3540}, {"errors": 0.06690283058434246, "time-step": 3541}, {"errors": 0.06684855640244214, "time-step": 3542}, {"errors": 0.06679421684960135, "time-step": 3543}, {"errors": 0.06673981204107046, "time-step": 3544}, {"errors": 0.06668534209355649, "time-step": 3545}, {"errors": 0.06663080712522225, "time-step": 3546}, {"errors": 0.06657620725568571, "time-step": 3547}, {"errors": 0.06652154260601915, "time-step": 3548}, {"errors": 0.06646681329874816, "time-step": 3549}, {"errors": 0.06641201945785083, "time-step": 3550}, {"errors": 0.06635716120875677, "time-step": 3551}, {"errors": 0.06630223867834589, "time-step": 3552}, {"errors": 0.06624725199494741, "time-step": 3553}, {"errors": 0.0661922012883388, "time-step": 3554}, {"errors": 0.06613708668974455, "time-step": 3555}, {"errors": 0.06608190833183489, "time-step": 3556}, {"errors": 0.06602666634872445, "time-step": 3557}, {"errors": 0.06597136087597086, "time-step": 3558}, {"errors": 0.06591599205057369, "time-step": 3559}, {"errors": 0.06586056001097271, "time-step": 3560}, {"errors": 0.06580506489704642, "time-step": 3561}, {"errors": 0.0657495068501106, "time-step": 3562}, {"errors": 0.06569388601291669, "time-step": 3563}, {"errors": 0.0656382025296501, "time-step": 3564}, {"errors": 0.06558245654592865, "time-step": 3565}, {"errors": 0.06552664820880061, "time-step": 3566}, {"errors": 0.06547077766674335, "time-step": 3567}, {"errors": 0.06541484506966094, "time-step": 3568}, {"errors": 0.06535885056888267, "time-step": 3569}, {"errors": 0.06530279431716102, "time-step": 3570}, {"errors": 0.06524667646866969, "time-step": 3571}, {"errors": 0.06519049717900155, "time-step": 3572}, {"errors": 0.06513425660516658, "time-step": 3573}, {"errors": 0.06507795490558979, "time-step": 3574}, {"errors": 0.06502159224010907, "time-step": 3575}, {"errors": 0.064965168769973, "time-step": 3576}, {"errors": 0.06490868465783844, "time-step": 3577}, {"errors": 0.0648521400677684, "time-step": 3578}, {"errors": 0.06479553516522973, "time-step": 3579}, {"errors": 0.06473887011709072, "time-step": 3580}, {"errors": 0.06468214509161825, "time-step": 3581}, {"errors": 0.06462536025847607, "time-step": 3582}, {"errors": 0.06456851578872169, "time-step": 3583}, {"errors": 0.06451161185480404, "time-step": 3584}, {"errors": 0.06445464863056077, "time-step": 3585}, {"errors": 0.06439762629121565, "time-step": 3586}, {"errors": 0.06434054501337588, "time-step": 3587}, {"errors": 0.0642834049750294, "time-step": 3588}, {"errors": 0.06422620635554185, "time-step": 3589}, {"errors": 0.0641689493356541, "time-step": 3590}, {"errors": 0.06411163409747912, "time-step": 3591}, {"errors": 0.06405426082449912, "time-step": 3592}, {"errors": 0.06399682970156259, "time-step": 3593}, {"errors": 0.06393934091488147, "time-step": 3594}, {"errors": 0.06388179465202763, "time-step": 3595}, {"errors": 0.0638241911019305, "time-step": 3596}, {"errors": 0.06376653045487307, "time-step": 3597}, {"errors": 0.06370881290248968, "time-step": 3598}, {"errors": 0.06365103863776189, "time-step": 3599}, {"errors": 0.06359320785501592, "time-step": 3600}, {"errors": 0.0635353207499189, "time-step": 3601}, {"errors": 0.06347737751947569, "time-step": 3602}, {"errors": 0.06341937836202564, "time-step": 3603}, {"errors": 0.06336132347723891, "time-step": 3604}, {"errors": 0.06330321306611307, "time-step": 3605}, {"errors": 0.06324504733096982, "time-step": 3606}, {"errors": 0.06318682647545117, "time-step": 3607}, {"errors": 0.06312855070451591, "time-step": 3608}, {"errors": 0.0630702202244359, "time-step": 3609}, {"errors": 0.06301183524279286, "time-step": 3610}, {"errors": 0.06295339596847396, "time-step": 3611}, {"errors": 0.06289490261166855, "time-step": 3612}, {"errors": 0.06283635538386426, "time-step": 3613}, {"errors": 0.06277775449784312, "time-step": 3614}, {"errors": 0.06271910016767769, "time-step": 3615}, {"errors": 0.06266039260872716, "time-step": 3616}, {"errors": 0.06260163203763328, "time-step": 3617}, {"errors": 0.06254281867231683, "time-step": 3618}, {"errors": 0.062483952731972825, "time-step": 3619}, {"errors": 0.06242503443706708, "time-step": 3620}, {"errors": 0.062366064009331895, "time-step": 3621}, {"errors": 0.06230704167176171, "time-step": 3622}, {"errors": 0.06224796764860923, "time-step": 3623}, {"errors": 0.062188842165380995, "time-step": 3624}, {"errors": 0.06212966544883317, "time-step": 3625}, {"errors": 0.06207043772696719, "time-step": 3626}, {"errors": 0.06201115922902539, "time-step": 3627}, {"errors": 0.061951830185486854, "time-step": 3628}, {"errors": 0.061892450828062634, "time-step": 3629}, {"errors": 0.061833021389691385, "time-step": 3630}, {"errors": 0.061773542104535145, "time-step": 3631}, {"errors": 0.0617140132079744, "time-step": 3632}, {"errors": 0.06165443493660358, "time-step": 3633}, {"errors": 0.061594807528226866, "time-step": 3634}, {"errors": 0.06153513122185275, "time-step": 3635}, {"errors": 0.061475406257690005, "time-step": 3636}, {"errors": 0.06141563287714272, "time-step": 3637}, {"errors": 0.061355811322805376, "time-step": 3638}, {"errors": 0.061295941838458295, "time-step": 3639}, {"errors": 0.061236024669062424, "time-step": 3640}, {"errors": 0.06117606006075492, "time-step": 3641}, {"errors": 0.06111604826084377, "time-step": 3642}, {"errors": 0.06105598951780314, "time-step": 3643}, {"errors": 0.060995884081268034, "time-step": 3644}, {"errors": 0.06093573220202972, "time-step": 3645}, {"errors": 0.06087553413203009, "time-step": 3646}, {"errors": 0.060815290124356866, "time-step": 3647}, {"errors": 0.060755000433238615, "time-step": 3648}, {"errors": 0.060694665314038956, "time-step": 3649}, {"errors": 0.060634285023251897, "time-step": 3650}, {"errors": 0.06057385981849624, "time-step": 3651}, {"errors": 0.06051338995851034, "time-step": 3652}, {"errors": 0.06045287570314685, "time-step": 3653}, {"errors": 0.06039231731336702, "time-step": 3654}, {"errors": 0.060331715051235746, "time-step": 3655}, {"errors": 0.06027106917991564, "time-step": 3656}, {"errors": 0.06021037996366174, "time-step": 3657}, {"errors": 0.06014964766781597, "time-step": 3658}, {"errors": 0.06008887255880152, "time-step": 3659}, {"errors": 0.060028054904117126, "time-step": 3660}, {"errors": 0.059967194972331606, "time-step": 3661}, {"errors": 0.059906293033077956, "time-step": 3662}, {"errors": 0.05984534935704779, "time-step": 3663}, {"errors": 0.05978436421598536, "time-step": 3664}, {"errors": 0.059723337882681915, "time-step": 3665}, {"errors": 0.059662270630969884, "time-step": 3666}, {"errors": 0.059601162735716647, "time-step": 3667}, {"errors": 0.059540014472819015, "time-step": 3668}, {"errors": 0.05947882611919706, "time-step": 3669}, {"errors": 0.059417597952788156, "time-step": 3670}, {"errors": 0.05935633025254086, "time-step": 3671}, {"errors": 0.059295023298408925, "time-step": 3672}, {"errors": 0.059233677371345064, "time-step": 3673}, {"errors": 0.05917229275329492, "time-step": 3674}, {"errors": 0.05911086972719091, "time-step": 3675}, {"errors": 0.059049408576945656, "time-step": 3676}, {"errors": 0.058987909587446166, "time-step": 3677}, {"errors": 0.05892637304454713, "time-step": 3678}, {"errors": 0.05886479923506498, "time-step": 3679}, {"errors": 0.05880318844677103, "time-step": 3680}, {"errors": 0.058741540968385325, "time-step": 3681}, {"errors": 0.058679857089570325, "time-step": 3682}, {"errors": 0.05861813710092404, "time-step": 3683}, {"errors": 0.05855638129397369, "time-step": 3684}, {"errors": 0.058494589961169186, "time-step": 3685}, {"errors": 0.05843276339587651, "time-step": 3686}, {"errors": 0.058370901892370694, "time-step": 3687}, {"errors": 0.0583090057458298, "time-step": 3688}, {"errors": 0.05824707525232753, "time-step": 3689}, {"errors": 0.058185110708826995, "time-step": 3690}, {"errors": 0.05812311241317353, "time-step": 3691}, {"errors": 0.05806108066408801, "time-step": 3692}, {"errors": 0.057999015761160094, "time-step": 3693}, {"errors": 0.057936918004840944, "time-step": 3694}, {"errors": 0.05787478769643687, "time-step": 3695}, {"errors": 0.0578126251381015, "time-step": 3696}, {"errors": 0.05775043063282978, "time-step": 3697}, {"errors": 0.0576882044844499, "time-step": 3698}, {"errors": 0.05762594699761694, "time-step": 3699}, {"errors": 0.05756365847780551, "time-step": 3700}, {"errors": 0.05750133923130223, "time-step": 3701}, {"errors": 0.057438989565199175, "time-step": 3702}, {"errors": 0.057376609787386054, "time-step": 3703}, {"errors": 0.057314200206543174, "time-step": 3704}, {"errors": 0.05725176113213415, "time-step": 3705}, {"errors": 0.05718929287439849, "time-step": 3706}, {"errors": 0.05712679574434419, "time-step": 3707}, {"errors": 0.057064270053740374, "time-step": 3708}, {"errors": 0.05700171611510978, "time-step": 3709}, {"errors": 0.056939134241721166, "time-step": 3710}, {"errors": 0.05687652474758204, "time-step": 3711}, {"errors": 0.056813887947430794, "time-step": 3712}, {"errors": 0.05675122415672938, "time-step": 3713}, {"errors": 0.05668853369165536, "time-step": 3714}, {"errors": 0.05662581686909457, "time-step": 3715}, {"errors": 0.056563074006633074, "time-step": 3716}, {"errors": 0.056500305422549704, "time-step": 3717}, {"errors": 0.056437511435808205, "time-step": 3718}, {"errors": 0.056374692366049126, "time-step": 3719}, {"errors": 0.0563118485335825, "time-step": 3720}, {"errors": 0.05624898025937959, "time-step": 3721}, {"errors": 0.05618608786506509, "time-step": 3722}, {"errors": 0.05612317167290902, "time-step": 3723}, {"errors": 0.0560602320058191, "time-step": 3724}, {"errors": 0.05599726918733236, "time-step": 3725}, {"errors": 0.05593428354160729, "time-step": 3726}, {"errors": 0.05587127539341574, "time-step": 3727}, {"errors": 0.055808245068134754, "time-step": 3728}, {"errors": 0.05574519289173844, "time-step": 3729}, {"errors": 0.05568211919078983, "time-step": 3730}, {"errors": 0.055619024292432574, "time-step": 3731}, {"errors": 0.05555590852438288, "time-step": 3732}, {"errors": 0.055492772214921, "time-step": 3733}, {"errors": 0.05542961569288317, "time-step": 3734}, {"errors": 0.05536643928765299, "time-step": 3735}, {"errors": 0.05530324332915343, "time-step": 3736}, {"errors": 0.055240028147837975, "time-step": 3737}, {"errors": 0.055176794074682685, "time-step": 3738}, {"errors": 0.055113541441177305, "time-step": 3739}, {"errors": 0.05505027057931708, "time-step": 3740}, {"errors": 0.05498698182159406, "time-step": 3741}, {"errors": 0.05492367550098871, "time-step": 3742}, {"errors": 0.054860351950961186, "time-step": 3743}, {"errors": 0.05479701150544286, "time-step": 3744}, {"errors": 0.05473365449882746, "time-step": 3745}, {"errors": 0.054670281265962725, "time-step": 3746}, {"errors": 0.054606892142141636, "time-step": 3747}, {"errors": 0.054543487463093454, "time-step": 3748}, {"errors": 0.054480067564975226, "time-step": 3749}, {"errors": 0.054416632784363074, "time-step": 3750}, {"errors": 0.05435318345824312, "time-step": 3751}, {"errors": 0.054289719924003006, "time-step": 3752}, {"errors": 0.05422624251942271, "time-step": 3753}, {"errors": 0.05416275158266596, "time-step": 3754}, {"errors": 0.05409924745227127, "time-step": 3755}, {"errors": 0.054035730467142815, "time-step": 3756}, {"errors": 0.053972200966541775, "time-step": 3757}, {"errors": 0.053908659290077335, "time-step": 3758}, {"errors": 0.053845105777697425, "time-step": 3759}, {"errors": 0.053781540769680045, "time-step": 3760}, {"errors": 0.0537179646066241, "time-step": 3761}, {"errors": 0.05365437762944025, "time-step": 3762}, {"errors": 0.053590780179341935, "time-step": 3763}, {"errors": 0.053527172597836264, "time-step": 3764}, {"errors": 0.0534635552267151, "time-step": 3765}, {"errors": 0.053399928408045375, "time-step": 3766}, {"errors": 0.0533362924841605, "time-step": 3767}, {"errors": 0.053272647797650965, "time-step": 3768}, {"errors": 0.05320899469135512, "time-step": 3769}, {"errors": 0.053145333508349935, "time-step": 3770}, {"errors": 0.053081664591941906, "time-step": 3771}, {"errors": 0.05301798828565771, "time-step": 3772}, {"errors": 0.052954304933234886, "time-step": 3773}, {"errors": 0.0528906148786127, "time-step": 3774}, {"errors": 0.052826918465922766, "time-step": 3775}, {"errors": 0.052763216039479616, "time-step": 3776}, {"errors": 0.0526995079437717, "time-step": 3777}, {"errors": 0.05263579452345167, "time-step": 3778}, {"errors": 0.052572076123327205, "time-step": 3779}, {"errors": 0.05250835308835168, "time-step": 3780}, {"errors": 0.05244462576361471, "time-step": 3781}, {"errors": 0.05238089449433264, "time-step": 3782}, {"errors": 0.05231715962583952, "time-step": 3783}, {"errors": 0.05225342150357714, "time-step": 3784}, {"errors": 0.05218968047308617, "time-step": 3785}, {"errors": 0.05212593687999621, "time-step": 3786}, {"errors": 0.05206219107001667, "time-step": 3787}, {"errors": 0.05199844338892711, "time-step": 3788}, {"errors": 0.05193469418256805, "time-step": 3789}, {"errors": 0.05187094379683116, "time-step": 3790}, {"errors": 0.051807192577649916, "time-step": 3791}, {"errors": 0.05174344087099016, "time-step": 3792}, {"errors": 0.05167968902284056, "time-step": 3793}, {"errors": 0.051615937379203156, "time-step": 3794}, {"errors": 0.05155218628608367, "time-step": 3795}, {"errors": 0.05148843608948211, "time-step": 3796}, {"errors": 0.05142468713538343, "time-step": 3797}, {"errors": 0.051360939769747635, "time-step": 3798}, {"errors": 0.051297194338500524, "time-step": 3799}, {"errors": 0.051233451187524134, "time-step": 3800}, {"errors": 0.051169710662647014, "time-step": 3801}, {"errors": 0.05110597310963502, "time-step": 3802}, {"errors": 0.0510422388741815, "time-step": 3803}, {"errors": 0.05097850830189779, "time-step": 3804}, {"errors": 0.05091478173830391, "time-step": 3805}, {"errors": 0.0508510595288187, "time-step": 3806}, {"errors": 0.050787342018750535, "time-step": 3807}, {"errors": 0.05072362955328781, "time-step": 3808}, {"errors": 0.0506599224774891, "time-step": 3809}, {"errors": 0.05059622113627406, "time-step": 3810}, {"errors": 0.0505325258744136, "time-step": 3811}, {"errors": 0.050468837036520484, "time-step": 3812}, {"errors": 0.050405154967039754, "time-step": 3813}, {"errors": 0.050341480010239414, "time-step": 3814}, {"errors": 0.050277812510200665, "time-step": 3815}, {"errors": 0.05021415281080868, "time-step": 3816}, {"errors": 0.050150501255742774, "time-step": 3817}, {"errors": 0.050086858188467365, "time-step": 3818}, {"errors": 0.050023223952222085, "time-step": 3819}, {"errors": 0.04995959889001271, "time-step": 3820}, {"errors": 0.04989598334460135, "time-step": 3821}, {"errors": 0.04983237765849734, "time-step": 3822}, {"errors": 0.04976878217394748, "time-step": 3823}, {"errors": 0.049705197232926976, "time-step": 3824}, {"errors": 0.04964162317712975, "time-step": 3825}, {"errors": 0.04957806034795926, "time-step": 3826}, {"errors": 0.04951450908651889, "time-step": 3827}, {"errors": 0.049450969733602815, "time-step": 3828}, {"errors": 0.049387442629686626, "time-step": 3829}, {"errors": 0.04932392811491784, "time-step": 3830}, {"errors": 0.04926042652910685, "time-step": 3831}, {"errors": 0.049196938211717244, "time-step": 3832}, {"errors": 0.049133463501856975, "time-step": 3833}, {"errors": 0.04907000273826878, "time-step": 3834}, {"errors": 0.04900655625932099, "time-step": 3835}, {"errors": 0.04894312440299839, "time-step": 3836}, {"errors": 0.04887970750689313, "time-step": 3837}, {"errors": 0.04881630590819519, "time-step": 3838}, {"errors": 0.04875291994368347, "time-step": 3839}, {"errors": 0.0486895499497167, "time-step": 3840}, {"errors": 0.048626196262224225, "time-step": 3841}, {"errors": 0.04856285921669673, "time-step": 3842}, {"errors": 0.04849953914817751, "time-step": 3843}, {"errors": 0.04843623639125323, "time-step": 3844}, {"errors": 0.04837295128004513, "time-step": 3845}, {"errors": 0.04830968414819942, "time-step": 3846}, {"errors": 0.04824643532887912, "time-step": 3847}, {"errors": 0.04818320515475455, "time-step": 3848}, {"errors": 0.048119993957994614, "time-step": 3849}, {"errors": 0.04805680207025785, "time-step": 3850}, {"errors": 0.047993629822683744, "time-step": 3851}, {"errors": 0.04793047754588363, "time-step": 3852}, {"errors": 0.047867345569932065, "time-step": 3853}, {"errors": 0.04780423422435809, "time-step": 3854}, {"errors": 0.047741143838136324, "time-step": 3855}, {"errors": 0.047678074739678285, "time-step": 3856}, {"errors": 0.04761502725682399, "time-step": 3857}, {"errors": 0.0475520017168329, "time-step": 3858}, {"errors": 0.04748899844637559, "time-step": 3859}, {"errors": 0.04742601777152507, "time-step": 3860}, {"errors": 0.047363060017748336, "time-step": 3861}, {"errors": 0.047300125509897574, "time-step": 3862}, {"errors": 0.047237214572202126, "time-step": 3863}, {"errors": 0.04717432752825962, "time-step": 3864}, {"errors": 0.04711146470102798, "time-step": 3865}, {"errors": 0.04704862641281665, "time-step": 3866}, {"errors": 0.046985812985278555, "time-step": 3867}, {"errors": 0.04692302473940179, "time-step": 3868}, {"errors": 0.04686026199550118, "time-step": 3869}, {"errors": 0.0467975250732103, "time-step": 3870}, {"errors": 0.046734814291473074, "time-step": 3871}, {"errors": 0.046672129968535904, "time-step": 3872}, {"errors": 0.04660947242193932, "time-step": 3873}, {"errors": 0.04654684196851015, "time-step": 3874}, {"errors": 0.04648423892435333, "time-step": 3875}, {"errors": 0.04642166360484408, "time-step": 3876}, {"errors": 0.046359116324619934, "time-step": 3877}, {"errors": 0.04629659739757272, "time-step": 3878}, {"errors": 0.04623410713684109, "time-step": 3879}, {"errors": 0.046171645854802254, "time-step": 3880}, {"errors": 0.04610921386306457, "time-step": 3881}, {"errors": 0.04604681147245976, "time-step": 3882}, {"errors": 0.04598443899303516, "time-step": 3883}, {"errors": 0.04592209673404632, "time-step": 3884}, {"errors": 0.04585978500394913, "time-step": 3885}, {"errors": 0.04579750411039264, "time-step": 3886}, {"errors": 0.04573525436021128, "time-step": 3887}, {"errors": 0.04567303605941774, "time-step": 3888}, {"errors": 0.04561084951319531, "time-step": 3889}, {"errors": 0.045548695025890686, "time-step": 3890}, {"errors": 0.04548657290100686, "time-step": 3891}, {"errors": 0.04542448344119552, "time-step": 3892}, {"errors": 0.04536242694825025, "time-step": 3893}, {"errors": 0.0453004037230991, "time-step": 3894}, {"errors": 0.0452384140657978, "time-step": 3895}, {"errors": 0.04517645827552248, "time-step": 3896}, {"errors": 0.04511453665056284, "time-step": 3897}, {"errors": 0.04505264948831518, "time-step": 3898}, {"errors": 0.044990797085275654, "time-step": 3899}, {"errors": 0.04492897973703307, "time-step": 3900}, {"errors": 0.04486719773826282, "time-step": 3901}, {"errors": 0.04480545138271941, "time-step": 3902}, {"errors": 0.04474374096323032, "time-step": 3903}, {"errors": 0.04468206677168925, "time-step": 3904}, {"errors": 0.04462042909904951, "time-step": 3905}, {"errors": 0.04455882823531764, "time-step": 3906}, {"errors": 0.04449726446954691, "time-step": 3907}, {"errors": 0.044435738089830895, "time-step": 3908}, {"errors": 0.044374249383297315, "time-step": 3909}, {"errors": 0.044312798636101616, "time-step": 3910}, {"errors": 0.044251386133420806, "time-step": 3911}, {"errors": 0.04419001215944729, "time-step": 3912}, {"errors": 0.0441286769973828, "time-step": 3913}, {"errors": 0.04406738092943246, "time-step": 3914}, {"errors": 0.04400612423679842, "time-step": 3915}, {"errors": 0.04394490719967452, "time-step": 3916}, {"errors": 0.04388373009723985, "time-step": 3917}, {"errors": 0.0438225932076534, "time-step": 3918}, {"errors": 0.04376149680804799, "time-step": 3919}, {"errors": 0.04370044117452467, "time-step": 3920}, {"errors": 0.043639426582147325, "time-step": 3921}, {"errors": 0.04357845330493672, "time-step": 3922}, {"errors": 0.0435175216158652, "time-step": 3923}, {"errors": 0.04345663178685142, "time-step": 3924}, {"errors": 0.04339578408875443, "time-step": 3925}, {"errors": 0.04333497879136886, "time-step": 3926}, {"errors": 0.04327421616341953, "time-step": 3927}, {"errors": 0.04321349647255601, "time-step": 3928}, {"errors": 0.04315281998534779, "time-step": 3929}, {"errors": 0.04309218696727885, "time-step": 3930}, {"errors": 0.04303159768274306, "time-step": 3931}, {"errors": 0.042971052395038845, "time-step": 3932}, {"errors": 0.04291055136636446, "time-step": 3933}, {"errors": 0.04285009485781305, "time-step": 3934}, {"errors": 0.04278968312936811, "time-step": 3935}, {"errors": 0.04272931643989843, "time-step": 3936}, {"errors": 0.042668995047153754, "time-step": 3937}, {"errors": 0.04260871920775991, "time-step": 3938}, {"errors": 0.04254848917721457, "time-step": 3939}, {"errors": 0.042488305209882476, "time-step": 3940}, {"errors": 0.04242816755899138, "time-step": 3941}, {"errors": 0.04236807647662742, "time-step": 3942}, {"errors": 0.04230803221373105, "time-step": 3943}, {"errors": 0.04224803502009257, "time-step": 3944}, {"errors": 0.04218808514434829, "time-step": 3945}, {"errors": 0.04212818283397626, "time-step": 3946}, {"errors": 0.0420683283352922, "time-step": 3947}, {"errors": 0.04200852189344574, "time-step": 3948}, {"errors": 0.04194876375241635, "time-step": 3949}, {"errors": 0.041889054155009535, "time-step": 3950}, {"errors": 0.04182939334285323, "time-step": 3951}, {"errors": 0.04176978155639379, "time-step": 3952}, {"errors": 0.04171021903489261, "time-step": 3953}, {"errors": 0.04165070601642251, "time-step": 3954}, {"errors": 0.04159124273786406, "time-step": 3955}, {"errors": 0.0415318294349024, "time-step": 3956}, {"errors": 0.041472466342023534, "time-step": 3957}, {"errors": 0.041413153692511265, "time-step": 3958}, {"errors": 0.04135389171844388, "time-step": 3959}, {"errors": 0.04129468065069081, "time-step": 3960}, {"errors": 0.04123552071890969, "time-step": 3961}, {"errors": 0.04117641215154332, "time-step": 3962}, {"errors": 0.04111735517581634, "time-step": 3963}, {"errors": 0.04105835001773262, "time-step": 3964}, {"errors": 0.04099939690207233, "time-step": 3965}, {"errors": 0.04094049605238895, "time-step": 3966}, {"errors": 0.04088164769100672, "time-step": 3967}, {"errors": 0.040822852039017865, "time-step": 3968}, {"errors": 0.04076410931628004, "time-step": 3969}, {"errors": 0.04070541974141367, "time-step": 3970}, {"errors": 0.04064678353179948, "time-step": 3971}, {"errors": 0.04058820090357611, "time-step": 3972}, {"errors": 0.040529672071637796, "time-step": 3973}, {"errors": 0.040471197249631934, "time-step": 3974}, {"errors": 0.04041277664995686, "time-step": 3975}, {"errors": 0.04035441048375989, "time-step": 3976}, {"errors": 0.040296098960934834, "time-step": 3977}, {"errors": 0.0402378422901202, "time-step": 3978}, {"errors": 0.04017964067869719, "time-step": 3979}, {"errors": 0.0401214943327877, "time-step": 3980}, {"errors": 0.04006340345725244, "time-step": 3981}, {"errors": 0.0400053682556892, "time-step": 3982}, {"errors": 0.039947388930431066, "time-step": 3983}, {"errors": 0.0398894656825448, "time-step": 3984}, {"errors": 0.03983159871182905, "time-step": 3985}, {"errors": 0.039773788216813016, "time-step": 3986}, {"errors": 0.03971603439475485, "time-step": 3987}, {"errors": 0.0396583374416402, "time-step": 3988}, {"errors": 0.039600697552180854, "time-step": 3989}, {"errors": 0.03954311491981349, "time-step": 3990}, {"errors": 0.03948558973669822, "time-step": 3991}, {"errors": 0.039428122193717885, "time-step": 3992}, {"errors": 0.039370712480476217, "time-step": 3993}, {"errors": 0.03931336078529733, "time-step": 3994}, {"errors": 0.03925606729522453, "time-step": 3995}, {"errors": 0.03919883219601937, "time-step": 3996}, {"errors": 0.039141655672160755, "time-step": 3997}, {"errors": 0.03908453790684395, "time-step": 3998}, {"errors": 0.039027479081980246, "time-step": 3999}, {"errors": 0.03897047937819571, "time-step": 4000}, {"errors": 0.038913538974830957, "time-step": 4001}, {"errors": 0.03885665804994024, "time-step": 4002}, {"errors": 0.03879983678029131, "time-step": 4003}, {"errors": 0.038743075341364376, "time-step": 4004}, {"errors": 0.03868637390735222, "time-step": 4005}, {"errors": 0.03862973265115956, "time-step": 4006}, {"errors": 0.03857315174440268, "time-step": 4007}, {"errors": 0.03851663135740943, "time-step": 4008}, {"errors": 0.038460171659218875, "time-step": 4009}, {"errors": 0.03840377281758112, "time-step": 4010}, {"errors": 0.03834743499895733, "time-step": 4011}, {"errors": 0.038291158368519665, "time-step": 4012}, {"errors": 0.03823494309015138, "time-step": 4013}, {"errors": 0.0381787893264467, "time-step": 4014}, {"errors": 0.038122697238711256, "time-step": 4015}, {"errors": 0.03806666698696205, "time-step": 4016}, {"errors": 0.038010698729927836, "time-step": 4017}, {"errors": 0.03795479262504943, "time-step": 4018}, {"errors": 0.03789894882847989, "time-step": 4019}, {"errors": 0.03784316749508517, "time-step": 4020}, {"errors": 0.03778744877844458, "time-step": 4021}, {"errors": 0.03773179283085101, "time-step": 4022}, {"errors": 0.037676199803311855, "time-step": 4023}, {"errors": 0.03762066984554934, "time-step": 4024}, {"errors": 0.03756520310600169, "time-step": 4025}, {"errors": 0.03750979973182311, "time-step": 4026}, {"errors": 0.03745445986888524, "time-step": 4027}, {"errors": 0.037399183661777705, "time-step": 4028}, {"errors": 0.03734397125380897, "time-step": 4029}, {"errors": 0.03728882278700737, "time-step": 4030}, {"errors": 0.03723373840212204, "time-step": 4031}, {"errors": 0.03717871823862401, "time-step": 4032}, {"errors": 0.037123762434707164, "time-step": 4033}, {"errors": 0.037068871127289627, "time-step": 4034}, {"errors": 0.03701404445201468, "time-step": 4035}, {"errors": 0.03695928254325202, "time-step": 4036}, {"errors": 0.03690458553409927, "time-step": 4037}, {"errors": 0.036849953556383076, "time-step": 4038}, {"errors": 0.03679538674066065, "time-step": 4039}, {"errors": 0.036740885216221, "time-step": 4040}, {"errors": 0.03668644911108658, "time-step": 4041}, {"errors": 0.03663207855201474, "time-step": 4042}, {"errors": 0.036577773664499276, "time-step": 4043}, {"errors": 0.03652353457277209, "time-step": 4044}, {"errors": 0.036469361399804646, "time-step": 4045}, {"errors": 0.0364152542673102, "time-step": 4046}, {"errors": 0.03636121329574477, "time-step": 4047}, {"errors": 0.03630723860430964, "time-step": 4048}, {"errors": 0.0362533303109527, "time-step": 4049}, {"errors": 0.036199488532370705, "time-step": 4050}, {"errors": 0.036145713384010736, "time-step": 4051}, {"errors": 0.03609200498007278, "time-step": 4052}, {"errors": 0.036038363433511064, "time-step": 4053}, {"errors": 0.0359847888560367, "time-step": 4054}, {"errors": 0.03593128135811936, "time-step": 4055}, {"errors": 0.03587784104898967, "time-step": 4056}, {"errors": 0.03582446803664115, "time-step": 4057}, {"errors": 0.035771162427832605, "time-step": 4058}, {"errors": 0.03571792432809035, "time-step": 4059}, {"errors": 0.03566475384171058, "time-step": 4060}, {"errors": 0.035611651071761445, "time-step": 4061}, {"errors": 0.03555861612008565, "time-step": 4062}, {"errors": 0.035505649087302846, "time-step": 4063}, {"errors": 0.035452750072812025, "time-step": 4064}, {"errors": 0.035399919174794056, "time-step": 4065}, {"errors": 0.03534715649021417, "time-step": 4066}, {"errors": 0.03529446211482456, "time-step": 4067}, {"errors": 0.03524183614316692, "time-step": 4068}, {"errors": 0.03518927866857516, "time-step": 4069}, {"errors": 0.03513678978317815, "time-step": 4070}, {"errors": 0.03508436957790219, "time-step": 4071}, {"errors": 0.03503201814247394, "time-step": 4072}, {"errors": 0.03497973556542334, "time-step": 4073}, {"errors": 0.03492752193408599, "time-step": 4074}, {"errors": 0.034875377334606425, "time-step": 4075}, {"errors": 0.03482330185194078, "time-step": 4076}, {"errors": 0.034771295569859854, "time-step": 4077}, {"errors": 0.03471935857095189, "time-step": 4078}, {"errors": 0.03466749093662573, "time-step": 4079}, {"errors": 0.034615692747113624, "time-step": 4080}, {"errors": 0.03456396408147453, "time-step": 4081}, {"errors": 0.03451230501759702, "time-step": 4082}, {"errors": 0.03446071563220248, "time-step": 4083}, {"errors": 0.03440919600084814, "time-step": 4084}, {"errors": 0.034357746197930444, "time-step": 4085}, {"errors": 0.034306366296688, "time-step": 4086}, {"errors": 0.034255056369205054, "time-step": 4087}, {"errors": 0.03420381648641466, "time-step": 4088}, {"errors": 0.03415264671810184, "time-step": 4089}, {"errors": 0.03410154713290718, "time-step": 4090}, {"errors": 0.03405051779832986, "time-step": 4091}, {"errors": 0.033999558780731354, "time-step": 4092}, {"errors": 0.03394867014533867, "time-step": 4093}, {"errors": 0.03389785195624764, "time-step": 4094}, {"errors": 0.03384710427642669, "time-step": 4095}, {"errors": 0.03379642716772004, "time-step": 4096}, {"errors": 0.03374582069085146, "time-step": 4097}, {"errors": 0.03369528490542756, "time-step": 4098}, {"errors": 0.033644819869941535, "time-step": 4099}, {"errors": 0.03359442564177673, "time-step": 4100}, {"errors": 0.033544102277210205, "time-step": 4101}, {"errors": 0.03349384983141626, "time-step": 4102}, {"errors": 0.03344366835847033, "time-step": 4103}, {"errors": 0.033393557911352525, "time-step": 4104}, {"errors": 0.03334351854195136, "time-step": 4105}, {"errors": 0.033293550301067426, "time-step": 4106}, {"errors": 0.0332436532384173, "time-step": 4107}, {"errors": 0.03319382740263711, "time-step": 4108}, {"errors": 0.03314407284128647, "time-step": 4109}, {"errors": 0.033094389600852286, "time-step": 4110}, {"errors": 0.03304477772675244, "time-step": 4111}, {"errors": 0.03299523726333993, "time-step": 4112}, {"errors": 0.03294576825390649, "time-step": 4113}, {"errors": 0.03289637074068655, "time-step": 4114}, {"errors": 0.03284704476486121, "time-step": 4115}, {"errors": 0.03279779036656213, "time-step": 4116}, {"errors": 0.032748607584875564, "time-step": 4117}, {"errors": 0.03269949645784607, "time-step": 4118}, {"errors": 0.03265045702248087, "time-step": 4119}, {"errors": 0.03260148931475363, "time-step": 4120}, {"errors": 0.03255259336960845, "time-step": 4121}, {"errors": 0.03250376922096404, "time-step": 4122}, {"errors": 0.03245501690171771, "time-step": 4123}, {"errors": 0.03240633644374939, "time-step": 4124}, {"errors": 0.03235772787792586, "time-step": 4125}, {"errors": 0.032309191234104695, "time-step": 4126}, {"errors": 0.03226072654113852, "time-step": 4127}, {"errors": 0.03221233382687899, "time-step": 4128}, {"errors": 0.03216401311818118, "time-step": 4129}, {"errors": 0.03211576444090737, "time-step": 4130}, {"errors": 0.03206758781993167, "time-step": 4131}, {"errors": 0.03201948327914388, "time-step": 4132}, {"errors": 0.03197145084145373, "time-step": 4133}, {"errors": 0.031923490528795354, "time-step": 4134}, {"errors": 0.031875602362131106, "time-step": 4135}, {"errors": 0.03182778636145615, "time-step": 4136}, {"errors": 0.03178004254580255, "time-step": 4137}, {"errors": 0.03173237093324358, "time-step": 4138}, {"errors": 0.031684771540897994, "time-step": 4139}, {"errors": 0.031637244384934204, "time-step": 4140}, {"errors": 0.03158978948057475, "time-step": 4141}, {"errors": 0.03154240684210052, "time-step": 4142}, {"errors": 0.03149509648285501, "time-step": 4143}, {"errors": 0.03144785841524883, "time-step": 4144}, {"errors": 0.031400692650763784, "time-step": 4145}, {"errors": 0.031353599199957366, "time-step": 4146}, {"errors": 0.03130657807246719, "time-step": 4147}, {"errors": 0.03125962927701515, "time-step": 4148}, {"errors": 0.031212752821411928, "time-step": 4149}, {"errors": 0.03116594871256127, "time-step": 4150}, {"errors": 0.03111921695646454, "time-step": 4151}, {"errors": 0.031072557558224904, "time-step": 4152}, {"errors": 0.03102597052205181, "time-step": 4153}, {"errors": 0.030979455851265478, "time-step": 4154}, {"errors": 0.03093301354830118, "time-step": 4155}, {"errors": 0.030886643614713688, "time-step": 4156}, {"errors": 0.030840346051181793, "time-step": 4157}, {"errors": 0.030794120857512576, "time-step": 4158}, {"errors": 0.030747968032645956, "time-step": 4159}, {"errors": 0.030701887574659067, "time-step": 4160}, {"errors": 0.030655879480770712, "time-step": 4161}, {"errors": 0.03060994374734579, "time-step": 4162}, {"errors": 0.03056408036989991, "time-step": 4163}, {"errors": 0.03051828934310348, "time-step": 4164}, {"errors": 0.030472570660786555, "time-step": 4165}, {"errors": 0.030426924315943057, "time-step": 4166}, {"errors": 0.030381350300735355, "time-step": 4167}, {"errors": 0.030335848606498603, "time-step": 4168}, {"errors": 0.030290419223745292, "time-step": 4169}, {"errors": 0.030245062142169758, "time-step": 4170}, {"errors": 0.03019977735065263, "time-step": 4171}, {"errors": 0.030154564837265196, "time-step": 4172}, {"errors": 0.03010942458927395, "time-step": 4173}, {"errors": 0.03006435659314518, "time-step": 4174}, {"errors": 0.03001936083454923, "time-step": 4175}, {"errors": 0.029974437298365186, "time-step": 4176}, {"errors": 0.02992958596868515, "time-step": 4177}, {"errors": 0.029884806828818843, "time-step": 4178}, {"errors": 0.02984009986129807, "time-step": 4179}, {"errors": 0.02979546504788117, "time-step": 4180}, {"errors": 0.029750902369557557, "time-step": 4181}, {"errors": 0.029706411806552, "time-step": 4182}, {"errors": 0.02966199333832942, "time-step": 4183}, {"errors": 0.029617646943598933, "time-step": 4184}, {"errors": 0.029573372600318858, "time-step": 4185}, {"errors": 0.02952917028570059, "time-step": 4186}, {"errors": 0.029485039976213587, "time-step": 4187}, {"errors": 0.029440981647589487, "time-step": 4188}, {"errors": 0.02939699527482675, "time-step": 4189}, {"errors": 0.02935308083219508, "time-step": 4190}, {"errors": 0.02930923829323975, "time-step": 4191}, {"errors": 0.02926546763078633, "time-step": 4192}, {"errors": 0.029221768816944875, "time-step": 4193}, {"errors": 0.029178141823114387, "time-step": 4194}, {"errors": 0.02913458661998755, "time-step": 4195}, {"errors": 0.029091103177554756, "time-step": 4196}, {"errors": 0.02904769146510886, "time-step": 4197}, {"errors": 0.029004351451249438, "time-step": 4198}, {"errors": 0.02896108310388728, "time-step": 4199}, {"errors": 0.02891788639024874, "time-step": 4200}, {"errors": 0.028874761276880295, "time-step": 4201}, {"errors": 0.02883170772965278, "time-step": 4202}, {"errors": 0.02878872571376595, "time-step": 4203}, {"errors": 0.02874581519375274, "time-step": 4204}, {"errors": 0.028702976133483778, "time-step": 4205}, {"errors": 0.028660208496171638, "time-step": 4206}, {"errors": 0.028617512244375372, "time-step": 4207}, {"errors": 0.028574887340004858, "time-step": 4208}, {"errors": 0.028532333744324966, "time-step": 4209}, {"errors": 0.028489851417960246, "time-step": 4210}, {"errors": 0.028447440320899027, "time-step": 4211}, {"errors": 0.028405100412497858, "time-step": 4212}, {"errors": 0.028362831651485943, "time-step": 4213}, {"errors": 0.0283206339959692, "time-step": 4214}, {"errors": 0.02827850740343493, "time-step": 4215}, {"errors": 0.02823645183075588, "time-step": 4216}, {"errors": 0.028194467234194727, "time-step": 4217}, {"errors": 0.028152553569408163, "time-step": 4218}, {"errors": 0.02811071079145144, "time-step": 4219}, {"errors": 0.028068938854782573, "time-step": 4220}, {"errors": 0.028027237713266456, "time-step": 4221}, {"errors": 0.02798560732017938, "time-step": 4222}, {"errors": 0.027944047628213148, "time-step": 4223}, {"errors": 0.02790255858947932, "time-step": 4224}, {"errors": 0.027861140155513553, "time-step": 4225}, {"errors": 0.02781979227727973, "time-step": 4226}, {"errors": 0.02777851490517424, "time-step": 4227}, {"errors": 0.027737307989030256, "time-step": 4228}, {"errors": 0.027696171478121718, "time-step": 4229}, {"errors": 0.02765510532116784, "time-step": 4230}, {"errors": 0.027614109466337078, "time-step": 4231}, {"errors": 0.02757318386125126, "time-step": 4232}, {"errors": 0.027532328452990047, "time-step": 4233}, {"errors": 0.027491543188094797, "time-step": 4234}, {"errors": 0.02745082801257282, "time-step": 4235}, {"errors": 0.027410182871901452, "time-step": 4236}, {"errors": 0.027369607711032397, "time-step": 4237}, {"errors": 0.027329102474395524, "time-step": 4238}, {"errors": 0.027288667105903126, "time-step": 4239}, {"errors": 0.02724830154895413, "time-step": 4240}, {"errors": 0.027208005746437964, "time-step": 4241}, {"errors": 0.027167779640738788, "time-step": 4242}, {"errors": 0.027127623173739387, "time-step": 4243}, {"errors": 0.027087536286825427, "time-step": 4244}, {"errors": 0.027047518920889323, "time-step": 4245}, {"errors": 0.02700757101633433, "time-step": 4246}, {"errors": 0.02696769251307856, "time-step": 4247}, {"errors": 0.026927883350558943, "time-step": 4248}, {"errors": 0.026888143467735312, "time-step": 4249}, {"errors": 0.02684847280309426, "time-step": 4250}, {"errors": 0.026808871294653085, "time-step": 4251}, {"errors": 0.02676933887996395, "time-step": 4252}, {"errors": 0.026729875496117675, "time-step": 4253}, {"errors": 0.02669048107974756, "time-step": 4254}, {"errors": 0.026651155567033506, "time-step": 4255}, {"errors": 0.02661189889370583, "time-step": 4256}, {"errors": 0.026572710995049147, "time-step": 4257}, {"errors": 0.026533591805906212, "time-step": 4258}, {"errors": 0.02649454126068189, "time-step": 4259}, {"errors": 0.026455559293346927, "time-step": 4260}, {"errors": 0.026416645837441823, "time-step": 4261}, {"errors": 0.026377800826080586, "time-step": 4262}, {"errors": 0.026339024191954732, "time-step": 4263}, {"errors": 0.02630031586733677, "time-step": 4264}, {"errors": 0.026261675784084292, "time-step": 4265}, {"errors": 0.02622310387364367, "time-step": 4266}, {"errors": 0.026184600067053684, "time-step": 4267}, {"errors": 0.026146164294949363, "time-step": 4268}, {"errors": 0.026107796487565785, "time-step": 4269}, {"errors": 0.02606949657474166, "time-step": 4270}, {"errors": 0.02603126448592314, "time-step": 4271}, {"errors": 0.02599310015016741, "time-step": 4272}, {"errors": 0.025955003496146514, "time-step": 4273}, {"errors": 0.025916974452150875, "time-step": 4274}, {"errors": 0.025879012946092975, "time-step": 4275}, {"errors": 0.025841118905511107, "time-step": 4276}, {"errors": 0.02580329225757287, "time-step": 4277}, {"errors": 0.025765532929078804, "time-step": 4278}, {"errors": 0.025727840846465948, "time-step": 4279}, {"errors": 0.02569021593581161, "time-step": 4280}, {"errors": 0.02565265812283663, "time-step": 4281}, {"errors": 0.025615167332909222, "time-step": 4282}, {"errors": 0.025577743491048327, "time-step": 4283}, {"errors": 0.02554038652192718, "time-step": 4284}, {"errors": 0.025503096349876818, "time-step": 4285}, {"errors": 0.02546587289888968, "time-step": 4286}, {"errors": 0.025428716092622854, "time-step": 4287}, {"errors": 0.025391625854401828, "time-step": 4288}, {"errors": 0.025354602107223685, "time-step": 4289}, {"errors": 0.0253176447737607, "time-step": 4290}, {"errors": 0.0252807537763637, "time-step": 4291}, {"errors": 0.025243929037065425, "time-step": 4292}, {"errors": 0.025207170477584136, "time-step": 4293}, {"errors": 0.02517047801932661, "time-step": 4294}, {"errors": 0.025133851583391913, "time-step": 4295}, {"errors": 0.025097291090574445, "time-step": 4296}, {"errors": 0.025060796461367447, "time-step": 4297}, {"errors": 0.025024367615966228, "time-step": 4298}, {"errors": 0.024988004474271543, "time-step": 4299}, {"errors": 0.024951706955892817, "time-step": 4300}, {"errors": 0.02491547498015139, "time-step": 4301}, {"errors": 0.02487930846608392, "time-step": 4302}, {"errors": 0.024843207332445473, "time-step": 4303}, {"errors": 0.024807171497712804, "time-step": 4304}, {"errors": 0.02477120088008767, "time-step": 4305}, {"errors": 0.024735295397499777, "time-step": 4306}, {"errors": 0.024699454967610307, "time-step": 4307}, {"errors": 0.02466367950781478, "time-step": 4308}, {"errors": 0.024627968935246373, "time-step": 4309}, {"errors": 0.02459232316677901, "time-step": 4310}, {"errors": 0.024556742119030542, "time-step": 4311}, {"errors": 0.024521225708365752, "time-step": 4312}, {"errors": 0.024485773850899534, "time-step": 4313}, {"errors": 0.024450386462499918, "time-step": 4314}, {"errors": 0.024415063458791197, "time-step": 4315}, {"errors": 0.0243798047551569, "time-step": 4316}, {"errors": 0.0243446102667429, "time-step": 4317}, {"errors": 0.02430947990846035, "time-step": 4318}, {"errors": 0.024274413594988796, "time-step": 4319}, {"errors": 0.02423941124077902, "time-step": 4320}, {"errors": 0.02420447276005612, "time-step": 4321}, {"errors": 0.024169598066822468, "time-step": 4322}, {"errors": 0.024134787074860636, "time-step": 4323}, {"errors": 0.024100039697736227, "time-step": 4324}, {"errors": 0.024065355848801047, "time-step": 4325}, {"errors": 0.02403073544119557, "time-step": 4326}, {"errors": 0.023996178387852295, "time-step": 4327}, {"errors": 0.02396168460149833, "time-step": 4328}, {"errors": 0.023927253994658282, "time-step": 4329}, {"errors": 0.023892886479657142, "time-step": 4330}, {"errors": 0.023858581968623116, "time-step": 4331}, {"errors": 0.023824340373490377, "time-step": 4332}, {"errors": 0.023790161606001836, "time-step": 4333}, {"errors": 0.02375604557771205, "time-step": 4334}, {"errors": 0.02372199219998987, "time-step": 4335}, {"errors": 0.023688001384021162, "time-step": 4336}, {"errors": 0.023654073040811747, "time-step": 4337}, {"errors": 0.02362020708118974, "time-step": 4338}, {"errors": 0.023586403415808664, "time-step": 4339}, {"errors": 0.023552661955149823, "time-step": 4340}, {"errors": 0.023518982609525237, "time-step": 4341}, {"errors": 0.02348536528908, "time-step": 4342}, {"errors": 0.023451809903795223, "time-step": 4343}, {"errors": 0.023418316363490448, "time-step": 4344}, {"errors": 0.023384884577826302, "time-step": 4345}, {"errors": 0.02335151445630721, "time-step": 4346}, {"errors": 0.02331820590828383, "time-step": 4347}, {"errors": 0.02328495884295575, "time-step": 4348}, {"errors": 0.023251773169373886, "time-step": 4349}, {"errors": 0.023218648796443135, "time-step": 4350}, {"errors": 0.023185585632924954, "time-step": 4351}, {"errors": 0.023152583587439664, "time-step": 4352}, {"errors": 0.023119642568469115, "time-step": 4353}, {"errors": 0.02308676248435914, "time-step": 4354}, {"errors": 0.02305394324332198, "time-step": 4355}, {"errors": 0.023021184753438728, "time-step": 4356}, {"errors": 0.02298848692266177, "time-step": 4357}, {"errors": 0.02295584965881732, "time-step": 4358}, {"errors": 0.02292327286960761, "time-step": 4359}, {"errors": 0.02289075646261343, "time-step": 4360}, {"errors": 0.02285830034529646, "time-step": 4361}, {"errors": 0.022825904425001778, "time-step": 4362}, {"errors": 0.022793568608959855, "time-step": 4363}, {"errors": 0.02276129280428927, "time-step": 4364}, {"errors": 0.022729076917998806, "time-step": 4365}, {"errors": 0.02269692085698987, "time-step": 4366}, {"errors": 0.022664824528058607, "time-step": 4367}, {"errors": 0.02263278783789846, "time-step": 4368}, {"errors": 0.022600810693102123, "time-step": 4369}, {"errors": 0.022568893000164066, "time-step": 4370}, {"errors": 0.02253703466548252, "time-step": 4371}, {"errors": 0.02250523559536194, "time-step": 4372}, {"errors": 0.022473495696015013, "time-step": 4373}, {"errors": 0.022441814873564895, "time-step": 4374}, {"errors": 0.02241019303404749, "time-step": 4375}, {"errors": 0.022378630083413502, "time-step": 4376}, {"errors": 0.022347125927530628, "time-step": 4377}, {"errors": 0.022315680472185687, "time-step": 4378}, {"errors": 0.022284293623086742, "time-step": 4379}, {"errors": 0.02225296528586517, "time-step": 4380}, {"errors": 0.02222169536607787, "time-step": 4381}, {"errors": 0.02219048376920923, "time-step": 4382}, {"errors": 0.022159330400673166, "time-step": 4383}, {"errors": 0.022128235165815364, "time-step": 4384}, {"errors": 0.02209719796991507, "time-step": 4385}, {"errors": 0.02206621871818732, "time-step": 4386}, {"errors": 0.02203529731578483, "time-step": 4387}, {"errors": 0.02200443366779999, "time-step": 4388}, {"errors": 0.02197362767926702, "time-step": 4389}, {"errors": 0.021942879255163764, "time-step": 4390}, {"errors": 0.021912188300413554, "time-step": 4391}, {"errors": 0.021881554719887508, "time-step": 4392}, {"errors": 0.0218509784184061, "time-step": 4393}, {"errors": 0.021820459300741293, "time-step": 4394}, {"errors": 0.021789997271618317, "time-step": 4395}, {"errors": 0.021759592235717752, "time-step": 4396}, {"errors": 0.02172924409767715, "time-step": 4397}, {"errors": 0.02169895276209308, "time-step": 4398}, {"errors": 0.021668718133522863, "time-step": 4399}, {"errors": 0.02163854011648654, "time-step": 4400}, {"errors": 0.02160841861546858, "time-step": 4401}, {"errors": 0.021578353534919804, "time-step": 4402}, {"errors": 0.02154834477925905, "time-step": 4403}, {"errors": 0.0215183922528751, "time-step": 4404}, {"errors": 0.02148849586012836, "time-step": 4405}, {"errors": 0.021458655505352614, "time-step": 4406}, {"errors": 0.02142887109285682, "time-step": 4407}, {"errors": 0.021399142526926866, "time-step": 4408}, {"errors": 0.02136946971182726, "time-step": 4409}, {"errors": 0.021339852551802818, "time-step": 4410}, {"errors": 0.02131029095108036, "time-step": 4411}, {"errors": 0.02128078481387047, "time-step": 4412}, {"errors": 0.02125133404436913, "time-step": 4413}, {"errors": 0.02122193854675931, "time-step": 4414}, {"errors": 0.02119259822521273, "time-step": 4415}, {"errors": 0.02116331298389141, "time-step": 4416}, {"errors": 0.02113408272694932, "time-step": 4417}, {"errors": 0.021104907358534125, "time-step": 4418}, {"errors": 0.02107578678278842, "time-step": 4419}, {"errors": 0.021046720903851783, "time-step": 4420}, {"errors": 0.02101770962586202, "time-step": 4421}, {"errors": 0.020988752852956837, "time-step": 4422}, {"errors": 0.02095985048927539, "time-step": 4423}, {"errors": 0.020931002438959866, "time-step": 4424}, {"errors": 0.020902208606156887, "time-step": 4425}, {"errors": 0.02087346889501917, "time-step": 4426}, {"errors": 0.020844783209706966, "time-step": 4427}, {"errors": 0.02081615145438952, "time-step": 4428}, {"errors": 0.02078757353324657, "time-step": 4429}, {"errors": 0.020759049350469884, "time-step": 4430}, {"errors": 0.02073057881026463, "time-step": 4431}, {"errors": 0.020702161816850903, "time-step": 4432}, {"errors": 0.02067379827446501, "time-step": 4433}, {"errors": 0.020645488087361087, "time-step": 4434}, {"errors": 0.02061723115981238, "time-step": 4435}, {"errors": 0.02058902739611273, "time-step": 4436}, {"errors": 0.020560876700577855, "time-step": 4437}, {"errors": 0.020532778977546833, "time-step": 4438}, {"errors": 0.020504734131383387, "time-step": 4439}, {"errors": 0.020476742066477316, "time-step": 4440}, {"errors": 0.02044880268724583, "time-step": 4441}, {"errors": 0.02042091589813474, "time-step": 4442}, {"errors": 0.020393081603620036, "time-step": 4443}, {"errors": 0.02036529970820891, "time-step": 4444}, {"errors": 0.02033757011644137, "time-step": 4445}, {"errors": 0.02030989273289128, "time-step": 4446}, {"errors": 0.02028226746216769, "time-step": 4447}, {"errors": 0.020254694208916228, "time-step": 4448}, {"errors": 0.020227172877820172, "time-step": 4449}, {"errors": 0.020199703373601868, "time-step": 4450}, {"errors": 0.02017228560102388, "time-step": 4451}, {"errors": 0.020144919464890186, "time-step": 4452}, {"errors": 0.02011760487004749, "time-step": 4453}, {"errors": 0.02009034172138634, "time-step": 4454}, {"errors": 0.020063129923842352, "time-step": 4455}, {"errors": 0.020035969382397427, "time-step": 4456}, {"errors": 0.020008860002080856, "time-step": 4457}, {"errors": 0.01998180168797058, "time-step": 4458}, {"errors": 0.019954794345194263, "time-step": 4459}, {"errors": 0.019927837878930436, "time-step": 4460}, {"errors": 0.01990093219440965, "time-step": 4461}, {"errors": 0.01987407719691567, "time-step": 4462}, {"errors": 0.01984727279178648, "time-step": 4463}, {"errors": 0.019820518884415418, "time-step": 4464}, {"errors": 0.019793815380252273, "time-step": 4465}, {"errors": 0.019767162184804468, "time-step": 4466}, {"errors": 0.019740559203637962, "time-step": 4467}, {"errors": 0.019714006342378344, "time-step": 4468}, {"errors": 0.019687503506712098, "time-step": 4469}, {"errors": 0.019661050602387365, "time-step": 4470}, {"errors": 0.01963464753521514, "time-step": 4471}, {"errors": 0.01960829421107027, "time-step": 4472}, {"errors": 0.019581990535892477, "time-step": 4473}, {"errors": 0.019555736415687322, "time-step": 4474}, {"errors": 0.019529531756527253, "time-step": 4475}, {"errors": 0.01950337646455259, "time-step": 4476}, {"errors": 0.019477270445972396, "time-step": 4477}, {"errors": 0.019451213607065677, "time-step": 4478}, {"errors": 0.01942520585418211, "time-step": 4479}, {"errors": 0.01939924709374312, "time-step": 4480}, {"errors": 0.01937333723224278, "time-step": 4481}, {"errors": 0.01934747617624876, "time-step": 4482}, {"errors": 0.019321663832403264, "time-step": 4483}, {"errors": 0.01929590010742396, "time-step": 4484}, {"errors": 0.019270184908104757, "time-step": 4485}, {"errors": 0.019244518141316933, "time-step": 4486}, {"errors": 0.01921889971400976, "time-step": 4487}, {"errors": 0.019193329533211637, "time-step": 4488}, {"errors": 0.01916780750603079, "time-step": 4489}, {"errors": 0.01914233353965622, "time-step": 4490}, {"errors": 0.01911690754135846, "time-step": 4491}, {"errors": 0.01909152941849059, "time-step": 4492}, {"errors": 0.01906619907848891, "time-step": 4493}, {"errors": 0.019040916428873837, "time-step": 4494}, {"errors": 0.019015681377250727, "time-step": 4495}, {"errors": 0.018990493831310712, "time-step": 4496}, {"errors": 0.018965353698831455, "time-step": 4497}, {"errors": 0.018940260887677945, "time-step": 4498}, {"errors": 0.01891521530580339, "time-step": 4499}, {"errors": 0.018890216861249778, "time-step": 4500}, {"errors": 0.01886526546214887, "time-step": 4501}, {"errors": 0.01884036101672295, "time-step": 4502}, {"errors": 0.018815503433285342, "time-step": 4503}, {"errors": 0.01879069262024142, "time-step": 4504}, {"errors": 0.01876592848608931, "time-step": 4505}, {"errors": 0.01874121093942044, "time-step": 4506}, {"errors": 0.01871653988892047, "time-step": 4507}, {"errors": 0.018691915243369852, "time-step": 4508}, {"errors": 0.01866733691164476, "time-step": 4509}, {"errors": 0.018642804802717464, "time-step": 4510}, {"errors": 0.01861831882565737, "time-step": 4511}, {"errors": 0.018593878889631363, "time-step": 4512}, {"errors": 0.01856948490390481, "time-step": 4513}, {"errors": 0.01854513677784202, "time-step": 4514}, {"errors": 0.018520834420907, "time-step": 4515}, {"errors": 0.018496577742664017, "time-step": 4516}, {"errors": 0.01847236665277839, "time-step": 4517}, {"errors": 0.01844820106101701, "time-step": 4518}, {"errors": 0.018424080877248988, "time-step": 4519}, {"errors": 0.018400006011446347, "time-step": 4520}, {"errors": 0.01837597637368461, "time-step": 4521}, {"errors": 0.01835199187414338, "time-step": 4522}, {"errors": 0.01832805242310696, "time-step": 4523}, {"errors": 0.018304157930965043, "time-step": 4524}, {"errors": 0.018280308308213103, "time-step": 4525}, {"errors": 0.018256503465453155, "time-step": 4526}, {"errors": 0.018232743313394313, "time-step": 4527}, {"errors": 0.018209027762853266, "time-step": 4528}, {"errors": 0.018185356724754947, "time-step": 4529}, {"errors": 0.018161730110132966, "time-step": 4530}, {"errors": 0.01813814783013036, "time-step": 4531}, {"errors": 0.018114609795999846, "time-step": 4532}, {"errors": 0.018091115919104696, "time-step": 4533}, {"errors": 0.01806766611091897, "time-step": 4534}, {"errors": 0.01804426028302827, "time-step": 4535}, {"errors": 0.018020898347130058, "time-step": 4536}, {"errors": 0.01799758021503428, "time-step": 4537}, {"errors": 0.0179743057986639, "time-step": 4538}, {"errors": 0.01795107501005534, "time-step": 4539}, {"errors": 0.017927887761358913, "time-step": 4540}, {"errors": 0.017904743964839494, "time-step": 4541}, {"errors": 0.017881643532876752, "time-step": 4542}, {"errors": 0.017858586377965825, "time-step": 4543}, {"errors": 0.017835572412717743, "time-step": 4544}, {"errors": 0.017812601549859773, "time-step": 4545}, {"errors": 0.017789673702236025, "time-step": 4546}, {"errors": 0.017766788782807835, "time-step": 4547}, {"errors": 0.017743946704654148, "time-step": 4548}, {"errors": 0.017721147380972066, "time-step": 4549}, {"errors": 0.0176983907250772, "time-step": 4550}, {"errors": 0.017675676650404145, "time-step": 4551}, {"errors": 0.017653005070506857, "time-step": 4552}, {"errors": 0.01763037589905911, "time-step": 4553}, {"errors": 0.017607789049854827, "time-step": 4554}, {"errors": 0.017585244436808523, "time-step": 4555}, {"errors": 0.017562741973955784, "time-step": 4556}, {"errors": 0.01754028157545348, "time-step": 4557}, {"errors": 0.01751786315558037, "time-step": 4558}, {"errors": 0.01749548662873722, "time-step": 4559}, {"errors": 0.017473151909447444, "time-step": 4560}, {"errors": 0.017450858912357224, "time-step": 4561}, {"errors": 0.017428607552236096, "time-step": 4562}, {"errors": 0.01740639774397714, "time-step": 4563}, {"errors": 0.01738422940259744, "time-step": 4564}, {"errors": 0.017362102443238315, "time-step": 4565}, {"errors": 0.01734001678116579, "time-step": 4566}, {"errors": 0.017317972331770813, "time-step": 4567}, {"errors": 0.01729596901056973, "time-step": 4568}, {"errors": 0.01727400673320446, "time-step": 4569}, {"errors": 0.017252085415442833, "time-step": 4570}, {"errors": 0.01723020497317907, "time-step": 4571}, {"errors": 0.017208365322433847, "time-step": 4572}, {"errors": 0.017186566379354784, "time-step": 4573}, {"errors": 0.01716480806021673, "time-step": 4574}, {"errors": 0.017143090281421886, "time-step": 4575}, {"errors": 0.017121412959500298, "time-step": 4576}, {"errors": 0.017099776011110082, "time-step": 4577}, {"errors": 0.01707817935303764, "time-step": 4578}, {"errors": 0.01705662290219804, "time-step": 4579}, {"errors": 0.017035106575635155, "time-step": 4580}, {"errors": 0.017013630290522004, "time-step": 4581}, {"errors": 0.016992193964161083, "time-step": 4582}, {"errors": 0.016970797513984483, "time-step": 4583}, {"errors": 0.016949440857554225, "time-step": 4584}, {"errors": 0.016928123912562473, "time-step": 4585}, {"errors": 0.01690684659683177, "time-step": 4586}, {"errors": 0.01688560882831537, "time-step": 4587}, {"errors": 0.01686441052509733, "time-step": 4588}, {"errors": 0.01684325160539282, "time-step": 4589}, {"errors": 0.016822131987548315, "time-step": 4590}, {"errors": 0.016801051590041874, "time-step": 4591}, {"errors": 0.016780010331483287, "time-step": 4592}, {"errors": 0.016759008130614327, "time-step": 4593}, {"errors": 0.016738044906308897, "time-step": 4594}, {"errors": 0.016717120577573304, "time-step": 4595}, {"errors": 0.016696235063546457, "time-step": 4596}, {"errors": 0.016675388283499987, "time-step": 4597}, {"errors": 0.01665458015683855, "time-step": 4598}, {"errors": 0.016633810603099826, "time-step": 4599}, {"errors": 0.016613079541954904, "time-step": 4600}, {"errors": 0.0165923868932084, "time-step": 4601}, {"errors": 0.01657173257679853, "time-step": 4602}, {"errors": 0.01655111651279741, "time-step": 4603}, {"errors": 0.01653053862141112, "time-step": 4604}, {"errors": 0.016509998822979967, "time-step": 4605}, {"errors": 0.016489497037978532, "time-step": 4606}, {"errors": 0.01646903318701591, "time-step": 4607}, {"errors": 0.01644860719083577, "time-step": 4608}, {"errors": 0.01642821897031667, "time-step": 4609}, {"errors": 0.016407868446471956, "time-step": 4610}, {"errors": 0.016387555540450086, "time-step": 4611}, {"errors": 0.016367280173534775, "time-step": 4612}, {"errors": 0.01634704226714491, "time-step": 4613}, {"errors": 0.016326841742834945, "time-step": 4614}, {"errors": 0.016306678522294865, "time-step": 4615}, {"errors": 0.016286552527350326, "time-step": 4616}, {"errors": 0.016266463679962862, "time-step": 4617}, {"errors": 0.016246411902229828, "time-step": 4618}, {"errors": 0.01622639711638465, "time-step": 4619}, {"errors": 0.016206419244796873, "time-step": 4620}, {"errors": 0.01618647820997231, "time-step": 4621}, {"errors": 0.016166573934553098, "time-step": 4622}, {"errors": 0.016146706341317717, "time-step": 4623}, {"errors": 0.016126875353181316, "time-step": 4624}, {"errors": 0.016107080893195506, "time-step": 4625}, {"errors": 0.01608732288454866, "time-step": 4626}, {"errors": 0.016067601250565933, "time-step": 4627}, {"errors": 0.016047915914709308, "time-step": 4628}, {"errors": 0.016028266800577676, "time-step": 4629}, {"errors": 0.016008653831906968, "time-step": 4630}, {"errors": 0.01598907693257014, "time-step": 4631}, {"errors": 0.01596953602657728, "time-step": 4632}, {"errors": 0.015950031038075747, "time-step": 4633}, {"errors": 0.015930561891349997, "time-step": 4634}, {"errors": 0.015911128510821968, "time-step": 4635}, {"errors": 0.015891730821050835, "time-step": 4636}, {"errors": 0.015872368746733184, "time-step": 4637}, {"errors": 0.01585304221270315, "time-step": 4638}, {"errors": 0.015833751143932297, "time-step": 4639}, {"errors": 0.01581449546552975, "time-step": 4640}, {"errors": 0.015795275102742194, "time-step": 4641}, {"errors": 0.01577608998095396, "time-step": 4642}, {"errors": 0.015756940025686977, "time-step": 4643}, {"errors": 0.01573782516260089, "time-step": 4644}, {"errors": 0.015718745317493024, "time-step": 4645}, {"errors": 0.015699700416298444, "time-step": 4646}, {"errors": 0.015680690385089922, "time-step": 4647}, {"errors": 0.01566171515007806, "time-step": 4648}, {"errors": 0.015642774637611163, "time-step": 4649}, {"errors": 0.015623868774175344, "time-step": 4650}, {"errors": 0.01560499748639457, "time-step": 4651}, {"errors": 0.015586160701030534, "time-step": 4652}, {"errors": 0.015567358344982785, "time-step": 4653}, {"errors": 0.015548590345288684, "time-step": 4654}, {"errors": 0.015529856629123366, "time-step": 4655}, {"errors": 0.015511157123799862, "time-step": 4656}, {"errors": 0.015492491756768874, "time-step": 4657}, {"errors": 0.015473860455618993, "time-step": 4658}, {"errors": 0.015455263148076548, "time-step": 4659}, {"errors": 0.015436699762005675, "time-step": 4660}, {"errors": 0.015418170225408246, "time-step": 4661}, {"errors": 0.015399674466423803, "time-step": 4662}, {"errors": 0.015381212413329681, "time-step": 4663}, {"errors": 0.015362783994540902, "time-step": 4664}, {"errors": 0.015344389138610049, "time-step": 4665}, {"errors": 0.01532602777422749, "time-step": 4666}, {"errors": 0.015307699830221063, "time-step": 4667}, {"errors": 0.01528940523555625, "time-step": 4668}, {"errors": 0.015271143919336098, "time-step": 4669}, {"errors": 0.01525291581080104, "time-step": 4670}, {"errors": 0.015234720839329075, "time-step": 4671}, {"errors": 0.015216558934435562, "time-step": 4672}, {"errors": 0.015198430025773275, "time-step": 4673}, {"errors": 0.015180334043132234, "time-step": 4674}, {"errors": 0.015162270916439863, "time-step": 4675}, {"errors": 0.015144240575760692, "time-step": 4676}, {"errors": 0.015126242951296531, "time-step": 4677}, {"errors": 0.015108277973386198, "time-step": 4678}, {"errors": 0.01509034557250567, "time-step": 4679}, {"errors": 0.015072445679267878, "time-step": 4680}, {"errors": 0.01505457822442273, "time-step": 4681}, {"errors": 0.01503674313885696, "time-step": 4682}, {"errors": 0.01501894035359421, "time-step": 4683}, {"errors": 0.015001169799794753, "time-step": 4684}, {"errors": 0.01498343140875565, "time-step": 4685}, {"errors": 0.014965725111910497, "time-step": 4686}, {"errors": 0.014948050840829473, "time-step": 4687}, {"errors": 0.014930408527219163, "time-step": 4688}, {"errors": 0.01491279810292261, "time-step": 4689}, {"errors": 0.014895219499919092, "time-step": 4690}, {"errors": 0.014877672650324181, "time-step": 4691}, {"errors": 0.014860157486389533, "time-step": 4692}, {"errors": 0.014842673940502885, "time-step": 4693}, {"errors": 0.014825221945187966, "time-step": 4694}, {"errors": 0.014807801433104385, "time-step": 4695}, {"errors": 0.014790412337047473, "time-step": 4696}, {"errors": 0.014773054589948396, "time-step": 4697}, {"errors": 0.01475572812487385, "time-step": 4698}, {"errors": 0.014738432875026072, "time-step": 4699}, {"errors": 0.014721168773742683, "time-step": 4700}, {"errors": 0.014703935754496706, "time-step": 4701}, {"errors": 0.014686733750896342, "time-step": 4702}, {"errors": 0.014669562696684877, "time-step": 4703}, {"errors": 0.014652422525740703, "time-step": 4704}, {"errors": 0.014635313172077065, "time-step": 4705}, {"errors": 0.014618234569842035, "time-step": 4706}, {"errors": 0.014601186653318388, "time-step": 4707}, {"errors": 0.014584169356923509, "time-step": 4708}, {"errors": 0.014567182615209225, "time-step": 4709}, {"errors": 0.014550226362861794, "time-step": 4710}, {"errors": 0.014533300534701688, "time-step": 4711}, {"errors": 0.014516405065683516, "time-step": 4712}, {"errors": 0.014499539890895953, "time-step": 4713}, {"errors": 0.014482704945561545, "time-step": 4714}, {"errors": 0.014465900165036644, "time-step": 4715}, {"errors": 0.01444912548481125, "time-step": 4716}, {"errors": 0.014432380840508888, "time-step": 4717}, {"errors": 0.014415666167886611, "time-step": 4718}, {"errors": 0.014398981402834644, "time-step": 4719}, {"errors": 0.014382326481376426, "time-step": 4720}, {"errors": 0.014365701339668462, "time-step": 4721}, {"errors": 0.01434910591400013, "time-step": 4722}, {"errors": 0.014332540140793607, "time-step": 4723}, {"errors": 0.014316003956603747, "time-step": 4724}, {"errors": 0.014299497298117858, "time-step": 4725}, {"errors": 0.014283020102155684, "time-step": 4726}, {"errors": 0.014266572305669217, "time-step": 4727}, {"errors": 0.014250153845742481, "time-step": 4728}, {"errors": 0.014233764659591606, "time-step": 4729}, {"errors": 0.014217404684564451, "time-step": 4730}, {"errors": 0.014201073858140565, "time-step": 4731}, {"errors": 0.014184772117931111, "time-step": 4732}, {"errors": 0.014168499401678617, "time-step": 4733}, {"errors": 0.0141522556472569, "time-step": 4734}, {"errors": 0.014136040792670872, "time-step": 4735}, {"errors": 0.014119854776056394, "time-step": 4736}, {"errors": 0.014103697535680224, "time-step": 4737}, {"errors": 0.01408756900993974, "time-step": 4738}, {"errors": 0.01407146913736285, "time-step": 4739}, {"errors": 0.01405539785660788, "time-step": 4740}, {"errors": 0.014039355106463319, "time-step": 4741}, {"errors": 0.01402334082584776, "time-step": 4742}, {"errors": 0.01400735495380974, "time-step": 4743}, {"errors": 0.013991397429527517, "time-step": 4744}, {"errors": 0.01397546819230893, "time-step": 4745}, {"errors": 0.01395956718159137, "time-step": 4746}, {"errors": 0.013943694336941424, "time-step": 4747}, {"errors": 0.013927849598054796, "time-step": 4748}, {"errors": 0.0139120329047563, "time-step": 4749}, {"errors": 0.013896244196999424, "time-step": 4750}, {"errors": 0.013880483414866385, "time-step": 4751}, {"errors": 0.013864750498567831, "time-step": 4752}, {"errors": 0.013849045388442748, "time-step": 4753}, {"errors": 0.01383336802495837, "time-step": 4754}, {"errors": 0.013817718348709748, "time-step": 4755}, {"errors": 0.013802096300419973, "time-step": 4756}, {"errors": 0.013786501820939625, "time-step": 4757}, {"errors": 0.01377093485124689, "time-step": 4758}, {"errors": 0.013755395332447178, "time-step": 4759}, {"errors": 0.013739883205773146, "time-step": 4760}, {"errors": 0.013724398412584389, "time-step": 4761}, {"errors": 0.01370894089436733, "time-step": 4762}, {"errors": 0.013693510592735032, "time-step": 4763}, {"errors": 0.01367810744942703, "time-step": 4764}, {"errors": 0.013662731406309095, "time-step": 4765}, {"errors": 0.013647382405373235, "time-step": 4766}, {"errors": 0.013632060388737304, "time-step": 4767}, {"errors": 0.013616765298644987, "time-step": 4768}, {"errors": 0.013601497077465493, "time-step": 4769}, {"errors": 0.013586255667693517, "time-step": 4770}, {"errors": 0.013571041011948975, "time-step": 4771}, {"errors": 0.013555853052976803, "time-step": 4772}, {"errors": 0.01354069173364686, "time-step": 4773}, {"errors": 0.01352555699695368, "time-step": 4774}, {"errors": 0.013510448786016326, "time-step": 4775}, {"errors": 0.013495367044078194, "time-step": 4776}, {"errors": 0.013480311714506824, "time-step": 4777}, {"errors": 0.013465282740793748, "time-step": 4778}, {"errors": 0.013450280066554262, "time-step": 4779}, {"errors": 0.01343530363552732, "time-step": 4780}, {"errors": 0.013420353391575206, "time-step": 4781}, {"errors": 0.01340542927868352, "time-step": 4782}, {"errors": 0.013390531240960898, "time-step": 4783}, {"errors": 0.013375659222638786, "time-step": 4784}, {"errors": 0.013360813168071358, "time-step": 4785}, {"errors": 0.01334599302173526, "time-step": 4786}, {"errors": 0.013331198728229412, "time-step": 4787}, {"errors": 0.013316430232274887, "time-step": 4788}, {"errors": 0.013301687478714647, "time-step": 4789}, {"errors": 0.013286970412513435, "time-step": 4790}, {"errors": 0.013272278978757452, "time-step": 4791}, {"errors": 0.013257613122654322, "time-step": 4792}, {"errors": 0.01324297278953283, "time-step": 4793}, {"errors": 0.013228357924842667, "time-step": 4794}, {"errors": 0.013213768474154345, "time-step": 4795}, {"errors": 0.013199204383158936, "time-step": 4796}, {"errors": 0.013184665597667943, "time-step": 4797}, {"errors": 0.013170152063613036, "time-step": 4798}, {"errors": 0.013155663727045873, "time-step": 4799}, {"errors": 0.013141200534137951, "time-step": 4800}, {"errors": 0.013126762431180335, "time-step": 4801}, {"errors": 0.01311234936458358, "time-step": 4802}, {"errors": 0.013097961280877373, "time-step": 4803}, {"errors": 0.013083598126710484, "time-step": 4804}, {"errors": 0.01306925984885051, "time-step": 4805}, {"errors": 0.013054946394183668, "time-step": 4806}, {"errors": 0.013040657709714572, "time-step": 4807}, {"errors": 0.013026393742566148, "time-step": 4808}, {"errors": 0.013012154439979272, "time-step": 4809}, {"errors": 0.012997939749312768, "time-step": 4810}, {"errors": 0.012983749618042998, "time-step": 4811}, {"errors": 0.012969583993763797, "time-step": 4812}, {"errors": 0.012955442824186258, "time-step": 4813}, {"errors": 0.012941326057138505, "time-step": 4814}, {"errors": 0.012927233640565514, "time-step": 4815}, {"errors": 0.012913165522528865, "time-step": 4816}, {"errors": 0.012899121651206647, "time-step": 4817}, {"errors": 0.012885101974893095, "time-step": 4818}, {"errors": 0.012871106441998563, "time-step": 4819}, {"errors": 0.012857135001049201, "time-step": 4820}, {"errors": 0.012843187600686794, "time-step": 4821}, {"errors": 0.012829264189668552, "time-step": 4822}, {"errors": 0.012815364716866937, "time-step": 4823}, {"errors": 0.01280148913126939, "time-step": 4824}, {"errors": 0.012787637381978245, "time-step": 4825}, {"errors": 0.01277380941821041, "time-step": 4826}, {"errors": 0.012760005189297197, "time-step": 4827}, {"errors": 0.012746224644684133, "time-step": 4828}, {"errors": 0.012732467733930785, "time-step": 4829}, {"errors": 0.012718734406710494, "time-step": 4830}, {"errors": 0.012705024612810194, "time-step": 4831}, {"errors": 0.01269133830213023, "time-step": 4832}, {"errors": 0.01267767542468415, "time-step": 4833}, {"errors": 0.012664035930598415, "time-step": 4834}, {"errors": 0.012650419770112373, "time-step": 4835}, {"errors": 0.012636826893577851, "time-step": 4836}, {"errors": 0.012623257251459056, "time-step": 4837}, {"errors": 0.01260971079433238, "time-step": 4838}, {"errors": 0.01259618747288618, "time-step": 4839}, {"errors": 0.012582687237920553, "time-step": 4840}, {"errors": 0.012569210040347105, "time-step": 4841}, {"errors": 0.012555755831188804, "time-step": 4842}, {"errors": 0.012542324561579736, "time-step": 4843}, {"errors": 0.012528916182764928, "time-step": 4844}, {"errors": 0.012515530646100104, "time-step": 4845}, {"errors": 0.012502167903051493, "time-step": 4846}, {"errors": 0.012488827905195626, "time-step": 4847}, {"errors": 0.012475510604219139, "time-step": 4848}, {"errors": 0.012462215951918546, "time-step": 4849}, {"errors": 0.012448943900200037, "time-step": 4850}, {"errors": 0.012435694401079275, "time-step": 4851}, {"errors": 0.012422467406681171, "time-step": 4852}, {"errors": 0.012409262869239695, "time-step": 4853}, {"errors": 0.012396080741097677, "time-step": 4854}, {"errors": 0.012382920974706613, "time-step": 4855}, {"errors": 0.01236978352262635, "time-step": 4856}, {"errors": 0.012356668337525013, "time-step": 4857}, {"errors": 0.012343575372178714, "time-step": 4858}, {"errors": 0.012330504579471404, "time-step": 4859}, {"errors": 0.012317455912394599, "time-step": 4860}, {"errors": 0.012304429324047243, "time-step": 4861}, {"errors": 0.012291424767635402, "time-step": 4862}, {"errors": 0.012278442196472145, "time-step": 4863}, {"errors": 0.012265481563977308, "time-step": 4864}, {"errors": 0.012252542823677298, "time-step": 4865}, {"errors": 0.012239625929204832, "time-step": 4866}, {"errors": 0.012226730834298753, "time-step": 4867}, {"errors": 0.012213857492803896, "time-step": 4868}, {"errors": 0.012201005858670743, "time-step": 4869}, {"errors": 0.012188175885955319, "time-step": 4870}, {"errors": 0.01217536752881898, "time-step": 4871}, {"errors": 0.012162580741528145, "time-step": 4872}, {"errors": 0.012149815478454097, "time-step": 4873}, {"errors": 0.012137071694072845, "time-step": 4874}, {"errors": 0.012124349342964812, "time-step": 4875}, {"errors": 0.012111648379814745, "time-step": 4876}, {"errors": 0.012098968759411355, "time-step": 4877}, {"errors": 0.012086310436647282, "time-step": 4878}, {"errors": 0.012073673366518736, "time-step": 4879}, {"errors": 0.012061057504125373, "time-step": 4880}, {"errors": 0.012048462804670087, "time-step": 4881}, {"errors": 0.012035889223458746, "time-step": 4882}, {"errors": 0.012023336715900022, "time-step": 4883}, {"errors": 0.012010805237505178, "time-step": 4884}, {"errors": 0.0119982947438879, "time-step": 4885}, {"errors": 0.011985805190763966, "time-step": 4886}, {"errors": 0.011973336533951202, "time-step": 4887}, {"errors": 0.01196088872936912, "time-step": 4888}, {"errors": 0.011948461733038877, "time-step": 4889}, {"errors": 0.011936055501082857, "time-step": 4890}, {"errors": 0.011923669989724644, "time-step": 4891}, {"errors": 0.011911305155288737, "time-step": 4892}, {"errors": 0.011898960954200339, "time-step": 4893}, {"errors": 0.011886637342985194, "time-step": 4894}, {"errors": 0.011874334278269321, "time-step": 4895}, {"errors": 0.011862051716778808, "time-step": 4896}, {"errors": 0.011849789615339695, "time-step": 4897}, {"errors": 0.011837547930877663, "time-step": 4898}, {"errors": 0.011825326620417864, "time-step": 4899}, {"errors": 0.01181312564108473, "time-step": 4900}, {"errors": 0.011800944950101722, "time-step": 4901}, {"errors": 0.011788784504791178, "time-step": 4902}, {"errors": 0.011776644262574104, "time-step": 4903}, {"errors": 0.01176452418096988, "time-step": 4904}, {"errors": 0.011752424217596159, "time-step": 4905}, {"errors": 0.011740344330168627, "time-step": 4906}, {"errors": 0.011728284476500745, "time-step": 4907}, {"errors": 0.01171624461450364, "time-step": 4908}, {"errors": 0.011704224702185791, "time-step": 4909}, {"errors": 0.011692224697652926, "time-step": 4910}, {"errors": 0.011680244559107739, "time-step": 4911}, {"errors": 0.011668284244849749, "time-step": 4912}, {"errors": 0.011656343713274949, "time-step": 4913}, {"errors": 0.011644422922875867, "time-step": 4914}, {"errors": 0.01163252183224109, "time-step": 4915}, {"errors": 0.011620640400055185, "time-step": 4916}, {"errors": 0.011608778585098541, "time-step": 4917}, {"errors": 0.011596936346247057, "time-step": 4918}, {"errors": 0.011585113642471983, "time-step": 4919}, {"errors": 0.011573310432839734, "time-step": 4920}, {"errors": 0.01156152667651168, "time-step": 4921}, {"errors": 0.011549762332743884, "time-step": 4922}, {"errors": 0.011538017360887004, "time-step": 4923}, {"errors": 0.011526291720386012, "time-step": 4924}, {"errors": 0.011514585370779961, "time-step": 4925}, {"errors": 0.011502898271701858, "time-step": 4926}, {"errors": 0.011491230382878501, "time-step": 4927}, {"errors": 0.011479581664130123, "time-step": 4928}, {"errors": 0.01146795207537029, "time-step": 4929}, {"errors": 0.011456341576605689, "time-step": 4930}, {"errors": 0.01144475012793592, "time-step": 4931}, {"errors": 0.011433177689553303, "time-step": 4932}, {"errors": 0.011421624221742645, "time-step": 4933}, {"errors": 0.011410089684881053, "time-step": 4934}, {"errors": 0.011398574039437743, "time-step": 4935}, {"errors": 0.011387077245973888, "time-step": 4936}, {"errors": 0.011375599265142275, "time-step": 4937}, {"errors": 0.011364140057687235, "time-step": 4938}, {"errors": 0.011352699584444358, "time-step": 4939}, {"errors": 0.011341277806340413, "time-step": 4940}, {"errors": 0.01132987468439298, "time-step": 4941}, {"errors": 0.01131849017971039, "time-step": 4942}, {"errors": 0.011307124253491455, "time-step": 4943}, {"errors": 0.011295776867025261, "time-step": 4944}, {"errors": 0.011284447981691028, "time-step": 4945}, {"errors": 0.011273137558957856, "time-step": 4946}, {"errors": 0.011261845560384552, "time-step": 4947}, {"errors": 0.01125057194761942, "time-step": 4948}, {"errors": 0.011239316682400032, "time-step": 4949}, {"errors": 0.01122807972655311, "time-step": 4950}, {"errors": 0.01121686104199429, "time-step": 4951}, {"errors": 0.011205660590727817, "time-step": 4952}, {"errors": 0.011194478334846594, "time-step": 4953}, {"errors": 0.011183314236531705, "time-step": 4954}, {"errors": 0.011172168258052432, "time-step": 4955}, {"errors": 0.011161040361765927, "time-step": 4956}, {"errors": 0.011149930510117072, "time-step": 4957}, {"errors": 0.011138838665638275, "time-step": 4958}, {"errors": 0.01112776479094928, "time-step": 4959}, {"errors": 0.011116708848756962, "time-step": 4960}, {"errors": 0.011105670801855113, "time-step": 4961}, {"errors": 0.011094650613124259, "time-step": 4962}, {"errors": 0.01108364824553154, "time-step": 4963}, {"errors": 0.011072663662130335, "time-step": 4964}, {"errors": 0.011061696826060265, "time-step": 4965}, {"errors": 0.011050747700546855, "time-step": 4966}, {"errors": 0.011039816248901466, "time-step": 4967}, {"errors": 0.01102890243452093, "time-step": 4968}, {"errors": 0.011018006220887559, "time-step": 4969}, {"errors": 0.011007127571568786, "time-step": 4970}, {"errors": 0.010996266450217016, "time-step": 4971}, {"errors": 0.010985422820569565, "time-step": 4972}, {"errors": 0.010974596646448183, "time-step": 4973}, {"errors": 0.010963787891759195, "time-step": 4974}, {"errors": 0.01095299652049303, "time-step": 4975}, {"errors": 0.010942222496724224, "time-step": 4976}, {"errors": 0.010931465784611115, "time-step": 4977}, {"errors": 0.010920726348395702, "time-step": 4978}, {"errors": 0.010910004152403362, "time-step": 4979}, {"errors": 0.010899299161042882, "time-step": 4980}, {"errors": 0.01088861133880599, "time-step": 4981}, {"errors": 0.010877940650267358, "time-step": 4982}, {"errors": 0.01086728706008433, "time-step": 4983}, {"errors": 0.01085665053299678, "time-step": 4984}, {"errors": 0.010846031033826867, "time-step": 4985}, {"errors": 0.010835428527478892, "time-step": 4986}, {"errors": 0.010824842978939087, "time-step": 4987}, {"errors": 0.01081427435327541, "time-step": 4988}, {"errors": 0.010803722615637392, "time-step": 4989}, {"errors": 0.010793187731255973, "time-step": 4990}, {"errors": 0.010782669665443199, "time-step": 4991}, {"errors": 0.010772168383592181, "time-step": 4992}, {"errors": 0.010761683851176804, "time-step": 4993}, {"errors": 0.010751216033751588, "time-step": 4994}, {"errors": 0.010740764896951471, "time-step": 4995}, {"errors": 0.010730330406491618, "time-step": 4996}, {"errors": 0.010719912528167366, "time-step": 4997}, {"errors": 0.010709511227853777, "time-step": 4998}, {"errors": 0.010699126471505706, "time-step": 4999}]}}, {"mode": "vega-lite"});
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The error curve is revealing. After the first few iterations the error dropped fast to around 0.13, and from there went down more gradually. If you are wondering how the accuracy is 100% although the error is not zero, remember that the binary predictions have no business in the error computation and that many different sets of weights may generate the correct predictions.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Application:-multilayer-perceptron-with-Keras">Application: multilayer perceptron with Keras<a class="anchor-link" href="#Application:-multilayer-perceptron-with-Keras"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The reason we implemented our own multilayer perceptron was for <strong>pedagogical purposes</strong>. Richard Feynman once famously said: "<strong>What I cannot create I do not understand</strong>", which is probably an exaggeration but I personally agree with the principle of "learning by creating". Learning to build neural networks is similar to learn math (maybe because they are <em>literally</em> math): yes, you'll end up using a calculator to compute almost everything, yet, we still do the exercise of computing systems of equations by hand when learning algebra. There is a deeper level of understanding that is unlocked when you actually get to build something from scratch.</p>
<p>Nonetheless, there is no need to go through this process every time. Nowadays, we have access to very good libraries to build neural networks. <a href="https://keras.io/">Keras</a> is a popular Python library for this. Keras main strength is the simplicity and elegance of its interface (sometimes people call it "API"). Keras hides most of the computations to the users and provides a way to define neural networks that match with what you would normally do when drawing a diagram. There are many other libraries you may hear about (Tensorflow, PyTorch, MXNet, Caffe, etc.) but I'll use this one because is the best for beginners in my opinion.</p>
<p>Next, we will build another multi-layer perceptron to solve the same XOR Problem and to illustrate how simple is the process with Keras.</p>
<p>This time, I'll put together a network with the following characteristics:</p>
<ul>
<li><strong>Input layer</strong> with 2 neurons (i.e., the two features).</li>
<li><strong>One hidden</strong> layer with 16 neurons with sigmoid activation functions.</li>
<li><strong>Output layer</strong> with 1 neuron with a sigmoid activation (i.e., a target value of 0 or 1).</li>
<li><strong>Mean squared error</strong> as the cost (or loss) function.</li>
<li><strong>"Adam" optimizer</strong>. This a variation of gradient descent that (sometimes) speed up the process by adapting the learning rate for each parameter in the network. It has the advantage that we don't need to manually search for the learning rate.</li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers.core</span> <span class="kn">import</span> <span class="n">Dense</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's generate the training data</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># expected values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># features</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's examine the model definition:</p>
<ul>
<li><code>Sequential()</code> specifies that the network is a linear stack of layers</li>
<li><code>model.add()</code> adds the hidden layer.</li>
<li><code>Dense</code> means that neurons between layers are fully connected</li>
<li><code>input_dim</code> defines the number of features in the training dataset</li>
<li><code>activation</code> defines the activation function</li>
<li><code>loss</code> selects the cost function</li>
<li><code>optimizer</code> selects the learning algorithm</li>
<li><code>metrics</code> selects the performance metrics to be saved for further analysis</li>
<li><code>model.fit()</code> initialize the training</li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_squared_error&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">errors</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>

<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;errors&quot;</span><span class="p">:</span><span class="n">errors</span><span class="p">,</span> <span class="s2">&quot;time-step&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">errors</span><span class="p">))})</span>

<span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">df2</span><span class="p">)</span><span class="o">.</span><span class="n">mark_line</span><span class="p">()</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;time-step&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;errors&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">properties</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Chart 3&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

<div id="altair-viz-5a49cb839eee4a98b3193b60ef11f4bf"></div>
<script type="text/javascript">
  (function(spec, embedOpt){
    const outputDiv = document.getElementById("altair-viz-5a49cb839eee4a98b3193b60ef11f4bf");
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm//vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm//vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm//vega-embed@6?noext",
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () => resolve(paths[lib]);
        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName("head")[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === "function") {
      displayChart(vegaEmbed);
    } else {
      loadScript("vega")
        .then(() => loadScript("vega-lite"))
        .then(() => loadScript("vega-embed"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 400, "continuousHeight": 300}}, "data": {"name": "data-6bfc0a5d97678e1be6f97ee0918be17a"}, "mark": "line", "encoding": {"x": {"type": "quantitative", "field": "time-step"}, "y": {"type": "quantitative", "field": "errors"}}, "title": "Chart 3", "$schema": "https://vega.github.io/schema/vega-lite/v4.0.2.json", "datasets": {"data-6bfc0a5d97678e1be6f97ee0918be17a": [{"errors": 0.3597352206707001, "time-step": 0}, {"errors": 0.3589778542518616, "time-step": 1}, {"errors": 0.3581027090549469, "time-step": 2}, {"errors": 0.35708147287368774, "time-step": 3}, {"errors": 0.3560582399368286, "time-step": 4}, {"errors": 0.35503315925598145, "time-step": 5}, {"errors": 0.3540063202381134, "time-step": 6}, {"errors": 0.35297778248786926, "time-step": 7}, {"errors": 0.351947546005249, "time-step": 8}, {"errors": 0.3509158194065094, "time-step": 9}, {"errors": 0.34988269209861755, "time-step": 10}, {"errors": 0.3488481044769287, "time-step": 11}, {"errors": 0.34781235456466675, "time-step": 12}, {"errors": 0.3467753529548645, "time-step": 13}, {"errors": 0.3457373380661011, "time-step": 14}, {"errors": 0.34469836950302124, "time-step": 15}, {"errors": 0.34365859627723694, "time-step": 16}, {"errors": 0.34261804819107056, "time-step": 17}, {"errors": 0.3415769338607788, "time-step": 18}, {"errors": 0.34053534269332886, "time-step": 19}, {"errors": 0.3394935131072998, "time-step": 20}, {"errors": 0.3384513854980469, "time-step": 21}, {"errors": 0.33739760518074036, "time-step": 22}, {"errors": 0.3363555371761322, "time-step": 23}, {"errors": 0.33531373739242554, "time-step": 24}, {"errors": 0.3342723250389099, "time-step": 25}, {"errors": 0.33323144912719727, "time-step": 26}, {"errors": 0.33219125866889954, "time-step": 27}, {"errors": 0.33115196228027344, "time-step": 28}, {"errors": 0.33011364936828613, "time-step": 29}, {"errors": 0.32907652854919434, "time-step": 30}, {"errors": 0.3280407190322876, "time-step": 31}, {"errors": 0.3270064890384674, "time-step": 32}, {"errors": 0.32597389817237854, "time-step": 33}, {"errors": 0.32494330406188965, "time-step": 34}, {"errors": 0.3239145278930664, "time-step": 35}, {"errors": 0.32288825511932373, "time-step": 36}, {"errors": 0.32186415791511536, "time-step": 37}, {"errors": 0.3208426833152771, "time-step": 38}, {"errors": 0.31982406973838806, "time-step": 39}, {"errors": 0.3188084363937378, "time-step": 40}, {"errors": 0.31779584288597107, "time-step": 41}, {"errors": 0.31678664684295654, "time-step": 42}, {"errors": 0.31578096747398376, "time-step": 43}, {"errors": 0.3147689700126648, "time-step": 44}, {"errors": 0.31377094984054565, "time-step": 45}, {"errors": 0.3127771019935608, "time-step": 46}, {"errors": 0.31178751587867737, "time-step": 47}, {"errors": 0.3108024597167969, "time-step": 48}, {"errors": 0.3098221719264984, "time-step": 49}, {"errors": 0.30884671211242676, "time-step": 50}, {"errors": 0.3078763484954834, "time-step": 51}, {"errors": 0.30691128969192505, "time-step": 52}, {"errors": 0.3059517741203308, "time-step": 53}, {"errors": 0.3049979507923126, "time-step": 54}, {"errors": 0.30404990911483765, "time-step": 55}, {"errors": 0.3031080365180969, "time-step": 56}, {"errors": 0.30217236280441284, "time-step": 57}, {"errors": 0.3012431561946869, "time-step": 58}, {"errors": 0.300320565700531, "time-step": 59}, {"errors": 0.2994048595428467, "time-step": 60}, {"errors": 0.2984960079193115, "time-step": 61}, {"errors": 0.29759442806243896, "time-step": 62}, {"errors": 0.2967001497745514, "time-step": 63}, {"errors": 0.2958133816719055, "time-step": 64}, {"errors": 0.29493433237075806, "time-step": 65}, {"errors": 0.29406309127807617, "time-step": 66}, {"errors": 0.2931998372077942, "time-step": 67}, {"errors": 0.29234474897384644, "time-step": 68}, {"errors": 0.29149800539016724, "time-step": 69}, {"errors": 0.29065966606140137, "time-step": 70}, {"errors": 0.28982993960380554, "time-step": 71}, {"errors": 0.2890089750289917, "time-step": 72}, {"errors": 0.2881968319416046, "time-step": 73}, {"errors": 0.287393718957901, "time-step": 74}, {"errors": 0.28659969568252563, "time-step": 75}, {"errors": 0.28581491112709045, "time-step": 76}, {"errors": 0.285034716129303, "time-step": 77}, {"errors": 0.28426870703697205, "time-step": 78}, {"errors": 0.2835123538970947, "time-step": 79}, {"errors": 0.28276553750038147, "time-step": 80}, {"errors": 0.28202855587005615, "time-step": 81}, {"errors": 0.281301349401474, "time-step": 82}, {"errors": 0.28058406710624695, "time-step": 83}, {"errors": 0.279876708984375, "time-step": 84}, {"errors": 0.2791794240474701, "time-step": 85}, {"errors": 0.2784922420978546, "time-step": 86}, {"errors": 0.27781519293785095, "time-step": 87}, {"errors": 0.2771483063697815, "time-step": 88}, {"errors": 0.2764917016029358, "time-step": 89}, {"errors": 0.27584534883499146, "time-step": 90}, {"errors": 0.27520933747291565, "time-step": 91}, {"errors": 0.274583637714386, "time-step": 92}, {"errors": 0.27396824955940247, "time-step": 93}, {"errors": 0.27336329221725464, "time-step": 94}, {"errors": 0.27276861667633057, "time-step": 95}, {"errors": 0.2721843719482422, "time-step": 96}, {"errors": 0.2716104984283447, "time-step": 97}, {"errors": 0.27104416489601135, "time-step": 98}, {"errors": 0.27048835158348083, "time-step": 99}, {"errors": 0.269942969083786, "time-step": 100}, {"errors": 0.2694079577922821, "time-step": 101}, {"errors": 0.26888328790664673, "time-step": 102}, {"errors": 0.2683689594268799, "time-step": 103}, {"errors": 0.26786714792251587, "time-step": 104}, {"errors": 0.26737549901008606, "time-step": 105}, {"errors": 0.26689383387565613, "time-step": 106}, {"errors": 0.2664222717285156, "time-step": 107}, {"errors": 0.26596057415008545, "time-step": 108}, {"errors": 0.265508770942688, "time-step": 109}, {"errors": 0.26506686210632324, "time-step": 110}, {"errors": 0.26463449001312256, "time-step": 111}, {"errors": 0.26421189308166504, "time-step": 112}, {"errors": 0.2637988030910492, "time-step": 113}, {"errors": 0.26339513063430786, "time-step": 114}, {"errors": 0.26300084590911865, "time-step": 115}, {"errors": 0.2626158893108368, "time-step": 116}, {"errors": 0.26224005222320557, "time-step": 117}, {"errors": 0.2618733048439026, "time-step": 118}, {"errors": 0.26151540875434875, "time-step": 119}, {"errors": 0.2611664831638336, "time-step": 120}, {"errors": 0.2608262300491333, "time-step": 121}, {"errors": 0.260494589805603, "time-step": 122}, {"errors": 0.26017144322395325, "time-step": 123}, {"errors": 0.2598566710948944, "time-step": 124}, {"errors": 0.2595501244068146, "time-step": 125}, {"errors": 0.25925174355506897, "time-step": 126}, {"errors": 0.25896134972572327, "time-step": 127}, {"errors": 0.2586788535118103, "time-step": 128}, {"errors": 0.25840407609939575, "time-step": 129}, {"errors": 0.2581368386745453, "time-step": 130}, {"errors": 0.2578771710395813, "time-step": 131}, {"errors": 0.2576248347759247, "time-step": 132}, {"errors": 0.2573796808719635, "time-step": 133}, {"errors": 0.2571415901184082, "time-step": 134}, {"errors": 0.2569104731082916, "time-step": 135}, {"errors": 0.25668615102767944, "time-step": 136}, {"errors": 0.2564685046672821, "time-step": 137}, {"errors": 0.25625738501548767, "time-step": 138}, {"errors": 0.2560526132583618, "time-step": 139}, {"errors": 0.25585418939590454, "time-step": 140}, {"errors": 0.25566181540489197, "time-step": 141}, {"errors": 0.2554754912853241, "time-step": 142}, {"errors": 0.2552949786186218, "time-step": 143}, {"errors": 0.255120187997818, "time-step": 144}, {"errors": 0.25495100021362305, "time-step": 145}, {"errors": 0.25478726625442505, "time-step": 146}, {"errors": 0.25462883710861206, "time-step": 147}, {"errors": 0.2544756233692169, "time-step": 148}, {"errors": 0.2543274760246277, "time-step": 149}, {"errors": 0.2541842460632324, "time-step": 150}, {"errors": 0.2540458142757416, "time-step": 151}, {"errors": 0.2539120316505432, "time-step": 152}, {"errors": 0.25378286838531494, "time-step": 153}, {"errors": 0.25365811586380005, "time-step": 154}, {"errors": 0.253537654876709, "time-step": 155}, {"errors": 0.253421425819397, "time-step": 156}, {"errors": 0.2533092200756073, "time-step": 157}, {"errors": 0.25320103764533997, "time-step": 158}, {"errors": 0.25309664011001587, "time-step": 159}, {"errors": 0.2529959976673126, "time-step": 160}, {"errors": 0.2528989911079407, "time-step": 161}, {"errors": 0.2528054714202881, "time-step": 162}, {"errors": 0.25271540880203247, "time-step": 163}, {"errors": 0.2526286244392395, "time-step": 164}, {"errors": 0.2525450587272644, "time-step": 165}, {"errors": 0.25246456265449524, "time-step": 166}, {"errors": 0.25238707661628723, "time-step": 167}, {"errors": 0.25231248140335083, "time-step": 168}, {"errors": 0.25224074721336365, "time-step": 169}, {"errors": 0.25217169523239136, "time-step": 170}, {"errors": 0.2521052658557892, "time-step": 171}, {"errors": 0.25204142928123474, "time-step": 172}, {"errors": 0.2519800066947937, "time-step": 173}, {"errors": 0.2519209682941437, "time-step": 174}, {"errors": 0.2518641948699951, "time-step": 175}, {"errors": 0.2518097162246704, "time-step": 176}, {"errors": 0.25175729393959045, "time-step": 177}, {"errors": 0.25170695781707764, "time-step": 178}, {"errors": 0.2516586184501648, "time-step": 179}, {"errors": 0.2516121566295624, "time-step": 180}, {"errors": 0.251567542552948, "time-step": 181}, {"errors": 0.25152477622032166, "time-step": 182}, {"errors": 0.25148364901542664, "time-step": 183}, {"errors": 0.25144416093826294, "time-step": 184}, {"errors": 0.25140631198883057, "time-step": 185}, {"errors": 0.25137001276016235, "time-step": 186}, {"errors": 0.251335084438324, "time-step": 187}, {"errors": 0.2513016164302826, "time-step": 188}, {"errors": 0.25126951932907104, "time-step": 189}, {"errors": 0.25123873353004456, "time-step": 190}, {"errors": 0.25120916962623596, "time-step": 191}, {"errors": 0.25118082761764526, "time-step": 192}, {"errors": 0.2511536478996277, "time-step": 193}, {"errors": 0.25112754106521606, "time-step": 194}, {"errors": 0.2511025369167328, "time-step": 195}, {"errors": 0.2510785460472107, "time-step": 196}, {"errors": 0.2510555386543274, "time-step": 197}, {"errors": 0.2510334551334381, "time-step": 198}, {"errors": 0.25101226568222046, "time-step": 199}, {"errors": 0.25099194049835205, "time-step": 200}, {"errors": 0.2509724795818329, "time-step": 201}, {"errors": 0.2509537637233734, "time-step": 202}, {"errors": 0.25093579292297363, "time-step": 203}, {"errors": 0.2509186267852783, "time-step": 204}, {"errors": 0.25090205669403076, "time-step": 205}, {"errors": 0.2508862316608429, "time-step": 206}, {"errors": 0.2508710026741028, "time-step": 207}, {"errors": 0.25085633993148804, "time-step": 208}, {"errors": 0.2508423328399658, "time-step": 209}, {"errors": 0.2508288621902466, "time-step": 210}, {"errors": 0.25081586837768555, "time-step": 211}, {"errors": 0.2508034110069275, "time-step": 212}, {"errors": 0.2507914900779724, "time-step": 213}, {"errors": 0.25077998638153076, "time-step": 214}, {"errors": 0.2507689297199249, "time-step": 215}, {"errors": 0.25075826048851013, "time-step": 216}, {"errors": 0.25074803829193115, "time-step": 217}, {"errors": 0.2507381737232208, "time-step": 218}, {"errors": 0.25072866678237915, "time-step": 219}, {"errors": 0.2507195472717285, "time-step": 220}, {"errors": 0.25071072578430176, "time-step": 221}, {"errors": 0.25070223212242126, "time-step": 222}, {"errors": 0.25069403648376465, "time-step": 223}, {"errors": 0.2506861090660095, "time-step": 224}, {"errors": 0.25067847967147827, "time-step": 225}, {"errors": 0.2506710886955261, "time-step": 226}, {"errors": 0.2506639361381531, "time-step": 227}, {"errors": 0.2506570816040039, "time-step": 228}, {"errors": 0.25065040588378906, "time-step": 229}, {"errors": 0.25064393877983093, "time-step": 230}, {"errors": 0.2506376802921295, "time-step": 231}, {"errors": 0.2506316304206848, "time-step": 232}, {"errors": 0.25062572956085205, "time-step": 233}, {"errors": 0.2506200671195984, "time-step": 234}, {"errors": 0.2506144940853119, "time-step": 235}, {"errors": 0.2506091594696045, "time-step": 236}, {"errors": 0.25060391426086426, "time-step": 237}, {"errors": 0.2505987882614136, "time-step": 238}, {"errors": 0.2505938708782196, "time-step": 239}, {"errors": 0.2505890130996704, "time-step": 240}, {"errors": 0.25058433413505554, "time-step": 241}, {"errors": 0.25057974457740784, "time-step": 242}, {"errors": 0.2505752742290497, "time-step": 243}, {"errors": 0.2505709230899811, "time-step": 244}, {"errors": 0.25056663155555725, "time-step": 245}, {"errors": 0.2505624294281006, "time-step": 246}, {"errors": 0.25055834650993347, "time-step": 247}, {"errors": 0.2505543529987335, "time-step": 248}, {"errors": 0.25055041909217834, "time-step": 249}, {"errors": 0.25054657459259033, "time-step": 250}, {"errors": 0.2505427896976471, "time-step": 251}, {"errors": 0.250539094209671, "time-step": 252}, {"errors": 0.2505354583263397, "time-step": 253}, {"errors": 0.2505318522453308, "time-step": 254}, {"errors": 0.25052833557128906, "time-step": 255}, {"errors": 0.2505248785018921, "time-step": 256}, {"errors": 0.2505214512348175, "time-step": 257}, {"errors": 0.2505181133747101, "time-step": 258}, {"errors": 0.25051477551460266, "time-step": 259}, {"errors": 0.2505115270614624, "time-step": 260}, {"errors": 0.25050827860832214, "time-step": 261}, {"errors": 0.25050508975982666, "time-step": 262}, {"errors": 0.25050193071365356, "time-step": 263}, {"errors": 0.25049886107444763, "time-step": 264}, {"errors": 0.2504957318305969, "time-step": 265}, {"errors": 0.25049272179603577, "time-step": 266}, {"errors": 0.2504896819591522, "time-step": 267}, {"errors": 0.25048673152923584, "time-step": 268}, {"errors": 0.25048378109931946, "time-step": 269}, {"errors": 0.2504808306694031, "time-step": 270}, {"errors": 0.2504779100418091, "time-step": 271}, {"errors": 0.25047504901885986, "time-step": 272}, {"errors": 0.25047218799591064, "time-step": 273}, {"errors": 0.2504693865776062, "time-step": 274}, {"errors": 0.25046655535697937, "time-step": 275}, {"errors": 0.2504637539386749, "time-step": 276}, {"errors": 0.2504609525203705, "time-step": 277}, {"errors": 0.2504582405090332, "time-step": 278}, {"errors": 0.25045549869537354, "time-step": 279}, {"errors": 0.25045281648635864, "time-step": 280}, {"errors": 0.25045010447502136, "time-step": 281}, {"errors": 0.25044742226600647, "time-step": 282}, {"errors": 0.25044476985931396, "time-step": 283}, {"errors": 0.2504420876502991, "time-step": 284}, {"errors": 0.25043943524360657, "time-step": 285}, {"errors": 0.25043681263923645, "time-step": 286}, {"errors": 0.25043419003486633, "time-step": 287}, {"errors": 0.2504315674304962, "time-step": 288}, {"errors": 0.2504289746284485, "time-step": 289}, {"errors": 0.25042638182640076, "time-step": 290}, {"errors": 0.2504238188266754, "time-step": 291}, {"errors": 0.2504212558269501, "time-step": 292}, {"errors": 0.25041869282722473, "time-step": 293}, {"errors": 0.2504161596298218, "time-step": 294}, {"errors": 0.2504136264324188, "time-step": 295}, {"errors": 0.25041109323501587, "time-step": 296}, {"errors": 0.2504085600376129, "time-step": 297}, {"errors": 0.25040602684020996, "time-step": 298}, {"errors": 0.2504035532474518, "time-step": 299}, {"errors": 0.2504010498523712, "time-step": 300}, {"errors": 0.25039854645729065, "time-step": 301}, {"errors": 0.2503960430622101, "time-step": 302}, {"errors": 0.2503935992717743, "time-step": 303}, {"errors": 0.2503910958766937, "time-step": 304}, {"errors": 0.25038865208625793, "time-step": 305}, {"errors": 0.25038617849349976, "time-step": 306}, {"errors": 0.25038376450538635, "time-step": 307}, {"errors": 0.2503812909126282, "time-step": 308}, {"errors": 0.2503788471221924, "time-step": 309}, {"errors": 0.2503764033317566, "time-step": 310}, {"errors": 0.2503739595413208, "time-step": 311}, {"errors": 0.2503715753555298, "time-step": 312}, {"errors": 0.2503691613674164, "time-step": 313}, {"errors": 0.250366747379303, "time-step": 314}, {"errors": 0.25036436319351196, "time-step": 315}, {"errors": 0.25036191940307617, "time-step": 316}, {"errors": 0.2503594756126404, "time-step": 317}, {"errors": 0.25035709142684937, "time-step": 318}, {"errors": 0.25035473704338074, "time-step": 319}, {"errors": 0.2503523528575897, "time-step": 320}, {"errors": 0.2503499686717987, "time-step": 321}, {"errors": 0.2503475844860077, "time-step": 322}, {"errors": 0.2503452003002167, "time-step": 323}, {"errors": 0.25034284591674805, "time-step": 324}, {"errors": 0.2503404915332794, "time-step": 325}, {"errors": 0.2503381371498108, "time-step": 326}, {"errors": 0.2503357529640198, "time-step": 327}, {"errors": 0.25033342838287354, "time-step": 328}, {"errors": 0.2503310441970825, "time-step": 329}, {"errors": 0.2503287196159363, "time-step": 330}, {"errors": 0.25032639503479004, "time-step": 331}, {"errors": 0.2503240406513214, "time-step": 332}, {"errors": 0.25032171607017517, "time-step": 333}, {"errors": 0.25031936168670654, "time-step": 334}, {"errors": 0.2503170371055603, "time-step": 335}, {"errors": 0.25031477212905884, "time-step": 336}, {"errors": 0.2503124475479126, "time-step": 337}, {"errors": 0.25031009316444397, "time-step": 338}, {"errors": 0.25030776858329773, "time-step": 339}, {"errors": 0.2503054738044739, "time-step": 340}, {"errors": 0.25030317902565, "time-step": 341}, {"errors": 0.25030088424682617, "time-step": 342}, {"errors": 0.2502985894680023, "time-step": 343}, {"errors": 0.2502962648868561, "time-step": 344}, {"errors": 0.2502939999103546, "time-step": 345}, {"errors": 0.2502916753292084, "time-step": 346}, {"errors": 0.2502893805503845, "time-step": 347}, {"errors": 0.25028711557388306, "time-step": 348}, {"errors": 0.2502848505973816, "time-step": 349}, {"errors": 0.2502825856208801, "time-step": 350}, {"errors": 0.2502802908420563, "time-step": 351}, {"errors": 0.2502780258655548, "time-step": 352}, {"errors": 0.25027576088905334, "time-step": 353}, {"errors": 0.2502734661102295, "time-step": 354}, {"errors": 0.250271201133728, "time-step": 355}, {"errors": 0.25026896595954895, "time-step": 356}, {"errors": 0.2502667009830475, "time-step": 357}, {"errors": 0.250264436006546, "time-step": 358}, {"errors": 0.25026220083236694, "time-step": 359}, {"errors": 0.2502599358558655, "time-step": 360}, {"errors": 0.2502577006816864, "time-step": 361}, {"errors": 0.2502554655075073, "time-step": 362}, {"errors": 0.25025320053100586, "time-step": 363}, {"errors": 0.25025099515914917, "time-step": 364}, {"errors": 0.2502487599849701, "time-step": 365}, {"errors": 0.250246524810791, "time-step": 366}, {"errors": 0.25024425983428955, "time-step": 367}, {"errors": 0.25024205446243286, "time-step": 368}, {"errors": 0.25023984909057617, "time-step": 369}, {"errors": 0.2502375841140747, "time-step": 370}, {"errors": 0.25023531913757324, "time-step": 371}, {"errors": 0.25023314356803894, "time-step": 372}, {"errors": 0.25023093819618225, "time-step": 373}, {"errors": 0.2502287030220032, "time-step": 374}, {"errors": 0.2502264976501465, "time-step": 375}, {"errors": 0.2502242624759674, "time-step": 376}, {"errors": 0.2502220869064331, "time-step": 377}, {"errors": 0.2502198815345764, "time-step": 378}, {"errors": 0.25021764636039734, "time-step": 379}, {"errors": 0.25021547079086304, "time-step": 380}, {"errors": 0.25021326541900635, "time-step": 381}, {"errors": 0.25021106004714966, "time-step": 382}, {"errors": 0.25020888447761536, "time-step": 383}, {"errors": 0.25020667910575867, "time-step": 384}, {"errors": 0.25020450353622437, "time-step": 385}, {"errors": 0.2502022683620453, "time-step": 386}, {"errors": 0.2502001225948334, "time-step": 387}, {"errors": 0.2501978874206543, "time-step": 388}, {"errors": 0.2501957416534424, "time-step": 389}, {"errors": 0.2501935362815857, "time-step": 390}, {"errors": 0.2501913905143738, "time-step": 391}, {"errors": 0.2501892149448395, "time-step": 392}, {"errors": 0.2501870393753052, "time-step": 393}, {"errors": 0.2501848340034485, "time-step": 394}, {"errors": 0.2501826584339142, "time-step": 395}, {"errors": 0.25018051266670227, "time-step": 396}, {"errors": 0.2501783072948456, "time-step": 397}, {"errors": 0.25017616152763367, "time-step": 398}, {"errors": 0.25017401576042175, "time-step": 399}, {"errors": 0.25017181038856506, "time-step": 400}, {"errors": 0.25016969442367554, "time-step": 401}, {"errors": 0.2501675486564636, "time-step": 402}, {"errors": 0.25016534328460693, "time-step": 403}, {"errors": 0.250163197517395, "time-step": 404}, {"errors": 0.2501610517501831, "time-step": 405}, {"errors": 0.2501589059829712, "time-step": 406}, {"errors": 0.2501567602157593, "time-step": 407}, {"errors": 0.25015461444854736, "time-step": 408}, {"errors": 0.25015246868133545, "time-step": 409}, {"errors": 0.25015032291412354, "time-step": 410}, {"errors": 0.25014814734458923, "time-step": 411}, {"errors": 0.2501460313796997, "time-step": 412}, {"errors": 0.2501438856124878, "time-step": 413}, {"errors": 0.2501417398452759, "time-step": 414}, {"errors": 0.25013959407806396, "time-step": 415}, {"errors": 0.25013744831085205, "time-step": 416}, {"errors": 0.25013530254364014, "time-step": 417}, {"errors": 0.2501331567764282, "time-step": 418}, {"errors": 0.2501310408115387, "time-step": 419}, {"errors": 0.25012892484664917, "time-step": 420}, {"errors": 0.25012677907943726, "time-step": 421}, {"errors": 0.25012463331222534, "time-step": 422}, {"errors": 0.2501225471496582, "time-step": 423}, {"errors": 0.2501203715801239, "time-step": 424}, {"errors": 0.25011831521987915, "time-step": 425}, {"errors": 0.25011613965034485, "time-step": 426}, {"errors": 0.2501140236854553, "time-step": 427}, {"errors": 0.2501119077205658, "time-step": 428}, {"errors": 0.2501097619533539, "time-step": 429}, {"errors": 0.25010764598846436, "time-step": 430}, {"errors": 0.25010550022125244, "time-step": 431}, {"errors": 0.2501034140586853, "time-step": 432}, {"errors": 0.2501012980937958, "time-step": 433}, {"errors": 0.25009921193122864, "time-step": 434}, {"errors": 0.25009703636169434, "time-step": 435}, {"errors": 0.2500949501991272, "time-step": 436}, {"errors": 0.25009286403656006, "time-step": 437}, {"errors": 0.2500907778739929, "time-step": 438}, {"errors": 0.250088632106781, "time-step": 439}, {"errors": 0.2500864863395691, "time-step": 440}, {"errors": 0.25008440017700195, "time-step": 441}, {"errors": 0.2500823140144348, "time-step": 442}, {"errors": 0.2500801980495453, "time-step": 443}, {"errors": 0.25007808208465576, "time-step": 444}, {"errors": 0.25007596611976624, "time-step": 445}, {"errors": 0.2500738501548767, "time-step": 446}, {"errors": 0.2500717341899872, "time-step": 447}, {"errors": 0.25006964802742004, "time-step": 448}, {"errors": 0.2500675320625305, "time-step": 449}, {"errors": 0.2500654458999634, "time-step": 450}, {"errors": 0.25006335973739624, "time-step": 451}, {"errors": 0.2500612437725067, "time-step": 452}, {"errors": 0.2500591576099396, "time-step": 453}, {"errors": 0.25005704164505005, "time-step": 454}, {"errors": 0.2500549554824829, "time-step": 455}, {"errors": 0.25005286931991577, "time-step": 456}, {"errors": 0.25005075335502625, "time-step": 457}, {"errors": 0.2500486671924591, "time-step": 458}, {"errors": 0.2500465512275696, "time-step": 459}, {"errors": 0.25004446506500244, "time-step": 460}, {"errors": 0.2500423789024353, "time-step": 461}, {"errors": 0.2500402629375458, "time-step": 462}, {"errors": 0.25003814697265625, "time-step": 463}, {"errors": 0.2500360608100891, "time-step": 464}, {"errors": 0.2500339448451996, "time-step": 465}, {"errors": 0.25003188848495483, "time-step": 466}, {"errors": 0.2500298023223877, "time-step": 467}, {"errors": 0.25002768635749817, "time-step": 468}, {"errors": 0.25002560019493103, "time-step": 469}, {"errors": 0.2500235140323639, "time-step": 470}, {"errors": 0.25002145767211914, "time-step": 471}, {"errors": 0.2500193417072296, "time-step": 472}, {"errors": 0.2500172555446625, "time-step": 473}, {"errors": 0.25001513957977295, "time-step": 474}, {"errors": 0.2500130534172058, "time-step": 475}, {"errors": 0.25001096725463867, "time-step": 476}, {"errors": 0.25000888109207153, "time-step": 477}, {"errors": 0.2500067353248596, "time-step": 478}, {"errors": 0.25000470876693726, "time-step": 479}, {"errors": 0.25000256299972534, "time-step": 480}, {"errors": 0.2500005066394806, "time-step": 481}, {"errors": 0.24999840557575226, "time-step": 482}, {"errors": 0.24999630451202393, "time-step": 483}, {"errors": 0.2499942034482956, "time-step": 484}, {"errors": 0.24999213218688965, "time-step": 485}, {"errors": 0.2499900460243225, "time-step": 486}, {"errors": 0.24998795986175537, "time-step": 487}, {"errors": 0.24998584389686584, "time-step": 488}, {"errors": 0.2499837577342987, "time-step": 489}, {"errors": 0.24998165667057037, "time-step": 490}, {"errors": 0.24997958540916443, "time-step": 491}, {"errors": 0.24997752904891968, "time-step": 492}, {"errors": 0.24997538328170776, "time-step": 493}, {"errors": 0.24997329711914062, "time-step": 494}, {"errors": 0.24997122585773468, "time-step": 495}, {"errors": 0.24996912479400635, "time-step": 496}, {"errors": 0.24996700882911682, "time-step": 497}, {"errors": 0.24996493756771088, "time-step": 498}, {"errors": 0.24996282160282135, "time-step": 499}, {"errors": 0.24996072053909302, "time-step": 500}, {"errors": 0.24995863437652588, "time-step": 501}, {"errors": 0.24995654821395874, "time-step": 502}, {"errors": 0.2499544471502304, "time-step": 503}, {"errors": 0.24995234608650208, "time-step": 504}, {"errors": 0.24995025992393494, "time-step": 505}, {"errors": 0.2499481588602066, "time-step": 506}, {"errors": 0.24994607269763947, "time-step": 507}, {"errors": 0.24994395673274994, "time-step": 508}, {"errors": 0.2499418556690216, "time-step": 509}, {"errors": 0.24993973970413208, "time-step": 510}, {"errors": 0.24993765354156494, "time-step": 511}, {"errors": 0.24993553757667542, "time-step": 512}, {"errors": 0.24993345141410828, "time-step": 513}, {"errors": 0.24993132054805756, "time-step": 514}, {"errors": 0.2499292641878128, "time-step": 515}, {"errors": 0.24992713332176208, "time-step": 516}, {"errors": 0.24992501735687256, "time-step": 517}, {"errors": 0.24992293119430542, "time-step": 518}, {"errors": 0.2499208152294159, "time-step": 519}, {"errors": 0.24991872906684875, "time-step": 520}, {"errors": 0.24991658329963684, "time-step": 521}, {"errors": 0.24991443753242493, "time-step": 522}, {"errors": 0.24991238117218018, "time-step": 523}, {"errors": 0.24991026520729065, "time-step": 524}, {"errors": 0.24990814924240112, "time-step": 525}, {"errors": 0.2499060034751892, "time-step": 526}, {"errors": 0.24990388751029968, "time-step": 527}, {"errors": 0.24990178644657135, "time-step": 528}, {"errors": 0.24989967048168182, "time-step": 529}, {"errors": 0.2498975396156311, "time-step": 530}, {"errors": 0.2498953938484192, "time-step": 531}, {"errors": 0.24989330768585205, "time-step": 532}, {"errors": 0.24989116191864014, "time-step": 533}, {"errors": 0.24988903105258942, "time-step": 534}, {"errors": 0.2498869150876999, "time-step": 535}, {"errors": 0.24988479912281036, "time-step": 536}, {"errors": 0.24988266825675964, "time-step": 537}, {"errors": 0.24988052248954773, "time-step": 538}, {"errors": 0.2498784065246582, "time-step": 539}, {"errors": 0.2498762458562851, "time-step": 540}, {"errors": 0.24987414479255676, "time-step": 541}, {"errors": 0.24987199902534485, "time-step": 542}, {"errors": 0.24986985325813293, "time-step": 543}, {"errors": 0.24986770749092102, "time-step": 544}, {"errors": 0.2498655617237091, "time-step": 545}, {"errors": 0.249863401055336, "time-step": 546}, {"errors": 0.24986127018928528, "time-step": 547}, {"errors": 0.24985912442207336, "time-step": 548}, {"errors": 0.24985696375370026, "time-step": 549}, {"errors": 0.24985483288764954, "time-step": 550}, {"errors": 0.24985262751579285, "time-step": 551}, {"errors": 0.24985051155090332, "time-step": 552}, {"errors": 0.2498483508825302, "time-step": 553}, {"errors": 0.2498461902141571, "time-step": 554}, {"errors": 0.249844029545784, "time-step": 555}, {"errors": 0.24984189867973328, "time-step": 556}, {"errors": 0.2498396933078766, "time-step": 557}, {"errors": 0.24983754754066467, "time-step": 558}, {"errors": 0.24983538687229156, "time-step": 559}, {"errors": 0.24983322620391846, "time-step": 560}, {"errors": 0.24983105063438416, "time-step": 561}, {"errors": 0.24982884526252747, "time-step": 562}, {"errors": 0.24982669949531555, "time-step": 563}, {"errors": 0.24982447922229767, "time-step": 564}, {"errors": 0.24982230365276337, "time-step": 565}, {"errors": 0.24982011318206787, "time-step": 566}, {"errors": 0.24981793761253357, "time-step": 567}, {"errors": 0.24981576204299927, "time-step": 568}, {"errors": 0.24981357157230377, "time-step": 569}, {"errors": 0.2498113512992859, "time-step": 570}, {"errors": 0.2498091757297516, "time-step": 571}, {"errors": 0.2498069703578949, "time-step": 572}, {"errors": 0.24980475008487701, "time-step": 573}, {"errors": 0.2498025745153427, "time-step": 574}, {"errors": 0.24980035424232483, "time-step": 575}, {"errors": 0.24979813396930695, "time-step": 576}, {"errors": 0.24979591369628906, "time-step": 577}, {"errors": 0.24979370832443237, "time-step": 578}, {"errors": 0.24979150295257568, "time-step": 579}, {"errors": 0.24978932738304138, "time-step": 580}, {"errors": 0.24978704750537872, "time-step": 581}, {"errors": 0.24978482723236084, "time-step": 582}, {"errors": 0.24978257715702057, "time-step": 583}, {"errors": 0.24978035688400269, "time-step": 584}, {"errors": 0.2497781217098236, "time-step": 585}, {"errors": 0.24977585673332214, "time-step": 586}, {"errors": 0.24977363646030426, "time-step": 587}, {"errors": 0.24977141618728638, "time-step": 588}, {"errors": 0.2497691512107849, "time-step": 589}, {"errors": 0.24976690113544464, "time-step": 590}, {"errors": 0.24976462125778198, "time-step": 591}, {"errors": 0.2497624009847641, "time-step": 592}, {"errors": 0.24976012110710144, "time-step": 593}, {"errors": 0.24975785613059998, "time-step": 594}, {"errors": 0.24975557625293732, "time-step": 595}, {"errors": 0.24975329637527466, "time-step": 596}, {"errors": 0.2497510313987732, "time-step": 597}, {"errors": 0.24974876642227173, "time-step": 598}, {"errors": 0.24974647164344788, "time-step": 599}, {"errors": 0.24974416196346283, "time-step": 600}, {"errors": 0.24974188208580017, "time-step": 601}, {"errors": 0.2497396022081375, "time-step": 602}, {"errors": 0.24973729252815247, "time-step": 603}, {"errors": 0.2497350126504898, "time-step": 604}, {"errors": 0.24973271787166595, "time-step": 605}, {"errors": 0.24973037838935852, "time-step": 606}, {"errors": 0.24972809851169586, "time-step": 607}, {"errors": 0.24972578883171082, "time-step": 608}, {"errors": 0.2497234344482422, "time-step": 609}, {"errors": 0.24972113966941833, "time-step": 610}, {"errors": 0.2497187852859497, "time-step": 611}, {"errors": 0.24971644580364227, "time-step": 612}, {"errors": 0.24971413612365723, "time-step": 613}, {"errors": 0.2497117966413498, "time-step": 614}, {"errors": 0.24970944225788116, "time-step": 615}, {"errors": 0.24970711767673492, "time-step": 616}, {"errors": 0.24970471858978271, "time-step": 617}, {"errors": 0.2497023642063141, "time-step": 618}, {"errors": 0.24969999492168427, "time-step": 619}, {"errors": 0.24969764053821564, "time-step": 620}, {"errors": 0.24969527125358582, "time-step": 621}, {"errors": 0.2496929168701172, "time-step": 622}, {"errors": 0.24969050288200378, "time-step": 623}, {"errors": 0.24968814849853516, "time-step": 624}, {"errors": 0.24968573451042175, "time-step": 625}, {"errors": 0.24968333542346954, "time-step": 626}, {"errors": 0.24968093633651733, "time-step": 627}, {"errors": 0.24967852234840393, "time-step": 628}, {"errors": 0.24967613816261292, "time-step": 629}, {"errors": 0.24967369437217712, "time-step": 630}, {"errors": 0.24967128038406372, "time-step": 631}, {"errors": 0.2496688812971115, "time-step": 632}, {"errors": 0.24966643750667572, "time-step": 633}, {"errors": 0.24966400861740112, "time-step": 634}, {"errors": 0.24966156482696533, "time-step": 635}, {"errors": 0.24965910613536835, "time-step": 636}, {"errors": 0.24965664744377136, "time-step": 637}, {"errors": 0.24965423345565796, "time-step": 638}, {"errors": 0.2496517151594162, "time-step": 639}, {"errors": 0.2496492564678192, "time-step": 640}, {"errors": 0.24964678287506104, "time-step": 641}, {"errors": 0.24964432418346405, "time-step": 642}, {"errors": 0.24964183568954468, "time-step": 643}, {"errors": 0.2496393620967865, "time-step": 644}, {"errors": 0.24963685870170593, "time-step": 645}, {"errors": 0.24963434040546417, "time-step": 646}, {"errors": 0.2496318221092224, "time-step": 647}, {"errors": 0.24962933361530304, "time-step": 648}, {"errors": 0.24962680041790009, "time-step": 649}, {"errors": 0.24962428212165833, "time-step": 650}, {"errors": 0.24962174892425537, "time-step": 651}, {"errors": 0.24961921572685242, "time-step": 652}, {"errors": 0.24961668252944946, "time-step": 653}, {"errors": 0.24961411952972412, "time-step": 654}, {"errors": 0.24961155652999878, "time-step": 655}, {"errors": 0.24960899353027344, "time-step": 656}, {"errors": 0.2496064305305481, "time-step": 657}, {"errors": 0.24960388243198395, "time-step": 658}, {"errors": 0.24960128962993622, "time-step": 659}, {"errors": 0.2495986968278885, "time-step": 660}, {"errors": 0.24959608912467957, "time-step": 661}, {"errors": 0.24959349632263184, "time-step": 662}, {"errors": 0.24959087371826172, "time-step": 663}, {"errors": 0.249588280916214, "time-step": 664}, {"errors": 0.24958565831184387, "time-step": 665}, {"errors": 0.24958303570747375, "time-step": 666}, {"errors": 0.24958038330078125, "time-step": 667}, {"errors": 0.24957773089408875, "time-step": 668}, {"errors": 0.24957510828971863, "time-step": 669}, {"errors": 0.24957245588302612, "time-step": 670}, {"errors": 0.24956975877285004, "time-step": 671}, {"errors": 0.24956709146499634, "time-step": 672}, {"errors": 0.24956437945365906, "time-step": 673}, {"errors": 0.24956174194812775, "time-step": 674}, {"errors": 0.24955904483795166, "time-step": 675}, {"errors": 0.24955633282661438, "time-step": 676}, {"errors": 0.2495535910129547, "time-step": 677}, {"errors": 0.24955090880393982, "time-step": 678}, {"errors": 0.24954819679260254, "time-step": 679}, {"errors": 0.24954545497894287, "time-step": 680}, {"errors": 0.2495427131652832, "time-step": 681}, {"errors": 0.24953997135162354, "time-step": 682}, {"errors": 0.24953719973564148, "time-step": 683}, {"errors": 0.24953442811965942, "time-step": 684}, {"errors": 0.24953162670135498, "time-step": 685}, {"errors": 0.2495288997888565, "time-step": 686}, {"errors": 0.24952606856822968, "time-step": 687}, {"errors": 0.24952328205108643, "time-step": 688}, {"errors": 0.24952048063278198, "time-step": 689}, {"errors": 0.24951766431331635, "time-step": 690}, {"errors": 0.24951481819152832, "time-step": 691}, {"errors": 0.24951200187206268, "time-step": 692}, {"errors": 0.24950915575027466, "time-step": 693}, {"errors": 0.24950629472732544, "time-step": 694}, {"errors": 0.2495034635066986, "time-step": 695}, {"errors": 0.24950061738491058, "time-step": 696}, {"errors": 0.24949771165847778, "time-step": 697}, {"errors": 0.24949485063552856, "time-step": 698}, {"errors": 0.24949195981025696, "time-step": 699}, {"errors": 0.24948900938034058, "time-step": 700}, {"errors": 0.24948614835739136, "time-step": 701}, {"errors": 0.2494831681251526, "time-step": 702}, {"errors": 0.2494802474975586, "time-step": 703}, {"errors": 0.2494773119688034, "time-step": 704}, {"errors": 0.24947437644004822, "time-step": 705}, {"errors": 0.24947142601013184, "time-step": 706}, {"errors": 0.24946844577789307, "time-step": 707}, {"errors": 0.2494654506444931, "time-step": 708}, {"errors": 0.24946242570877075, "time-step": 709}, {"errors": 0.24945944547653198, "time-step": 710}, {"errors": 0.24945645034313202, "time-step": 711}, {"errors": 0.24945339560508728, "time-step": 712}, {"errors": 0.24945038557052612, "time-step": 713}, {"errors": 0.24944734573364258, "time-step": 714}, {"errors": 0.24944427609443665, "time-step": 715}, {"errors": 0.2494412511587143, "time-step": 716}, {"errors": 0.24943816661834717, "time-step": 717}, {"errors": 0.24943503737449646, "time-step": 718}, {"errors": 0.24943196773529053, "time-step": 719}, {"errors": 0.24942883849143982, "time-step": 720}, {"errors": 0.2494257688522339, "time-step": 721}, {"errors": 0.2494226098060608, "time-step": 722}, {"errors": 0.24941948056221008, "time-step": 723}, {"errors": 0.249416321516037, "time-step": 724}, {"errors": 0.2494131624698639, "time-step": 725}, {"errors": 0.2494100034236908, "time-step": 726}, {"errors": 0.2494068145751953, "time-step": 727}, {"errors": 0.24940362572669983, "time-step": 728}, {"errors": 0.24940040707588196, "time-step": 729}, {"errors": 0.2493971884250641, "time-step": 730}, {"errors": 0.24939393997192383, "time-step": 731}, {"errors": 0.24939069151878357, "time-step": 732}, {"errors": 0.2493874728679657, "time-step": 733}, {"errors": 0.24938414990901947, "time-step": 734}, {"errors": 0.24938088655471802, "time-step": 735}, {"errors": 0.24937760829925537, "time-step": 736}, {"errors": 0.24937430024147034, "time-step": 737}, {"errors": 0.24937096238136292, "time-step": 738}, {"errors": 0.24936765432357788, "time-step": 739}, {"errors": 0.24936430156230927, "time-step": 740}, {"errors": 0.24936093389987946, "time-step": 741}, {"errors": 0.24935756623744965, "time-step": 742}, {"errors": 0.24935418367385864, "time-step": 743}, {"errors": 0.24935080111026764, "time-step": 744}, {"errors": 0.24934738874435425, "time-step": 745}, {"errors": 0.24934397637844086, "time-step": 746}, {"errors": 0.24934053421020508, "time-step": 747}, {"errors": 0.2493370622396469, "time-step": 748}, {"errors": 0.24933362007141113, "time-step": 749}, {"errors": 0.24933016300201416, "time-step": 750}, {"errors": 0.2493266463279724, "time-step": 751}, {"errors": 0.24932312965393066, "time-step": 752}, {"errors": 0.24931961297988892, "time-step": 753}, {"errors": 0.24931609630584717, "time-step": 754}, {"errors": 0.24931253492832184, "time-step": 755}, {"errors": 0.2493089884519577, "time-step": 756}, {"errors": 0.24930541217327118, "time-step": 757}, {"errors": 0.24930180609226227, "time-step": 758}, {"errors": 0.24929822981357574, "time-step": 759}, {"errors": 0.24929456412792206, "time-step": 760}, {"errors": 0.24929094314575195, "time-step": 761}, {"errors": 0.24928730726242065, "time-step": 762}, {"errors": 0.24928361177444458, "time-step": 763}, {"errors": 0.2492799609899521, "time-step": 764}, {"errors": 0.2492762804031372, "time-step": 765}, {"errors": 0.24927255511283875, "time-step": 766}, {"errors": 0.24926882982254028, "time-step": 767}, {"errors": 0.24926507472991943, "time-step": 768}, {"errors": 0.24926131963729858, "time-step": 769}, {"errors": 0.24925756454467773, "time-step": 770}, {"errors": 0.2492537498474121, "time-step": 771}, {"errors": 0.24924993515014648, "time-step": 772}, {"errors": 0.24924612045288086, "time-step": 773}, {"errors": 0.24924229085445404, "time-step": 774}, {"errors": 0.24923840165138245, "time-step": 775}, {"errors": 0.24923452734947205, "time-step": 776}, {"errors": 0.24923068284988403, "time-step": 777}, {"errors": 0.24922676384449005, "time-step": 778}, {"errors": 0.24922284483909607, "time-step": 779}, {"errors": 0.2492188811302185, "time-step": 780}, {"errors": 0.24921491742134094, "time-step": 781}, {"errors": 0.249210923910141, "time-step": 782}, {"errors": 0.24920694530010223, "time-step": 783}, {"errors": 0.2492029368877411, "time-step": 784}, {"errors": 0.24919889867305756, "time-step": 785}, {"errors": 0.24919486045837402, "time-step": 786}, {"errors": 0.2491908073425293, "time-step": 787}, {"errors": 0.24918672442436218, "time-step": 788}, {"errors": 0.24918261170387268, "time-step": 789}, {"errors": 0.2491784691810608, "time-step": 790}, {"errors": 0.2491743564605713, "time-step": 791}, {"errors": 0.2491702139377594, "time-step": 792}, {"errors": 0.24916604161262512, "time-step": 793}, {"errors": 0.24916180968284607, "time-step": 794}, {"errors": 0.2491575926542282, "time-step": 795}, {"errors": 0.24915337562561035, "time-step": 796}, {"errors": 0.2491491138935089, "time-step": 797}, {"errors": 0.24914482235908508, "time-step": 798}, {"errors": 0.24914056062698364, "time-step": 799}, {"errors": 0.24913623929023743, "time-step": 800}, {"errors": 0.24913187325000763, "time-step": 801}, {"errors": 0.24912753701210022, "time-step": 802}, {"errors": 0.24912315607070923, "time-step": 803}, {"errors": 0.24911876022815704, "time-step": 804}, {"errors": 0.24911433458328247, "time-step": 805}, {"errors": 0.2491099238395691, "time-step": 806}, {"errors": 0.24910546839237213, "time-step": 807}, {"errors": 0.24910098314285278, "time-step": 808}, {"errors": 0.24909648299217224, "time-step": 809}, {"errors": 0.2490919530391693, "time-step": 810}, {"errors": 0.24908742308616638, "time-step": 811}, {"errors": 0.24908286333084106, "time-step": 812}, {"errors": 0.24907825887203217, "time-step": 813}, {"errors": 0.24907363951206207, "time-step": 814}, {"errors": 0.24906903505325317, "time-step": 815}, {"errors": 0.2490643560886383, "time-step": 816}, {"errors": 0.24905972182750702, "time-step": 817}, {"errors": 0.24905499815940857, "time-step": 818}, {"errors": 0.24905025959014893, "time-step": 819}, {"errors": 0.2490454912185669, "time-step": 820}, {"errors": 0.24904072284698486, "time-step": 821}, {"errors": 0.24903595447540283, "time-step": 822}, {"errors": 0.24903114140033722, "time-step": 823}, {"errors": 0.2490263283252716, "time-step": 824}, {"errors": 0.24902141094207764, "time-step": 825}, {"errors": 0.24901658296585083, "time-step": 826}, {"errors": 0.24901165068149567, "time-step": 827}, {"errors": 0.2490067034959793, "time-step": 828}, {"errors": 0.24900174140930176, "time-step": 829}, {"errors": 0.248996764421463, "time-step": 830}, {"errors": 0.2489917278289795, "time-step": 831}, {"errors": 0.24898675084114075, "time-step": 832}, {"errors": 0.24898168444633484, "time-step": 833}, {"errors": 0.24897657334804535, "time-step": 834}, {"errors": 0.24897149205207825, "time-step": 835}, {"errors": 0.24896636605262756, "time-step": 836}, {"errors": 0.24896115064620972, "time-step": 837}, {"errors": 0.24895596504211426, "time-step": 838}, {"errors": 0.24895079433918, "time-step": 839}, {"errors": 0.2489454746246338, "time-step": 840}, {"errors": 0.24894025921821594, "time-step": 841}, {"errors": 0.24893493950366974, "time-step": 842}, {"errors": 0.24892961978912354, "time-step": 843}, {"errors": 0.24892428517341614, "time-step": 844}, {"errors": 0.24891889095306396, "time-step": 845}, {"errors": 0.2489134967327118, "time-step": 846}, {"errors": 0.24890802800655365, "time-step": 847}, {"errors": 0.24890261888504028, "time-step": 848}, {"errors": 0.24889713525772095, "time-step": 849}, {"errors": 0.24889157712459564, "time-step": 850}, {"errors": 0.24888604879379272, "time-step": 851}, {"errors": 0.24888047575950623, "time-step": 852}, {"errors": 0.24887485802173615, "time-step": 853}, {"errors": 0.24886924028396606, "time-step": 854}, {"errors": 0.2488635778427124, "time-step": 855}, {"errors": 0.24885788559913635, "time-step": 856}, {"errors": 0.24885214865207672, "time-step": 857}, {"errors": 0.2488463968038559, "time-step": 858}, {"errors": 0.2488406002521515, "time-step": 859}, {"errors": 0.24883480370044708, "time-step": 860}, {"errors": 0.2488289475440979, "time-step": 861}, {"errors": 0.24882309138774872, "time-step": 862}, {"errors": 0.24881717562675476, "time-step": 863}, {"errors": 0.24881121516227722, "time-step": 864}, {"errors": 0.24880526959896088, "time-step": 865}, {"errors": 0.24879926443099976, "time-step": 866}, {"errors": 0.24879321455955505, "time-step": 867}, {"errors": 0.24878714978694916, "time-step": 868}, {"errors": 0.24878104031085968, "time-step": 869}, {"errors": 0.2487749457359314, "time-step": 870}, {"errors": 0.24876874685287476, "time-step": 871}, {"errors": 0.24876254796981812, "time-step": 872}, {"errors": 0.2487563192844391, "time-step": 873}, {"errors": 0.24875007569789886, "time-step": 874}, {"errors": 0.24874375760555267, "time-step": 875}, {"errors": 0.24873745441436768, "time-step": 876}, {"errors": 0.2487310767173767, "time-step": 877}, {"errors": 0.24872466921806335, "time-step": 878}, {"errors": 0.2487182319164276, "time-step": 879}, {"errors": 0.24871176481246948, "time-step": 880}, {"errors": 0.24870526790618896, "time-step": 881}, {"errors": 0.24869871139526367, "time-step": 882}, {"errors": 0.24869213998317719, "time-step": 883}, {"errors": 0.24868552386760712, "time-step": 884}, {"errors": 0.24867889285087585, "time-step": 885}, {"errors": 0.24867217242717743, "time-step": 886}, {"errors": 0.24866542220115662, "time-step": 887}, {"errors": 0.248658686876297, "time-step": 888}, {"errors": 0.2486519068479538, "time-step": 889}, {"errors": 0.24864503741264343, "time-step": 890}, {"errors": 0.24863819777965546, "time-step": 891}, {"errors": 0.24863125383853912, "time-step": 892}, {"errors": 0.24862432479858398, "time-step": 893}, {"errors": 0.24861735105514526, "time-step": 894}, {"errors": 0.24861031770706177, "time-step": 895}, {"errors": 0.2486032098531723, "time-step": 896}, {"errors": 0.24859611690044403, "time-step": 897}, {"errors": 0.24858897924423218, "time-step": 898}, {"errors": 0.24858178198337555, "time-step": 899}, {"errors": 0.24857455492019653, "time-step": 900}, {"errors": 0.24856728315353394, "time-step": 901}, {"errors": 0.24855995178222656, "time-step": 902}, {"errors": 0.24855265021324158, "time-step": 903}, {"errors": 0.24854522943496704, "time-step": 904}, {"errors": 0.2485378086566925, "time-step": 905}, {"errors": 0.2485303431749344, "time-step": 906}, {"errors": 0.2485228180885315, "time-step": 907}, {"errors": 0.2485153079032898, "time-step": 908}, {"errors": 0.24850764870643616, "time-step": 909}, {"errors": 0.2485000491142273, "time-step": 910}, {"errors": 0.24849236011505127, "time-step": 911}, {"errors": 0.24848461151123047, "time-step": 912}, {"errors": 0.2484768182039261, "time-step": 913}, {"errors": 0.2484690099954605, "time-step": 914}, {"errors": 0.24846117198467255, "time-step": 915}, {"errors": 0.24845324456691742, "time-step": 916}, {"errors": 0.2484452724456787, "time-step": 917}, {"errors": 0.24843725562095642, "time-step": 918}, {"errors": 0.24842923879623413, "time-step": 919}, {"errors": 0.24842113256454468, "time-step": 920}, {"errors": 0.24841301143169403, "time-step": 921}, {"errors": 0.2484048455953598, "time-step": 922}, {"errors": 0.2483965903520584, "time-step": 923}, {"errors": 0.2483883500099182, "time-step": 924}, {"errors": 0.24837994575500488, "time-step": 925}, {"errors": 0.24837160110473633, "time-step": 926}, {"errors": 0.2483631670475006, "time-step": 927}, {"errors": 0.2483547329902649, "time-step": 928}, {"errors": 0.24834617972373962, "time-step": 929}, {"errors": 0.24833764135837555, "time-step": 930}, {"errors": 0.24832899868488312, "time-step": 931}, {"errors": 0.2483203262090683, "time-step": 932}, {"errors": 0.24831163883209229, "time-step": 933}, {"errors": 0.24830284714698792, "time-step": 934}, {"errors": 0.24829401075839996, "time-step": 935}, {"errors": 0.24828511476516724, "time-step": 936}, {"errors": 0.2482762187719345, "time-step": 937}, {"errors": 0.2482672482728958, "time-step": 938}, {"errors": 0.24825820326805115, "time-step": 939}, {"errors": 0.2482491433620453, "time-step": 940}, {"errors": 0.24823999404907227, "time-step": 941}, {"errors": 0.24823081493377686, "time-step": 942}, {"errors": 0.24822157621383667, "time-step": 943}, {"errors": 0.24821226298809052, "time-step": 944}, {"errors": 0.24820289015769958, "time-step": 945}, {"errors": 0.24819353222846985, "time-step": 946}, {"errors": 0.24818405508995056, "time-step": 947}, {"errors": 0.2481745481491089, "time-step": 948}, {"errors": 0.24816498160362244, "time-step": 949}, {"errors": 0.24815532565116882, "time-step": 950}, {"errors": 0.2481456995010376, "time-step": 951}, {"errors": 0.24813593924045563, "time-step": 952}, {"errors": 0.24812613427639008, "time-step": 953}, {"errors": 0.24811625480651855, "time-step": 954}, {"errors": 0.24810634553432465, "time-step": 955}, {"errors": 0.24809636175632477, "time-step": 956}, {"errors": 0.24808631837368011, "time-step": 957}, {"errors": 0.24807626008987427, "time-step": 958}, {"errors": 0.24806606769561768, "time-step": 959}, {"errors": 0.2480558454990387, "time-step": 960}, {"errors": 0.24804560840129852, "time-step": 961}, {"errors": 0.2480352520942688, "time-step": 962}, {"errors": 0.2480248510837555, "time-step": 963}, {"errors": 0.2480143904685974, "time-step": 964}, {"errors": 0.24800390005111694, "time-step": 965}, {"errors": 0.24799329042434692, "time-step": 966}, {"errors": 0.24798265099525452, "time-step": 967}, {"errors": 0.24797195196151733, "time-step": 968}, {"errors": 0.24796119332313538, "time-step": 969}, {"errors": 0.24795034527778625, "time-step": 970}, {"errors": 0.24793943762779236, "time-step": 971}, {"errors": 0.2479284703731537, "time-step": 972}, {"errors": 0.24791741371154785, "time-step": 973}, {"errors": 0.24790632724761963, "time-step": 974}, {"errors": 0.24789516627788544, "time-step": 975}, {"errors": 0.24788391590118408, "time-step": 976}, {"errors": 0.24787262082099915, "time-step": 977}, {"errors": 0.24786126613616943, "time-step": 978}, {"errors": 0.24784982204437256, "time-step": 979}, {"errors": 0.2478383183479309, "time-step": 980}, {"errors": 0.2478267401456833, "time-step": 981}, {"errors": 0.2478151023387909, "time-step": 982}, {"errors": 0.24780340492725372, "time-step": 983}, {"errors": 0.24779163300991058, "time-step": 984}, {"errors": 0.2477797567844391, "time-step": 985}, {"errors": 0.24776782095432281, "time-step": 986}, {"errors": 0.24775584042072296, "time-step": 987}, {"errors": 0.24774375557899475, "time-step": 988}, {"errors": 0.24773159623146057, "time-step": 989}, {"errors": 0.24771936237812042, "time-step": 990}, {"errors": 0.24770712852478027, "time-step": 991}, {"errors": 0.24769476056098938, "time-step": 992}, {"errors": 0.24768228828907013, "time-step": 993}, {"errors": 0.2476697862148285, "time-step": 994}, {"errors": 0.2476571798324585, "time-step": 995}, {"errors": 0.24764452874660492, "time-step": 996}, {"errors": 0.24763178825378418, "time-step": 997}, {"errors": 0.24761895835399628, "time-step": 998}, {"errors": 0.2476060688495636, "time-step": 999}, {"errors": 0.24759310483932495, "time-step": 1000}, {"errors": 0.24758000671863556, "time-step": 1001}, {"errors": 0.24756687879562378, "time-step": 1002}, {"errors": 0.24755364656448364, "time-step": 1003}, {"errors": 0.24754035472869873, "time-step": 1004}, {"errors": 0.24752700328826904, "time-step": 1005}, {"errors": 0.2475135326385498, "time-step": 1006}, {"errors": 0.24750003218650818, "time-step": 1007}, {"errors": 0.2474863976240158, "time-step": 1008}, {"errors": 0.24747267365455627, "time-step": 1009}, {"errors": 0.24745890498161316, "time-step": 1010}, {"errors": 0.2474450021982193, "time-step": 1011}, {"errors": 0.24743105471134186, "time-step": 1012}, {"errors": 0.24741701781749725, "time-step": 1013}, {"errors": 0.24740290641784668, "time-step": 1014}, {"errors": 0.24738870561122894, "time-step": 1015}, {"errors": 0.24737438559532166, "time-step": 1016}, {"errors": 0.247359961271286, "time-step": 1017}, {"errors": 0.24734550714492798, "time-step": 1018}, {"errors": 0.2473309487104416, "time-step": 1019}, {"errors": 0.24731628596782684, "time-step": 1020}, {"errors": 0.24730157852172852, "time-step": 1021}, {"errors": 0.24728675186634064, "time-step": 1022}, {"errors": 0.2472718060016632, "time-step": 1023}, {"errors": 0.2472568154335022, "time-step": 1024}, {"errors": 0.24724167585372925, "time-step": 1025}, {"errors": 0.24722647666931152, "time-step": 1026}, {"errors": 0.24721118807792664, "time-step": 1027}, {"errors": 0.24719582498073578, "time-step": 1028}, {"errors": 0.24718035757541656, "time-step": 1029}, {"errors": 0.24716481566429138, "time-step": 1030}, {"errors": 0.24714909493923187, "time-step": 1031}, {"errors": 0.24713334441184998, "time-step": 1032}, {"errors": 0.24711748957633972, "time-step": 1033}, {"errors": 0.24710150063037872, "time-step": 1034}, {"errors": 0.24708545207977295, "time-step": 1035}, {"errors": 0.2470693290233612, "time-step": 1036}, {"errors": 0.24705305695533752, "time-step": 1037}, {"errors": 0.24703672528266907, "time-step": 1038}, {"errors": 0.24702025949954987, "time-step": 1039}, {"errors": 0.2470037341117859, "time-step": 1040}, {"errors": 0.24698705971240997, "time-step": 1041}, {"errors": 0.2469703108072281, "time-step": 1042}, {"errors": 0.24695345759391785, "time-step": 1043}, {"errors": 0.24693650007247925, "time-step": 1044}, {"errors": 0.2469193935394287, "time-step": 1045}, {"errors": 0.2469022572040558, "time-step": 1046}, {"errors": 0.2468850016593933, "time-step": 1047}, {"errors": 0.24686762690544128, "time-step": 1048}, {"errors": 0.2468501180410385, "time-step": 1049}, {"errors": 0.24683253467082977, "time-step": 1050}, {"errors": 0.24681486189365387, "time-step": 1051}, {"errors": 0.24679704010486603, "time-step": 1052}, {"errors": 0.24677912890911102, "time-step": 1053}, {"errors": 0.24676108360290527, "time-step": 1054}, {"errors": 0.24674299359321594, "time-step": 1055}, {"errors": 0.2467247098684311, "time-step": 1056}, {"errors": 0.24670638144016266, "time-step": 1057}, {"errors": 0.2466878890991211, "time-step": 1058}, {"errors": 0.24666933715343475, "time-step": 1059}, {"errors": 0.24665062129497528, "time-step": 1060}, {"errors": 0.24663180112838745, "time-step": 1061}, {"errors": 0.24661284685134888, "time-step": 1062}, {"errors": 0.24659383296966553, "time-step": 1063}, {"errors": 0.24657468497753143, "time-step": 1064}, {"errors": 0.2465553730726242, "time-step": 1065}, {"errors": 0.246535986661911, "time-step": 1066}, {"errors": 0.24651649594306946, "time-step": 1067}, {"errors": 0.24649685621261597, "time-step": 1068}, {"errors": 0.2464771270751953, "time-step": 1069}, {"errors": 0.24645720422267914, "time-step": 1070}, {"errors": 0.24643723666667938, "time-step": 1071}, {"errors": 0.2464171051979065, "time-step": 1072}, {"errors": 0.24639688432216644, "time-step": 1073}, {"errors": 0.24637657403945923, "time-step": 1074}, {"errors": 0.2463560402393341, "time-step": 1075}, {"errors": 0.2463354468345642, "time-step": 1076}, {"errors": 0.24631470441818237, "time-step": 1077}, {"errors": 0.24629387259483337, "time-step": 1078}, {"errors": 0.24627286195755005, "time-step": 1079}, {"errors": 0.24625174701213837, "time-step": 1080}, {"errors": 0.24623048305511475, "time-step": 1081}, {"errors": 0.24620917439460754, "time-step": 1082}, {"errors": 0.24618761241436005, "time-step": 1083}, {"errors": 0.24616603553295135, "time-step": 1084}, {"errors": 0.24614423513412476, "time-step": 1085}, {"errors": 0.246122345328331, "time-step": 1086}, {"errors": 0.24610033631324768, "time-step": 1087}, {"errors": 0.24607819318771362, "time-step": 1088}, {"errors": 0.24605587124824524, "time-step": 1089}, {"errors": 0.2460334599018097, "time-step": 1090}, {"errors": 0.2460108995437622, "time-step": 1091}, {"errors": 0.2459881752729416, "time-step": 1092}, {"errors": 0.24596531689167023, "time-step": 1093}, {"errors": 0.2459423840045929, "time-step": 1094}, {"errors": 0.24591925740242004, "time-step": 1095}, {"errors": 0.24589599668979645, "time-step": 1096}, {"errors": 0.2458726167678833, "time-step": 1097}, {"errors": 0.24584908783435822, "time-step": 1098}, {"errors": 0.2458254098892212, "time-step": 1099}, {"errors": 0.24580159783363342, "time-step": 1100}, {"errors": 0.24577762186527252, "time-step": 1101}, {"errors": 0.24575352668762207, "time-step": 1102}, {"errors": 0.2457292526960373, "time-step": 1103}, {"errors": 0.24570485949516296, "time-step": 1104}, {"errors": 0.2456803172826767, "time-step": 1105}, {"errors": 0.2456556260585785, "time-step": 1106}, {"errors": 0.24563080072402954, "time-step": 1107}, {"errors": 0.24560579657554626, "time-step": 1108}, {"errors": 0.24558065831661224, "time-step": 1109}, {"errors": 0.24555537104606628, "time-step": 1110}, {"errors": 0.24552994966506958, "time-step": 1111}, {"errors": 0.24550434947013855, "time-step": 1112}, {"errors": 0.2454785853624344, "time-step": 1113}, {"errors": 0.24545274674892426, "time-step": 1114}, {"errors": 0.24542666971683502, "time-step": 1115}, {"errors": 0.24540044367313385, "time-step": 1116}, {"errors": 0.24537406861782074, "time-step": 1117}, {"errors": 0.24534755945205688, "time-step": 1118}, {"errors": 0.24532093107700348, "time-step": 1119}, {"errors": 0.24529406428337097, "time-step": 1120}, {"errors": 0.2452670931816101, "time-step": 1121}, {"errors": 0.24523992836475372, "time-step": 1122}, {"errors": 0.2452126145362854, "time-step": 1123}, {"errors": 0.24518516659736633, "time-step": 1124}, {"errors": 0.24515751004219055, "time-step": 1125}, {"errors": 0.24512968957424164, "time-step": 1126}, {"errors": 0.24510174989700317, "time-step": 1127}, {"errors": 0.24507364630699158, "time-step": 1128}, {"errors": 0.24504531919956207, "time-step": 1129}, {"errors": 0.24501684308052063, "time-step": 1130}, {"errors": 0.24498823285102844, "time-step": 1131}, {"errors": 0.24495945870876312, "time-step": 1132}, {"errors": 0.2449304610490799, "time-step": 1133}, {"errors": 0.24490132927894592, "time-step": 1134}, {"errors": 0.24487203359603882, "time-step": 1135}, {"errors": 0.2448425143957138, "time-step": 1136}, {"errors": 0.24481293559074402, "time-step": 1137}, {"errors": 0.24478305876255035, "time-step": 1138}, {"errors": 0.24475306272506714, "time-step": 1139}, {"errors": 0.24472293257713318, "time-step": 1140}, {"errors": 0.24469256401062012, "time-step": 1141}, {"errors": 0.24466204643249512, "time-step": 1142}, {"errors": 0.2446313500404358, "time-step": 1143}, {"errors": 0.24460045993328094, "time-step": 1144}, {"errors": 0.24456945061683655, "time-step": 1145}, {"errors": 0.24453818798065186, "time-step": 1146}, {"errors": 0.24450679123401642, "time-step": 1147}, {"errors": 0.24447515606880188, "time-step": 1148}, {"errors": 0.2444434016942978, "time-step": 1149}, {"errors": 0.2444114089012146, "time-step": 1150}, {"errors": 0.24437928199768066, "time-step": 1151}, {"errors": 0.2443469613790512, "time-step": 1152}, {"errors": 0.24431441724300385, "time-step": 1153}, {"errors": 0.24428170919418335, "time-step": 1154}, {"errors": 0.24424883723258972, "time-step": 1155}, {"errors": 0.24421575665473938, "time-step": 1156}, {"errors": 0.24418248236179352, "time-step": 1157}, {"errors": 0.24414904415607452, "time-step": 1158}, {"errors": 0.24411538243293762, "time-step": 1159}, {"errors": 0.2440815567970276, "time-step": 1160}, {"errors": 0.24404750764369965, "time-step": 1161}, {"errors": 0.24401327967643738, "time-step": 1162}, {"errors": 0.24397888779640198, "time-step": 1163}, {"errors": 0.24394425749778748, "time-step": 1164}, {"errors": 0.24390944838523865, "time-step": 1165}, {"errors": 0.2438744455575943, "time-step": 1166}, {"errors": 0.24383924901485443, "time-step": 1167}, {"errors": 0.24380382895469666, "time-step": 1168}, {"errors": 0.24376824498176575, "time-step": 1169}, {"errors": 0.24373242259025574, "time-step": 1170}, {"errors": 0.2436964213848114, "time-step": 1171}, {"errors": 0.24366021156311035, "time-step": 1172}, {"errors": 0.2436237931251526, "time-step": 1173}, {"errors": 0.2435871958732605, "time-step": 1174}, {"errors": 0.2435503900051117, "time-step": 1175}, {"errors": 0.24351337552070618, "time-step": 1176}, {"errors": 0.24347616732120514, "time-step": 1177}, {"errors": 0.2434387356042862, "time-step": 1178}, {"errors": 0.24340111017227173, "time-step": 1179}, {"errors": 0.24336323142051697, "time-step": 1180}, {"errors": 0.24332518875598907, "time-step": 1181}, {"errors": 0.24328690767288208, "time-step": 1182}, {"errors": 0.24324844777584076, "time-step": 1183}, {"errors": 0.24320976436138153, "time-step": 1184}, {"errors": 0.243170827627182, "time-step": 1185}, {"errors": 0.24313169717788696, "time-step": 1186}, {"errors": 0.2430923581123352, "time-step": 1187}, {"errors": 0.24305281043052673, "time-step": 1188}, {"errors": 0.24301305413246155, "time-step": 1189}, {"errors": 0.24297305941581726, "time-step": 1190}, {"errors": 0.24293287098407745, "time-step": 1191}, {"errors": 0.24289244413375854, "time-step": 1192}, {"errors": 0.24285182356834412, "time-step": 1193}, {"errors": 0.24281097948551178, "time-step": 1194}, {"errors": 0.24276988208293915, "time-step": 1195}, {"errors": 0.242728590965271, "time-step": 1196}, {"errors": 0.24268706142902374, "time-step": 1197}, {"errors": 0.24264532327651978, "time-step": 1198}, {"errors": 0.2426033318042755, "time-step": 1199}, {"errors": 0.24256113171577454, "time-step": 1200}, {"errors": 0.24251872301101685, "time-step": 1201}, {"errors": 0.24247607588768005, "time-step": 1202}, {"errors": 0.24243316054344177, "time-step": 1203}, {"errors": 0.24239006638526917, "time-step": 1204}, {"errors": 0.24234670400619507, "time-step": 1205}, {"errors": 0.24230313301086426, "time-step": 1206}, {"errors": 0.24225932359695435, "time-step": 1207}, {"errors": 0.24221530556678772, "time-step": 1208}, {"errors": 0.24217106401920319, "time-step": 1209}, {"errors": 0.24212650954723358, "time-step": 1210}, {"errors": 0.24208182096481323, "time-step": 1211}, {"errors": 0.24203680455684662, "time-step": 1212}, {"errors": 0.24199160933494568, "time-step": 1213}, {"errors": 0.24194616079330444, "time-step": 1214}, {"errors": 0.2419004589319229, "time-step": 1215}, {"errors": 0.24185451865196228, "time-step": 1216}, {"errors": 0.24180835485458374, "time-step": 1217}, {"errors": 0.2417619377374649, "time-step": 1218}, {"errors": 0.24171529710292816, "time-step": 1219}, {"errors": 0.24166841804981232, "time-step": 1220}, {"errors": 0.2416212558746338, "time-step": 1221}, {"errors": 0.24157385528087616, "time-step": 1222}, {"errors": 0.24152624607086182, "time-step": 1223}, {"errors": 0.24147836863994598, "time-step": 1224}, {"errors": 0.24143026769161224, "time-step": 1225}, {"errors": 0.24138188362121582, "time-step": 1226}, {"errors": 0.2413332462310791, "time-step": 1227}, {"errors": 0.24128440022468567, "time-step": 1228}, {"errors": 0.24123527109622955, "time-step": 1229}, {"errors": 0.24118593335151672, "time-step": 1230}, {"errors": 0.24113628268241882, "time-step": 1231}, {"errors": 0.24108639359474182, "time-step": 1232}, {"errors": 0.2410362958908081, "time-step": 1233}, {"errors": 0.24098588526248932, "time-step": 1234}, {"errors": 0.24093522131443024, "time-step": 1235}, {"errors": 0.24088434875011444, "time-step": 1236}, {"errors": 0.24083319306373596, "time-step": 1237}, {"errors": 0.240781769156456, "time-step": 1238}, {"errors": 0.24073012173175812, "time-step": 1239}, {"errors": 0.24067819118499756, "time-step": 1240}, {"errors": 0.2406259924173355, "time-step": 1241}, {"errors": 0.24057354032993317, "time-step": 1242}, {"errors": 0.24052080512046814, "time-step": 1243}, {"errors": 0.2404678463935852, "time-step": 1244}, {"errors": 0.240414559841156, "time-step": 1245}, {"errors": 0.2403610646724701, "time-step": 1246}, {"errors": 0.2403073012828827, "time-step": 1247}, {"errors": 0.2402532696723938, "time-step": 1248}, {"errors": 0.24019895493984222, "time-step": 1249}, {"errors": 0.24014437198638916, "time-step": 1250}, {"errors": 0.2400895208120346, "time-step": 1251}, {"errors": 0.24003440141677856, "time-step": 1252}, {"errors": 0.23997902870178223, "time-step": 1253}, {"errors": 0.2399234026670456, "time-step": 1254}, {"errors": 0.2398674190044403, "time-step": 1255}, {"errors": 0.23981121182441711, "time-step": 1256}, {"errors": 0.23975473642349243, "time-step": 1257}, {"errors": 0.23969800770282745, "time-step": 1258}, {"errors": 0.2396409809589386, "time-step": 1259}, {"errors": 0.23958364129066467, "time-step": 1260}, {"errors": 0.23952606320381165, "time-step": 1261}, {"errors": 0.23946821689605713, "time-step": 1262}, {"errors": 0.23941007256507874, "time-step": 1263}, {"errors": 0.23935166001319885, "time-step": 1264}, {"errors": 0.2392929494380951, "time-step": 1265}, {"errors": 0.23923397064208984, "time-step": 1266}, {"errors": 0.23917466402053833, "time-step": 1267}, {"errors": 0.2391151487827301, "time-step": 1268}, {"errors": 0.2390553057193756, "time-step": 1269}, {"errors": 0.23899520933628082, "time-step": 1270}, {"errors": 0.23893477022647858, "time-step": 1271}, {"errors": 0.23887406289577484, "time-step": 1272}, {"errors": 0.2388131022453308, "time-step": 1273}, {"errors": 0.2387518435716629, "time-step": 1274}, {"errors": 0.23869025707244873, "time-step": 1275}, {"errors": 0.23862841725349426, "time-step": 1276}, {"errors": 0.2385662943124771, "time-step": 1277}, {"errors": 0.23850387334823608, "time-step": 1278}, {"errors": 0.23844113945960999, "time-step": 1279}, {"errors": 0.2383781373500824, "time-step": 1280}, {"errors": 0.23831482231616974, "time-step": 1281}, {"errors": 0.2382512092590332, "time-step": 1282}, {"errors": 0.23818731307983398, "time-step": 1283}, {"errors": 0.2381231188774109, "time-step": 1284}, {"errors": 0.23805861175060272, "time-step": 1285}, {"errors": 0.23799383640289307, "time-step": 1286}, {"errors": 0.23792873322963715, "time-step": 1287}, {"errors": 0.23786333203315735, "time-step": 1288}, {"errors": 0.23779764771461487, "time-step": 1289}, {"errors": 0.2377316653728485, "time-step": 1290}, {"errors": 0.2376653552055359, "time-step": 1291}, {"errors": 0.2375987470149994, "time-step": 1292}, {"errors": 0.2375318557024002, "time-step": 1293}, {"errors": 0.23746465146541595, "time-step": 1294}, {"errors": 0.23739713430404663, "time-step": 1295}, {"errors": 0.23732930421829224, "time-step": 1296}, {"errors": 0.23726116120815277, "time-step": 1297}, {"errors": 0.23719273507595062, "time-step": 1298}, {"errors": 0.2371239960193634, "time-step": 1299}, {"errors": 0.2370549440383911, "time-step": 1300}, {"errors": 0.23698556423187256, "time-step": 1301}, {"errors": 0.23691591620445251, "time-step": 1302}, {"errors": 0.236845925450325, "time-step": 1303}, {"errors": 0.23677562177181244, "time-step": 1304}, {"errors": 0.2367049902677536, "time-step": 1305}, {"errors": 0.23663409054279327, "time-step": 1306}, {"errors": 0.2365628182888031, "time-step": 1307}, {"errors": 0.23649129271507263, "time-step": 1308}, {"errors": 0.23641939461231232, "time-step": 1309}, {"errors": 0.23634721338748932, "time-step": 1310}, {"errors": 0.23627468943595886, "time-step": 1311}, {"errors": 0.23620185256004333, "time-step": 1312}, {"errors": 0.23612870275974274, "time-step": 1313}, {"errors": 0.23605524003505707, "time-step": 1314}, {"errors": 0.23598144948482513, "time-step": 1315}, {"errors": 0.23590734601020813, "time-step": 1316}, {"errors": 0.2358328402042389, "time-step": 1317}, {"errors": 0.23575809597969055, "time-step": 1318}, {"errors": 0.23568303883075714, "time-step": 1319}, {"errors": 0.23560762405395508, "time-step": 1320}, {"errors": 0.23553188145160675, "time-step": 1321}, {"errors": 0.23545582592487335, "time-step": 1322}, {"errors": 0.2353794127702713, "time-step": 1323}, {"errors": 0.23530268669128418, "time-step": 1324}, {"errors": 0.235225647687912, "time-step": 1325}, {"errors": 0.23514828085899353, "time-step": 1326}, {"errors": 0.23507052659988403, "time-step": 1327}, {"errors": 0.23499250411987305, "time-step": 1328}, {"errors": 0.23491410911083221, "time-step": 1329}, {"errors": 0.2348354458808899, "time-step": 1330}, {"errors": 0.23475638031959534, "time-step": 1331}, {"errors": 0.2346770018339157, "time-step": 1332}, {"errors": 0.23459729552268982, "time-step": 1333}, {"errors": 0.23451724648475647, "time-step": 1334}, {"errors": 0.23443686962127686, "time-step": 1335}, {"errors": 0.2343561351299286, "time-step": 1336}, {"errors": 0.23427508771419525, "time-step": 1337}, {"errors": 0.23419366776943207, "time-step": 1338}, {"errors": 0.2341119349002838, "time-step": 1339}, {"errors": 0.2340298742055893, "time-step": 1340}, {"errors": 0.23394744098186493, "time-step": 1341}, {"errors": 0.2338646799325943, "time-step": 1342}, {"errors": 0.23378154635429382, "time-step": 1343}, {"errors": 0.23369809985160828, "time-step": 1344}, {"errors": 0.23361429572105408, "time-step": 1345}, {"errors": 0.233530193567276, "time-step": 1346}, {"errors": 0.23344570398330688, "time-step": 1347}, {"errors": 0.2333608716726303, "time-step": 1348}, {"errors": 0.23327571153640747, "time-step": 1349}, {"errors": 0.23319017887115479, "time-step": 1350}, {"errors": 0.23310430347919464, "time-step": 1351}, {"errors": 0.23301810026168823, "time-step": 1352}, {"errors": 0.23293150961399078, "time-step": 1353}, {"errors": 0.23284459114074707, "time-step": 1354}, {"errors": 0.23275728523731232, "time-step": 1355}, {"errors": 0.2326696664094925, "time-step": 1356}, {"errors": 0.2325817197561264, "time-step": 1357}, {"errors": 0.23249338567256927, "time-step": 1358}, {"errors": 0.2324046939611435, "time-step": 1359}, {"errors": 0.23231567442417145, "time-step": 1360}, {"errors": 0.23222626745700836, "time-step": 1361}, {"errors": 0.23213651776313782, "time-step": 1362}, {"errors": 0.23204641044139862, "time-step": 1363}, {"errors": 0.23195596039295197, "time-step": 1364}, {"errors": 0.23186513781547546, "time-step": 1365}, {"errors": 0.2317739725112915, "time-step": 1366}, {"errors": 0.23168238997459412, "time-step": 1367}, {"errors": 0.23159050941467285, "time-step": 1368}, {"errors": 0.23149825632572174, "time-step": 1369}, {"errors": 0.23140566051006317, "time-step": 1370}, {"errors": 0.23131267726421356, "time-step": 1371}, {"errors": 0.2312193214893341, "time-step": 1372}, {"errors": 0.231125608086586, "time-step": 1373}, {"errors": 0.23103155195713043, "time-step": 1374}, {"errors": 0.23093712329864502, "time-step": 1375}, {"errors": 0.23084232211112976, "time-step": 1376}, {"errors": 0.23074716329574585, "time-step": 1377}, {"errors": 0.2306516468524933, "time-step": 1378}, {"errors": 0.2305557280778885, "time-step": 1379}, {"errors": 0.23045946657657623, "time-step": 1380}, {"errors": 0.23036286234855652, "time-step": 1381}, {"errors": 0.23026582598686218, "time-step": 1382}, {"errors": 0.23016849160194397, "time-step": 1383}, {"errors": 0.23007075488567352, "time-step": 1384}, {"errors": 0.22997267544269562, "time-step": 1385}, {"errors": 0.22987417876720428, "time-step": 1386}, {"errors": 0.2297753244638443, "time-step": 1387}, {"errors": 0.22967611253261566, "time-step": 1388}, {"errors": 0.22957652807235718, "time-step": 1389}, {"errors": 0.22947655618190765, "time-step": 1390}, {"errors": 0.2293761968612671, "time-step": 1391}, {"errors": 0.22927550971508026, "time-step": 1392}, {"errors": 0.2291744351387024, "time-step": 1393}, {"errors": 0.22907298803329468, "time-step": 1394}, {"errors": 0.22897115349769592, "time-step": 1395}, {"errors": 0.22886893153190613, "time-step": 1396}, {"errors": 0.22876635193824768, "time-step": 1397}, {"errors": 0.2286633551120758, "time-step": 1398}, {"errors": 0.22856006026268005, "time-step": 1399}, {"errors": 0.22845634818077087, "time-step": 1400}, {"errors": 0.22835221886634827, "time-step": 1401}, {"errors": 0.2282477617263794, "time-step": 1402}, {"errors": 0.22814291715621948, "time-step": 1403}, {"errors": 0.22803767025470734, "time-step": 1404}, {"errors": 0.22793208062648773, "time-step": 1405}, {"errors": 0.2278260886669159, "time-step": 1406}, {"errors": 0.2277197241783142, "time-step": 1407}, {"errors": 0.22761297225952148, "time-step": 1408}, {"errors": 0.22750583291053772, "time-step": 1409}, {"errors": 0.22739830613136292, "time-step": 1410}, {"errors": 0.22729040682315826, "time-step": 1411}, {"errors": 0.22718209028244019, "time-step": 1412}, {"errors": 0.22707343101501465, "time-step": 1413}, {"errors": 0.22696441411972046, "time-step": 1414}, {"errors": 0.22685495018959045, "time-step": 1415}, {"errors": 0.2267451286315918, "time-step": 1416}, {"errors": 0.2266349196434021, "time-step": 1417}, {"errors": 0.22652432322502136, "time-step": 1418}, {"errors": 0.22641333937644958, "time-step": 1419}, {"errors": 0.22630199790000916, "time-step": 1420}, {"errors": 0.2261902540922165, "time-step": 1421}, {"errors": 0.22607813775539398, "time-step": 1422}, {"errors": 0.22596555948257446, "time-step": 1423}, {"errors": 0.22585265338420868, "time-step": 1424}, {"errors": 0.22573935985565186, "time-step": 1425}, {"errors": 0.22562569379806519, "time-step": 1426}, {"errors": 0.2255115807056427, "time-step": 1427}, {"errors": 0.22539713978767395, "time-step": 1428}, {"errors": 0.22528226673603058, "time-step": 1429}, {"errors": 0.22516702115535736, "time-step": 1430}, {"errors": 0.2250514030456543, "time-step": 1431}, {"errors": 0.224935382604599, "time-step": 1432}, {"errors": 0.22481897473335266, "time-step": 1433}, {"errors": 0.2247021496295929, "time-step": 1434}, {"errors": 0.2245849221944809, "time-step": 1435}, {"errors": 0.22446735203266144, "time-step": 1436}, {"errors": 0.22434936463832855, "time-step": 1437}, {"errors": 0.22423101961612701, "time-step": 1438}, {"errors": 0.22411222755908966, "time-step": 1439}, {"errors": 0.22399309277534485, "time-step": 1440}, {"errors": 0.2238735407590866, "time-step": 1441}, {"errors": 0.22375358641147614, "time-step": 1442}, {"errors": 0.22363325953483582, "time-step": 1443}, {"errors": 0.22351253032684326, "time-step": 1444}, {"errors": 0.22339139878749847, "time-step": 1445}, {"errors": 0.22326987981796265, "time-step": 1446}, {"errors": 0.22314797341823578, "time-step": 1447}, {"errors": 0.22302567958831787, "time-step": 1448}, {"errors": 0.22290296852588654, "time-step": 1449}, {"errors": 0.22277989983558655, "time-step": 1450}, {"errors": 0.22265639901161194, "time-step": 1451}, {"errors": 0.2225324809551239, "time-step": 1452}, {"errors": 0.2224082350730896, "time-step": 1453}, {"errors": 0.2222835272550583, "time-step": 1454}, {"errors": 0.2221584916114807, "time-step": 1455}, {"errors": 0.22203302383422852, "time-step": 1456}, {"errors": 0.22190716862678528, "time-step": 1457}, {"errors": 0.221780925989151, "time-step": 1458}, {"errors": 0.2216542810201645, "time-step": 1459}, {"errors": 0.22152720391750336, "time-step": 1460}, {"errors": 0.22139978408813477, "time-step": 1461}, {"errors": 0.22127193212509155, "time-step": 1462}, {"errors": 0.2211436927318573, "time-step": 1463}, {"errors": 0.221015065908432, "time-step": 1464}, {"errors": 0.2208860218524933, "time-step": 1465}, {"errors": 0.22075659036636353, "time-step": 1466}, {"errors": 0.2206268012523651, "time-step": 1467}, {"errors": 0.22049656510353088, "time-step": 1468}, {"errors": 0.22036594152450562, "time-step": 1469}, {"errors": 0.2202349454164505, "time-step": 1470}, {"errors": 0.22010354697704315, "time-step": 1471}, {"errors": 0.21997173130512238, "time-step": 1472}, {"errors": 0.21983951330184937, "time-step": 1473}, {"errors": 0.2197069227695465, "time-step": 1474}, {"errors": 0.21957391500473022, "time-step": 1475}, {"errors": 0.2194405198097229, "time-step": 1476}, {"errors": 0.21930669248104095, "time-step": 1477}, {"errors": 0.21917253732681274, "time-step": 1478}, {"errors": 0.2190379649400711, "time-step": 1479}, {"errors": 0.21890297532081604, "time-step": 1480}, {"errors": 0.21876758337020874, "time-step": 1481}, {"errors": 0.2186318188905716, "time-step": 1482}, {"errors": 0.21849563717842102, "time-step": 1483}, {"errors": 0.2183590680360794, "time-step": 1484}, {"errors": 0.21822208166122437, "time-step": 1485}, {"errors": 0.21808476746082306, "time-step": 1486}, {"errors": 0.21794697642326355, "time-step": 1487}, {"errors": 0.2178088128566742, "time-step": 1488}, {"errors": 0.2176702469587326, "time-step": 1489}, {"errors": 0.21753130853176117, "time-step": 1490}, {"errors": 0.2173919677734375, "time-step": 1491}, {"errors": 0.2172521948814392, "time-step": 1492}, {"errors": 0.21711207926273346, "time-step": 1493}, {"errors": 0.2169715166091919, "time-step": 1494}, {"errors": 0.21683059632778168, "time-step": 1495}, {"errors": 0.21668925881385803, "time-step": 1496}, {"errors": 0.21654754877090454, "time-step": 1497}, {"errors": 0.21640539169311523, "time-step": 1498}, {"errors": 0.21626287698745728, "time-step": 1499}, {"errors": 0.21611995995044708, "time-step": 1500}, {"errors": 0.21597665548324585, "time-step": 1501}, {"errors": 0.21583294868469238, "time-step": 1502}, {"errors": 0.21568885445594788, "time-step": 1503}, {"errors": 0.21554434299468994, "time-step": 1504}, {"errors": 0.21539945900440216, "time-step": 1505}, {"errors": 0.21525415778160095, "time-step": 1506}, {"errors": 0.2151084840297699, "time-step": 1507}, {"errors": 0.21496239304542542, "time-step": 1508}, {"errors": 0.2148159146308899, "time-step": 1509}, {"errors": 0.21466907858848572, "time-step": 1510}, {"errors": 0.21452181041240692, "time-step": 1511}, {"errors": 0.21437418460845947, "time-step": 1512}, {"errors": 0.2142261117696762, "time-step": 1513}, {"errors": 0.2140776515007019, "time-step": 1514}, {"errors": 0.21392884850502014, "time-step": 1515}, {"errors": 0.21377962827682495, "time-step": 1516}, {"errors": 0.21362997591495514, "time-step": 1517}, {"errors": 0.21347999572753906, "time-step": 1518}, {"errors": 0.21332958340644836, "time-step": 1519}, {"errors": 0.21317876875400543, "time-step": 1520}, {"errors": 0.21302761137485504, "time-step": 1521}, {"errors": 0.21287602186203003, "time-step": 1522}, {"errors": 0.21272404491901398, "time-step": 1523}, {"errors": 0.21257168054580688, "time-step": 1524}, {"errors": 0.21241892874240875, "time-step": 1525}, {"errors": 0.2122657746076584, "time-step": 1526}, {"errors": 0.21211223304271698, "time-step": 1527}, {"errors": 0.21195831894874573, "time-step": 1528}, {"errors": 0.21180401742458344, "time-step": 1529}, {"errors": 0.2116493135690689, "time-step": 1530}, {"errors": 0.21149423718452454, "time-step": 1531}, {"errors": 0.21133874356746674, "time-step": 1532}, {"errors": 0.21118289232254028, "time-step": 1533}, {"errors": 0.2110266387462616, "time-step": 1534}, {"errors": 0.21086999773979187, "time-step": 1535}, {"errors": 0.21071293950080872, "time-step": 1536}, {"errors": 0.2105555236339569, "time-step": 1537}, {"errors": 0.21039772033691406, "time-step": 1538}, {"errors": 0.2102394998073578, "time-step": 1539}, {"errors": 0.21008095145225525, "time-step": 1540}, {"errors": 0.2099219709634781, "time-step": 1541}, {"errors": 0.2097626030445099, "time-step": 1542}, {"errors": 0.20960287749767303, "time-step": 1543}, {"errors": 0.20944279432296753, "time-step": 1544}, {"errors": 0.2092822790145874, "time-step": 1545}, {"errors": 0.20912140607833862, "time-step": 1546}, {"errors": 0.20896011590957642, "time-step": 1547}, {"errors": 0.20879848301410675, "time-step": 1548}, {"errors": 0.20863643288612366, "time-step": 1549}, {"errors": 0.2084740251302719, "time-step": 1550}, {"errors": 0.20831120014190674, "time-step": 1551}, {"errors": 0.2081480175256729, "time-step": 1552}, {"errors": 0.20798447728157043, "time-step": 1553}, {"errors": 0.20782054960727692, "time-step": 1554}, {"errors": 0.20765617489814758, "time-step": 1555}, {"errors": 0.20749151706695557, "time-step": 1556}, {"errors": 0.2073264718055725, "time-step": 1557}, {"errors": 0.20716096460819244, "time-step": 1558}, {"errors": 0.20699509978294373, "time-step": 1559}, {"errors": 0.20682890713214874, "time-step": 1560}, {"errors": 0.2066623419523239, "time-step": 1561}, {"errors": 0.20649534463882446, "time-step": 1562}, {"errors": 0.20632798969745636, "time-step": 1563}, {"errors": 0.2061602622270584, "time-step": 1564}, {"errors": 0.20599216222763062, "time-step": 1565}, {"errors": 0.20582370460033417, "time-step": 1566}, {"errors": 0.20565484464168549, "time-step": 1567}, {"errors": 0.20548564195632935, "time-step": 1568}, {"errors": 0.20531606674194336, "time-step": 1569}, {"errors": 0.20514607429504395, "time-step": 1570}, {"errors": 0.20497570931911469, "time-step": 1571}, {"errors": 0.20480501651763916, "time-step": 1572}, {"errors": 0.2046339213848114, "time-step": 1573}, {"errors": 0.2044624537229538, "time-step": 1574}, {"errors": 0.20429064333438873, "time-step": 1575}, {"errors": 0.20411844551563263, "time-step": 1576}, {"errors": 0.20394589006900787, "time-step": 1577}, {"errors": 0.20377294719219208, "time-step": 1578}, {"errors": 0.20359966158866882, "time-step": 1579}, {"errors": 0.20342598855495453, "time-step": 1580}, {"errors": 0.2032519280910492, "time-step": 1581}, {"errors": 0.2030775547027588, "time-step": 1582}, {"errors": 0.20290279388427734, "time-step": 1583}, {"errors": 0.20272764563560486, "time-step": 1584}, {"errors": 0.2025521844625473, "time-step": 1585}, {"errors": 0.20237627625465393, "time-step": 1586}, {"errors": 0.20220008492469788, "time-step": 1587}, {"errors": 0.2020234912633896, "time-step": 1588}, {"errors": 0.20184653997421265, "time-step": 1589}, {"errors": 0.20166921615600586, "time-step": 1590}, {"errors": 0.2014915496110916, "time-step": 1591}, {"errors": 0.20131352543830872, "time-step": 1592}, {"errors": 0.20113509893417358, "time-step": 1593}, {"errors": 0.20095638930797577, "time-step": 1594}, {"errors": 0.20077727735042572, "time-step": 1595}, {"errors": 0.20059777796268463, "time-step": 1596}, {"errors": 0.20041798055171967, "time-step": 1597}, {"errors": 0.20023779571056366, "time-step": 1598}, {"errors": 0.200057253241539, "time-step": 1599}, {"errors": 0.19987636804580688, "time-step": 1600}, {"errors": 0.19969509541988373, "time-step": 1601}, {"errors": 0.1995135247707367, "time-step": 1602}, {"errors": 0.19933158159255981, "time-step": 1603}, {"errors": 0.19914928078651428, "time-step": 1604}, {"errors": 0.1989666372537613, "time-step": 1605}, {"errors": 0.19878360629081726, "time-step": 1606}, {"errors": 0.19860026240348816, "time-step": 1607}, {"errors": 0.1984165608882904, "time-step": 1608}, {"errors": 0.1982324868440628, "time-step": 1609}, {"errors": 0.19804809987545013, "time-step": 1610}, {"errors": 0.19786337018013, "time-step": 1611}, {"errors": 0.19767823815345764, "time-step": 1612}, {"errors": 0.1974928081035614, "time-step": 1613}, {"errors": 0.1973070502281189, "time-step": 1614}, {"errors": 0.19712091982364655, "time-step": 1615}, {"errors": 0.19693441689014435, "time-step": 1616}, {"errors": 0.19674760103225708, "time-step": 1617}, {"errors": 0.19656047224998474, "time-step": 1618}, {"errors": 0.19637292623519897, "time-step": 1619}, {"errors": 0.1961851269006729, "time-step": 1620}, {"errors": 0.1959969401359558, "time-step": 1621}, {"errors": 0.19580842554569244, "time-step": 1622}, {"errors": 0.1956195831298828, "time-step": 1623}, {"errors": 0.19543036818504333, "time-step": 1624}, {"errors": 0.19524088501930237, "time-step": 1625}, {"errors": 0.19505098462104797, "time-step": 1626}, {"errors": 0.1948608160018921, "time-step": 1627}, {"errors": 0.19467027485370636, "time-step": 1628}, {"errors": 0.19447939097881317, "time-step": 1629}, {"errors": 0.1942882239818573, "time-step": 1630}, {"errors": 0.1940966546535492, "time-step": 1631}, {"errors": 0.1939048171043396, "time-step": 1632}, {"errors": 0.19371262192726135, "time-step": 1633}, {"errors": 0.19352008402347565, "time-step": 1634}, {"errors": 0.19332721829414368, "time-step": 1635}, {"errors": 0.19313408434391022, "time-step": 1636}, {"errors": 0.19294054806232452, "time-step": 1637}, {"errors": 0.19274675846099854, "time-step": 1638}, {"errors": 0.1925526261329651, "time-step": 1639}, {"errors": 0.192358136177063, "time-step": 1640}, {"errors": 0.192163348197937, "time-step": 1641}, {"errors": 0.19196823239326477, "time-step": 1642}, {"errors": 0.19177275896072388, "time-step": 1643}, {"errors": 0.1915770173072815, "time-step": 1644}, {"errors": 0.19138093292713165, "time-step": 1645}, {"errors": 0.19118456542491913, "time-step": 1646}, {"errors": 0.19098784029483795, "time-step": 1647}, {"errors": 0.19079084694385529, "time-step": 1648}, {"errors": 0.19059348106384277, "time-step": 1649}, {"errors": 0.19039581716060638, "time-step": 1650}, {"errors": 0.19019785523414612, "time-step": 1651}, {"errors": 0.1899995505809784, "time-step": 1652}, {"errors": 0.18980096280574799, "time-step": 1653}, {"errors": 0.1896020472049713, "time-step": 1654}, {"errors": 0.18940284848213196, "time-step": 1655}, {"errors": 0.18920330703258514, "time-step": 1656}, {"errors": 0.18900349736213684, "time-step": 1657}, {"errors": 0.18880334496498108, "time-step": 1658}, {"errors": 0.18860292434692383, "time-step": 1659}, {"errors": 0.18840214610099792, "time-step": 1660}, {"errors": 0.18820111453533173, "time-step": 1661}, {"errors": 0.18799978494644165, "time-step": 1662}, {"errors": 0.18779809772968292, "time-step": 1663}, {"errors": 0.1875961571931839, "time-step": 1664}, {"errors": 0.1873939037322998, "time-step": 1665}, {"errors": 0.18719133734703064, "time-step": 1666}, {"errors": 0.1869884878396988, "time-step": 1667}, {"errors": 0.18678534030914307, "time-step": 1668}, {"errors": 0.18658192455768585, "time-step": 1669}, {"errors": 0.18637819588184357, "time-step": 1670}, {"errors": 0.18617413938045502, "time-step": 1671}, {"errors": 0.18596982955932617, "time-step": 1672}, {"errors": 0.18576525151729584, "time-step": 1673}, {"errors": 0.18556034564971924, "time-step": 1674}, {"errors": 0.18535512685775757, "time-step": 1675}, {"errors": 0.1851496398448944, "time-step": 1676}, {"errors": 0.18494389951229095, "time-step": 1677}, {"errors": 0.18473786115646362, "time-step": 1678}, {"errors": 0.1845315396785736, "time-step": 1679}, {"errors": 0.18432490527629852, "time-step": 1680}, {"errors": 0.18411800265312195, "time-step": 1681}, {"errors": 0.18391083180904388, "time-step": 1682}, {"errors": 0.18370337784290314, "time-step": 1683}, {"errors": 0.1834956258535385, "time-step": 1684}, {"errors": 0.1832876205444336, "time-step": 1685}, {"errors": 0.18307934701442719, "time-step": 1686}, {"errors": 0.1828707754611969, "time-step": 1687}, {"errors": 0.18266192078590393, "time-step": 1688}, {"errors": 0.18245284259319305, "time-step": 1689}, {"errors": 0.1822434514760971, "time-step": 1690}, {"errors": 0.18203380703926086, "time-step": 1691}, {"errors": 0.18182389438152313, "time-step": 1692}, {"errors": 0.18161368370056152, "time-step": 1693}, {"errors": 0.1814032346010208, "time-step": 1694}, {"errors": 0.1811925172805786, "time-step": 1695}, {"errors": 0.18098151683807373, "time-step": 1696}, {"errors": 0.18077024817466736, "time-step": 1697}, {"errors": 0.18055877089500427, "time-step": 1698}, {"errors": 0.18034698069095612, "time-step": 1699}, {"errors": 0.18013493716716766, "time-step": 1700}, {"errors": 0.1799226552248001, "time-step": 1701}, {"errors": 0.17971011996269226, "time-step": 1702}, {"errors": 0.17949733138084412, "time-step": 1703}, {"errors": 0.17928427457809448, "time-step": 1704}, {"errors": 0.17907097935676575, "time-step": 1705}, {"errors": 0.17885738611221313, "time-step": 1706}, {"errors": 0.17864356935024261, "time-step": 1707}, {"errors": 0.178429514169693, "time-step": 1708}, {"errors": 0.17821523547172546, "time-step": 1709}, {"errors": 0.17800064384937286, "time-step": 1710}, {"errors": 0.17778584361076355, "time-step": 1711}, {"errors": 0.17757081985473633, "time-step": 1712}, {"errors": 0.17735552787780762, "time-step": 1713}, {"errors": 0.1771399825811386, "time-step": 1714}, {"errors": 0.1769242286682129, "time-step": 1715}, {"errors": 0.17670822143554688, "time-step": 1716}, {"errors": 0.17649197578430176, "time-step": 1717}, {"errors": 0.17627552151679993, "time-step": 1718}, {"errors": 0.1760587841272354, "time-step": 1719}, {"errors": 0.17584183812141418, "time-step": 1720}, {"errors": 0.17562465369701385, "time-step": 1721}, {"errors": 0.1754072904586792, "time-step": 1722}, {"errors": 0.17518959939479828, "time-step": 1723}, {"errors": 0.17497174441814423, "time-step": 1724}, {"errors": 0.1747536063194275, "time-step": 1725}, {"errors": 0.1745353639125824, "time-step": 1726}, {"errors": 0.17431680858135223, "time-step": 1727}, {"errors": 0.17409804463386536, "time-step": 1728}, {"errors": 0.17387902736663818, "time-step": 1729}, {"errors": 0.17365983128547668, "time-step": 1730}, {"errors": 0.17344044148921967, "time-step": 1731}, {"errors": 0.17322079837322235, "time-step": 1732}, {"errors": 0.17300094664096832, "time-step": 1733}, {"errors": 0.172780841588974, "time-step": 1734}, {"errors": 0.17256061732769012, "time-step": 1735}, {"errors": 0.17234013974666595, "time-step": 1736}, {"errors": 0.17211943864822388, "time-step": 1737}, {"errors": 0.17189854383468628, "time-step": 1738}, {"errors": 0.17167741060256958, "time-step": 1739}, {"errors": 0.17145609855651855, "time-step": 1740}, {"errors": 0.171234592795372, "time-step": 1741}, {"errors": 0.17101289331912994, "time-step": 1742}, {"errors": 0.17079094052314758, "time-step": 1743}, {"errors": 0.17056885361671448, "time-step": 1744}, {"errors": 0.17034654319286346, "time-step": 1745}, {"errors": 0.17012402415275574, "time-step": 1746}, {"errors": 0.1699013113975525, "time-step": 1747}, {"errors": 0.1696784645318985, "time-step": 1748}, {"errors": 0.16945533454418182, "time-step": 1749}, {"errors": 0.1692320704460144, "time-step": 1750}, {"errors": 0.16900861263275146, "time-step": 1751}, {"errors": 0.16878493130207062, "time-step": 1752}, {"errors": 0.16856111586093903, "time-step": 1753}, {"errors": 0.1683371216058731, "time-step": 1754}, {"errors": 0.16811291873455048, "time-step": 1755}, {"errors": 0.16788853704929352, "time-step": 1756}, {"errors": 0.16766397655010223, "time-step": 1757}, {"errors": 0.16743923723697662, "time-step": 1758}, {"errors": 0.1672143191099167, "time-step": 1759}, {"errors": 0.16698923707008362, "time-step": 1760}, {"errors": 0.1667640209197998, "time-step": 1761}, {"errors": 0.1665385663509369, "time-step": 1762}, {"errors": 0.16631296277046204, "time-step": 1763}, {"errors": 0.16608721017837524, "time-step": 1764}, {"errors": 0.16586127877235413, "time-step": 1765}, {"errors": 0.16563516855239868, "time-step": 1766}, {"errors": 0.16540895402431488, "time-step": 1767}, {"errors": 0.16518253087997437, "time-step": 1768}, {"errors": 0.1649559587240219, "time-step": 1769}, {"errors": 0.16472920775413513, "time-step": 1770}, {"errors": 0.1645023226737976, "time-step": 1771}, {"errors": 0.16427525877952576, "time-step": 1772}, {"errors": 0.16404809057712555, "time-step": 1773}, {"errors": 0.16382072865962982, "time-step": 1774}, {"errors": 0.16359326243400574, "time-step": 1775}, {"errors": 0.16336563229560852, "time-step": 1776}, {"errors": 0.16313783824443817, "time-step": 1777}, {"errors": 0.1629098653793335, "time-step": 1778}, {"errors": 0.16268180310726166, "time-step": 1779}, {"errors": 0.16245362162590027, "time-step": 1780}, {"errors": 0.16222524642944336, "time-step": 1781}, {"errors": 0.1619967818260193, "time-step": 1782}, {"errors": 0.1617681086063385, "time-step": 1783}, {"errors": 0.16153933107852936, "time-step": 1784}, {"errors": 0.16131044924259186, "time-step": 1785}, {"errors": 0.161081463098526, "time-step": 1786}, {"errors": 0.16085228323936462, "time-step": 1787}, {"errors": 0.16062301397323608, "time-step": 1788}, {"errors": 0.16039356589317322, "time-step": 1789}, {"errors": 0.16016405820846558, "time-step": 1790}, {"errors": 0.1599343866109848, "time-step": 1791}, {"errors": 0.15970459580421448, "time-step": 1792}, {"errors": 0.15947476029396057, "time-step": 1793}, {"errors": 0.15924474596977234, "time-step": 1794}, {"errors": 0.15901459753513336, "time-step": 1795}, {"errors": 0.1587843894958496, "time-step": 1796}, {"errors": 0.15855401754379272, "time-step": 1797}, {"errors": 0.15832357108592987, "time-step": 1798}, {"errors": 0.15809299051761627, "time-step": 1799}, {"errors": 0.15786230564117432, "time-step": 1800}, {"errors": 0.15763156116008759, "time-step": 1801}, {"errors": 0.15740065276622772, "time-step": 1802}, {"errors": 0.15716969966888428, "time-step": 1803}, {"errors": 0.1569385826587677, "time-step": 1804}, {"errors": 0.15670739114284515, "time-step": 1805}, {"errors": 0.15647614002227783, "time-step": 1806}, {"errors": 0.15624476969242096, "time-step": 1807}, {"errors": 0.15601330995559692, "time-step": 1808}, {"errors": 0.15578176081180573, "time-step": 1809}, {"errors": 0.15555009245872498, "time-step": 1810}, {"errors": 0.15531834959983826, "time-step": 1811}, {"errors": 0.15508653223514557, "time-step": 1812}, {"errors": 0.1548546701669693, "time-step": 1813}, {"errors": 0.15462270379066467, "time-step": 1814}, {"errors": 0.1543906331062317, "time-step": 1815}, {"errors": 0.15415847301483154, "time-step": 1816}, {"errors": 0.15392625331878662, "time-step": 1817}, {"errors": 0.15369397401809692, "time-step": 1818}, {"errors": 0.15346162021160126, "time-step": 1819}, {"errors": 0.15322914719581604, "time-step": 1820}, {"errors": 0.15299665927886963, "time-step": 1821}, {"errors": 0.15276408195495605, "time-step": 1822}, {"errors": 0.1525314748287201, "time-step": 1823}, {"errors": 0.15229874849319458, "time-step": 1824}, {"errors": 0.15206597745418549, "time-step": 1825}, {"errors": 0.151833176612854, "time-step": 1826}, {"errors": 0.15160027146339417, "time-step": 1827}, {"errors": 0.15136735141277313, "time-step": 1828}, {"errors": 0.15113435685634613, "time-step": 1829}, {"errors": 0.15090131759643555, "time-step": 1830}, {"errors": 0.1506682187318802, "time-step": 1831}, {"errors": 0.15043509006500244, "time-step": 1832}, {"errors": 0.15020188689231873, "time-step": 1833}, {"errors": 0.14996863901615143, "time-step": 1834}, {"errors": 0.14973533153533936, "time-step": 1835}, {"errors": 0.14950202405452728, "time-step": 1836}, {"errors": 0.14926865696907043, "time-step": 1837}, {"errors": 0.1490352302789688, "time-step": 1838}, {"errors": 0.148801788687706, "time-step": 1839}, {"errors": 0.14856833219528198, "time-step": 1840}, {"errors": 0.1483348309993744, "time-step": 1841}, {"errors": 0.14810128509998322, "time-step": 1842}, {"errors": 0.14786770939826965, "time-step": 1843}, {"errors": 0.1476341187953949, "time-step": 1844}, {"errors": 0.14740049839019775, "time-step": 1845}, {"errors": 0.14716683328151703, "time-step": 1846}, {"errors": 0.14693313837051392, "time-step": 1847}, {"errors": 0.1466994434595108, "time-step": 1848}, {"errors": 0.1464657485485077, "time-step": 1849}, {"errors": 0.146232008934021, "time-step": 1850}, {"errors": 0.14599823951721191, "time-step": 1851}, {"errors": 0.14576449990272522, "time-step": 1852}, {"errors": 0.14553071558475494, "time-step": 1853}, {"errors": 0.14529696106910706, "time-step": 1854}, {"errors": 0.14506316184997559, "time-step": 1855}, {"errors": 0.14482936263084412, "time-step": 1856}, {"errors": 0.14459557831287384, "time-step": 1857}, {"errors": 0.14436177909374237, "time-step": 1858}, {"errors": 0.1441279798746109, "time-step": 1859}, {"errors": 0.14389415085315704, "time-step": 1860}, {"errors": 0.14366035163402557, "time-step": 1861}, {"errors": 0.1434265524148941, "time-step": 1862}, {"errors": 0.14319276809692383, "time-step": 1863}, {"errors": 0.14295896887779236, "time-step": 1864}, {"errors": 0.14272521436214447, "time-step": 1865}, {"errors": 0.14249145984649658, "time-step": 1866}, {"errors": 0.1422576904296875, "time-step": 1867}, {"errors": 0.1420239508152008, "time-step": 1868}, {"errors": 0.1417902559041977, "time-step": 1869}, {"errors": 0.1415565460920334, "time-step": 1870}, {"errors": 0.14132286608219147, "time-step": 1871}, {"errors": 0.14108920097351074, "time-step": 1872}, {"errors": 0.1408555954694748, "time-step": 1873}, {"errors": 0.14062198996543884, "time-step": 1874}, {"errors": 0.1403883993625641, "time-step": 1875}, {"errors": 0.14015483856201172, "time-step": 1876}, {"errors": 0.13992132246494293, "time-step": 1877}, {"errors": 0.13968786597251892, "time-step": 1878}, {"errors": 0.1394544094800949, "time-step": 1879}, {"errors": 0.1392209678888321, "time-step": 1880}, {"errors": 0.13898761570453644, "time-step": 1881}, {"errors": 0.13875427842140198, "time-step": 1882}, {"errors": 0.1385209709405899, "time-step": 1883}, {"errors": 0.1382877230644226, "time-step": 1884}, {"errors": 0.1380545198917389, "time-step": 1885}, {"errors": 0.13782134652137756, "time-step": 1886}, {"errors": 0.1375882476568222, "time-step": 1887}, {"errors": 0.13735516369342804, "time-step": 1888}, {"errors": 0.13712219893932343, "time-step": 1889}, {"errors": 0.13688921928405762, "time-step": 1890}, {"errors": 0.13665632903575897, "time-step": 1891}, {"errors": 0.13642346858978271, "time-step": 1892}, {"errors": 0.13619065284729004, "time-step": 1893}, {"errors": 0.13595795631408691, "time-step": 1894}, {"errors": 0.13572528958320618, "time-step": 1895}, {"errors": 0.1354926973581314, "time-step": 1896}, {"errors": 0.13526016473770142, "time-step": 1897}, {"errors": 0.135027676820755, "time-step": 1898}, {"errors": 0.13479524850845337, "time-step": 1899}, {"errors": 0.13456293940544128, "time-step": 1900}, {"errors": 0.13433067500591278, "time-step": 1901}, {"errors": 0.13409845530986786, "time-step": 1902}, {"errors": 0.1338663548231125, "time-step": 1903}, {"errors": 0.13363434374332428, "time-step": 1904}, {"errors": 0.13340237736701965, "time-step": 1905}, {"errors": 0.13317051529884338, "time-step": 1906}, {"errors": 0.1329387128353119, "time-step": 1907}, {"errors": 0.13270701467990875, "time-step": 1908}, {"errors": 0.1324753612279892, "time-step": 1909}, {"errors": 0.1322438269853592, "time-step": 1910}, {"errors": 0.13201236724853516, "time-step": 1911}, {"errors": 0.13178105652332306, "time-step": 1912}, {"errors": 0.13154976069927216, "time-step": 1913}, {"errors": 0.131318598985672, "time-step": 1914}, {"errors": 0.1310874968767166, "time-step": 1915}, {"errors": 0.13085652887821198, "time-step": 1916}, {"errors": 0.1306256353855133, "time-step": 1917}, {"errors": 0.13039487600326538, "time-step": 1918}, {"errors": 0.13016417622566223, "time-step": 1919}, {"errors": 0.12993358075618744, "time-step": 1920}, {"errors": 0.1297031044960022, "time-step": 1921}, {"errors": 0.1294727623462677, "time-step": 1922}, {"errors": 0.12924247980117798, "time-step": 1923}, {"errors": 0.129012331366539, "time-step": 1924}, {"errors": 0.1287822723388672, "time-step": 1925}, {"errors": 0.12855231761932373, "time-step": 1926}, {"errors": 0.1283225417137146, "time-step": 1927}, {"errors": 0.12809282541275024, "time-step": 1928}, {"errors": 0.12786321341991425, "time-step": 1929}, {"errors": 0.12763378024101257, "time-step": 1930}, {"errors": 0.12740442156791687, "time-step": 1931}, {"errors": 0.1271751970052719, "time-step": 1932}, {"errors": 0.1269461065530777, "time-step": 1933}, {"errors": 0.12671709060668945, "time-step": 1934}, {"errors": 0.12648825347423553, "time-step": 1935}, {"errors": 0.12625953555107117, "time-step": 1936}, {"errors": 0.12603093683719635, "time-step": 1937}, {"errors": 0.12580248713493347, "time-step": 1938}, {"errors": 0.12557415664196014, "time-step": 1939}, {"errors": 0.12534596025943756, "time-step": 1940}, {"errors": 0.12511788308620453, "time-step": 1941}, {"errors": 0.12488994747400284, "time-step": 1942}, {"errors": 0.12466216087341309, "time-step": 1943}, {"errors": 0.1244344711303711, "time-step": 1944}, {"errors": 0.1242070123553276, "time-step": 1945}, {"errors": 0.12397964298725128, "time-step": 1946}, {"errors": 0.12375238537788391, "time-step": 1947}, {"errors": 0.12352532148361206, "time-step": 1948}, {"errors": 0.12329838424921036, "time-step": 1949}, {"errors": 0.12307158857584, "time-step": 1950}, {"errors": 0.12284496426582336, "time-step": 1951}, {"errors": 0.12261846661567688, "time-step": 1952}, {"errors": 0.12239213287830353, "time-step": 1953}, {"errors": 0.12216596305370331, "time-step": 1954}, {"errors": 0.12193992733955383, "time-step": 1955}, {"errors": 0.1217140406370163, "time-step": 1956}, {"errors": 0.12148837745189667, "time-step": 1957}, {"errors": 0.12126277387142181, "time-step": 1958}, {"errors": 0.12103740870952606, "time-step": 1959}, {"errors": 0.12081217765808105, "time-step": 1960}, {"errors": 0.12058711051940918, "time-step": 1961}, {"errors": 0.12036220729351044, "time-step": 1962}, {"errors": 0.12013748288154602, "time-step": 1963}, {"errors": 0.11991290748119354, "time-step": 1964}, {"errors": 0.1196884959936142, "time-step": 1965}, {"errors": 0.11946427077054977, "time-step": 1966}, {"errors": 0.11924022436141968, "time-step": 1967}, {"errors": 0.11901630461215973, "time-step": 1968}, {"errors": 0.11879262328147888, "time-step": 1969}, {"errors": 0.11856907606124878, "time-step": 1970}, {"errors": 0.1183457002043724, "time-step": 1971}, {"errors": 0.11812251061201096, "time-step": 1972}, {"errors": 0.11789948493242264, "time-step": 1973}, {"errors": 0.11767666786909103, "time-step": 1974}, {"errors": 0.11745402961969376, "time-step": 1975}, {"errors": 0.11723160743713379, "time-step": 1976}, {"errors": 0.11700929701328278, "time-step": 1977}, {"errors": 0.11678722500801086, "time-step": 1978}, {"errors": 0.1165652945637703, "time-step": 1979}, {"errors": 0.11634358763694763, "time-step": 1980}, {"errors": 0.1161220520734787, "time-step": 1981}, {"errors": 0.11590072512626648, "time-step": 1982}, {"errors": 0.1156795546412468, "time-step": 1983}, {"errors": 0.11545860767364502, "time-step": 1984}, {"errors": 0.11523783951997757, "time-step": 1985}, {"errors": 0.11501727998256683, "time-step": 1986}, {"errors": 0.11479690670967102, "time-step": 1987}, {"errors": 0.11457672715187073, "time-step": 1988}, {"errors": 0.11435678601264954, "time-step": 1989}, {"errors": 0.11413699388504028, "time-step": 1990}, {"errors": 0.11391744017601013, "time-step": 1991}, {"errors": 0.11369803547859192, "time-step": 1992}, {"errors": 0.113478884100914, "time-step": 1993}, {"errors": 0.11325988918542862, "time-step": 1994}, {"errors": 0.11304113268852234, "time-step": 1995}, {"errors": 0.11282260715961456, "time-step": 1996}, {"errors": 0.11260424554347992, "time-step": 1997}, {"errors": 0.11238610744476318, "time-step": 1998}, {"errors": 0.11216818541288376, "time-step": 1999}, {"errors": 0.11195047944784164, "time-step": 2000}, {"errors": 0.11173294484615326, "time-step": 2001}, {"errors": 0.11151567101478577, "time-step": 2002}, {"errors": 0.1112985908985138, "time-step": 2003}, {"errors": 0.11108171939849854, "time-step": 2004}, {"errors": 0.11086509376764297, "time-step": 2005}, {"errors": 0.11064866185188293, "time-step": 2006}, {"errors": 0.1104324460029602, "time-step": 2007}, {"errors": 0.11021646112203598, "time-step": 2008}, {"errors": 0.11000066995620728, "time-step": 2009}, {"errors": 0.10978513956069946, "time-step": 2010}, {"errors": 0.10956982523202896, "time-step": 2011}, {"errors": 0.10935470461845398, "time-step": 2012}, {"errors": 0.1091398373246193, "time-step": 2013}, {"errors": 0.10892520844936371, "time-step": 2014}, {"errors": 0.10871076583862305, "time-step": 2015}, {"errors": 0.10849656909704208, "time-step": 2016}, {"errors": 0.10828261822462082, "time-step": 2017}, {"errors": 0.10806883871555328, "time-step": 2018}, {"errors": 0.10785537213087082, "time-step": 2019}, {"errors": 0.10764209181070328, "time-step": 2020}, {"errors": 0.10742902755737305, "time-step": 2021}, {"errors": 0.10721622407436371, "time-step": 2022}, {"errors": 0.10700365900993347, "time-step": 2023}, {"errors": 0.10679131746292114, "time-step": 2024}, {"errors": 0.10657922178506851, "time-step": 2025}, {"errors": 0.10636735707521439, "time-step": 2026}, {"errors": 0.10615570843219757, "time-step": 2027}, {"errors": 0.10594432055950165, "time-step": 2028}, {"errors": 0.10573316365480423, "time-step": 2029}, {"errors": 0.10552230477333069, "time-step": 2030}, {"errors": 0.10531161725521088, "time-step": 2031}, {"errors": 0.10510119795799255, "time-step": 2032}, {"errors": 0.10489100962877274, "time-step": 2033}, {"errors": 0.10468106716871262, "time-step": 2034}, {"errors": 0.10447138547897339, "time-step": 2035}, {"errors": 0.10426194220781326, "time-step": 2036}, {"errors": 0.10405274480581284, "time-step": 2037}, {"errors": 0.10384377837181091, "time-step": 2038}, {"errors": 0.10363508015871048, "time-step": 2039}, {"errors": 0.10342665016651154, "time-step": 2040}, {"errors": 0.1032184436917305, "time-step": 2041}, {"errors": 0.10301048308610916, "time-step": 2042}, {"errors": 0.10280279070138931, "time-step": 2043}, {"errors": 0.10259536653757095, "time-step": 2044}, {"errors": 0.1023881733417511, "time-step": 2045}, {"errors": 0.10218122601509094, "time-step": 2046}, {"errors": 0.10197456181049347, "time-step": 2047}, {"errors": 0.1017681360244751, "time-step": 2048}, {"errors": 0.10156197100877762, "time-step": 2049}, {"errors": 0.10135606676340103, "time-step": 2050}, {"errors": 0.10115037858486176, "time-step": 2051}, {"errors": 0.10094501078128815, "time-step": 2052}, {"errors": 0.10073989629745483, "time-step": 2053}, {"errors": 0.10053502023220062, "time-step": 2054}, {"errors": 0.1003304272890091, "time-step": 2055}, {"errors": 0.10012608021497726, "time-step": 2056}, {"errors": 0.09992196410894394, "time-step": 2057}, {"errors": 0.09971817582845688, "time-step": 2058}, {"errors": 0.09951458871364594, "time-step": 2059}, {"errors": 0.09931132942438126, "time-step": 2060}, {"errors": 0.09910828620195389, "time-step": 2061}, {"errors": 0.0989055186510086, "time-step": 2062}, {"errors": 0.09870303422212601, "time-step": 2063}, {"errors": 0.0985008254647255, "time-step": 2064}, {"errors": 0.09829886257648468, "time-step": 2065}, {"errors": 0.09809716045856476, "time-step": 2066}, {"errors": 0.09789576381444931, "time-step": 2067}, {"errors": 0.09769464284181595, "time-step": 2068}, {"errors": 0.0974937304854393, "time-step": 2069}, {"errors": 0.09729315340518951, "time-step": 2070}, {"errors": 0.09709281474351883, "time-step": 2071}, {"errors": 0.09689273685216904, "time-step": 2072}, {"errors": 0.09669297933578491, "time-step": 2073}, {"errors": 0.09649346768856049, "time-step": 2074}, {"errors": 0.09629422426223755, "time-step": 2075}, {"errors": 0.09609527140855789, "time-step": 2076}, {"errors": 0.09589659422636032, "time-step": 2077}, {"errors": 0.09569819271564484, "time-step": 2078}, {"errors": 0.09550005942583084, "time-step": 2079}, {"errors": 0.09530220180749893, "time-step": 2080}, {"errors": 0.0951046347618103, "time-step": 2081}, {"errors": 0.09490734338760376, "time-step": 2082}, {"errors": 0.09471036493778229, "time-step": 2083}, {"errors": 0.09451359510421753, "time-step": 2084}, {"errors": 0.09431716799736023, "time-step": 2085}, {"errors": 0.09412097185850143, "time-step": 2086}, {"errors": 0.09392508864402771, "time-step": 2087}, {"errors": 0.09372948110103607, "time-step": 2088}, {"errors": 0.09353415668010712, "time-step": 2089}, {"errors": 0.09333913028240204, "time-step": 2090}, {"errors": 0.09314437210559845, "time-step": 2091}, {"errors": 0.09294994175434113, "time-step": 2092}, {"errors": 0.09275570511817932, "time-step": 2093}, {"errors": 0.09256181120872498, "time-step": 2094}, {"errors": 0.09236817061901093, "time-step": 2095}, {"errors": 0.09217486530542374, "time-step": 2096}, {"errors": 0.09198185056447983, "time-step": 2097}, {"errors": 0.091789111495018, "time-step": 2098}, {"errors": 0.0915965810418129, "time-step": 2099}, {"errors": 0.09140443801879883, "time-step": 2100}, {"errors": 0.09121255576610565, "time-step": 2101}, {"errors": 0.09102091938257217, "time-step": 2102}, {"errors": 0.09082963317632675, "time-step": 2103}, {"errors": 0.09063860774040222, "time-step": 2104}, {"errors": 0.09044790267944336, "time-step": 2105}, {"errors": 0.09025748074054718, "time-step": 2106}, {"errors": 0.0900672972202301, "time-step": 2107}, {"errors": 0.08987745642662048, "time-step": 2108}, {"errors": 0.08968791365623474, "time-step": 2109}, {"errors": 0.0894986242055893, "time-step": 2110}, {"errors": 0.08930965512990952, "time-step": 2111}, {"errors": 0.08912099897861481, "time-step": 2112}, {"errors": 0.0889325886964798, "time-step": 2113}, {"errors": 0.08874447643756866, "time-step": 2114}, {"errors": 0.0885566994547844, "time-step": 2115}, {"errors": 0.08836919069290161, "time-step": 2116}, {"errors": 0.0881819874048233, "time-step": 2117}, {"errors": 0.08799508959054947, "time-step": 2118}, {"errors": 0.08780848234891891, "time-step": 2119}, {"errors": 0.08762214332818985, "time-step": 2120}, {"errors": 0.08743615448474884, "time-step": 2121}, {"errors": 0.08725041896104813, "time-step": 2122}, {"errors": 0.08706500381231308, "time-step": 2123}, {"errors": 0.08687985688447952, "time-step": 2124}, {"errors": 0.08669501543045044, "time-step": 2125}, {"errors": 0.08651050180196762, "time-step": 2126}, {"errors": 0.08632627874612808, "time-step": 2127}, {"errors": 0.08614233136177063, "time-step": 2128}, {"errors": 0.08595868945121765, "time-step": 2129}, {"errors": 0.08577535301446915, "time-step": 2130}, {"errors": 0.08559231460094452, "time-step": 2131}, {"errors": 0.08540961146354675, "time-step": 2132}, {"errors": 0.08522716164588928, "time-step": 2133}, {"errors": 0.08504501730203629, "time-step": 2134}, {"errors": 0.08486319333314896, "time-step": 2135}, {"errors": 0.08468165993690491, "time-step": 2136}, {"errors": 0.08450044691562653, "time-step": 2137}, {"errors": 0.08431949466466904, "time-step": 2138}, {"errors": 0.08413886278867722, "time-step": 2139}, {"errors": 0.08395857363939285, "time-step": 2140}, {"errors": 0.08377856016159058, "time-step": 2141}, {"errors": 0.08359885215759277, "time-step": 2142}, {"errors": 0.08341942727565765, "time-step": 2143}, {"errors": 0.0832403302192688, "time-step": 2144}, {"errors": 0.08306150883436203, "time-step": 2145}, {"errors": 0.08288301527500153, "time-step": 2146}, {"errors": 0.08270479738712311, "time-step": 2147}, {"errors": 0.08252690732479095, "time-step": 2148}, {"errors": 0.08234934508800507, "time-step": 2149}, {"errors": 0.08217205107212067, "time-step": 2150}, {"errors": 0.08199506998062134, "time-step": 2151}, {"errors": 0.08181837946176529, "time-step": 2152}, {"errors": 0.0816420465707779, "time-step": 2153}, {"errors": 0.0814659520983696, "time-step": 2154}, {"errors": 0.08129020780324936, "time-step": 2155}, {"errors": 0.0811147689819336, "time-step": 2156}, {"errors": 0.08093961328268051, "time-step": 2157}, {"errors": 0.0807647854089737, "time-step": 2158}, {"errors": 0.08059023320674896, "time-step": 2159}, {"errors": 0.0804159939289093, "time-step": 2160}, {"errors": 0.0802420973777771, "time-step": 2161}, {"errors": 0.08006848394870758, "time-step": 2162}, {"errors": 0.07989516854286194, "time-step": 2163}, {"errors": 0.07972218096256256, "time-step": 2164}, {"errors": 0.07954947650432587, "time-step": 2165}, {"errors": 0.07937711477279663, "time-step": 2166}, {"errors": 0.07920504361391068, "time-step": 2167}, {"errors": 0.0790332481265068, "time-step": 2168}, {"errors": 0.0788617879152298, "time-step": 2169}, {"errors": 0.07869064062833786, "time-step": 2170}, {"errors": 0.0785197764635086, "time-step": 2171}, {"errors": 0.07834924012422562, "time-step": 2172}, {"errors": 0.0781790167093277, "time-step": 2173}, {"errors": 0.07800909876823425, "time-step": 2174}, {"errors": 0.07783948630094528, "time-step": 2175}, {"errors": 0.077670156955719, "time-step": 2176}, {"errors": 0.07750117033720016, "time-step": 2177}, {"errors": 0.07733248919248581, "time-step": 2178}, {"errors": 0.07716409862041473, "time-step": 2179}, {"errors": 0.07699602842330933, "time-step": 2180}, {"errors": 0.0768282562494278, "time-step": 2181}, {"errors": 0.07666079699993134, "time-step": 2182}, {"errors": 0.07649365067481995, "time-step": 2183}, {"errors": 0.07632680237293243, "time-step": 2184}, {"errors": 0.07616028934717178, "time-step": 2185}, {"errors": 0.07599405944347382, "time-step": 2186}, {"errors": 0.07582813501358032, "time-step": 2187}, {"errors": 0.0756625384092331, "time-step": 2188}, {"errors": 0.07549723237752914, "time-step": 2189}, {"errors": 0.07533224672079086, "time-step": 2190}, {"errors": 0.07516756653785706, "time-step": 2191}, {"errors": 0.07500320672988892, "time-step": 2192}, {"errors": 0.07483913004398346, "time-step": 2193}, {"errors": 0.07467538863420486, "time-step": 2194}, {"errors": 0.07451193034648895, "time-step": 2195}, {"errors": 0.0743487998843193, "time-step": 2196}, {"errors": 0.07418598234653473, "time-step": 2197}, {"errors": 0.07402347028255463, "time-step": 2198}, {"errors": 0.0738612487912178, "time-step": 2199}, {"errors": 0.07369936257600784, "time-step": 2200}, {"errors": 0.07353775948286057, "time-step": 2201}, {"errors": 0.07337649166584015, "time-step": 2202}, {"errors": 0.07321550697088242, "time-step": 2203}, {"errors": 0.07305484265089035, "time-step": 2204}, {"errors": 0.07289446890354156, "time-step": 2205}, {"errors": 0.07273440808057785, "time-step": 2206}, {"errors": 0.072574682533741, "time-step": 2207}, {"errors": 0.07241526991128922, "time-step": 2208}, {"errors": 0.07225612550973892, "time-step": 2209}, {"errors": 0.0720973089337349, "time-step": 2210}, {"errors": 0.07193880528211594, "time-step": 2211}, {"errors": 0.07178058475255966, "time-step": 2212}, {"errors": 0.07162270694971085, "time-step": 2213}, {"errors": 0.07146512717008591, "time-step": 2214}, {"errors": 0.07130783796310425, "time-step": 2215}, {"errors": 0.07115086913108826, "time-step": 2216}, {"errors": 0.07099422812461853, "time-step": 2217}, {"errors": 0.07083787024021149, "time-step": 2218}, {"errors": 0.07068182528018951, "time-step": 2219}, {"errors": 0.07052607089281082, "time-step": 2220}, {"errors": 0.0703706443309784, "time-step": 2221}, {"errors": 0.07021550089120865, "time-step": 2222}, {"errors": 0.07006069272756577, "time-step": 2223}, {"errors": 0.06990617513656616, "time-step": 2224}, {"errors": 0.06975196301937103, "time-step": 2225}, {"errors": 0.06959807872772217, "time-step": 2226}, {"errors": 0.06944449990987778, "time-step": 2227}, {"errors": 0.06929120421409607, "time-step": 2228}, {"errors": 0.06913822889328003, "time-step": 2229}, {"errors": 0.06898555159568787, "time-step": 2230}, {"errors": 0.06883318722248077, "time-step": 2231}, {"errors": 0.06868110597133636, "time-step": 2232}, {"errors": 0.06852935999631882, "time-step": 2233}, {"errors": 0.06837791949510574, "time-step": 2234}, {"errors": 0.06822677701711655, "time-step": 2235}, {"errors": 0.06807593256235123, "time-step": 2236}, {"errors": 0.06792537868022919, "time-step": 2237}, {"errors": 0.06777515262365341, "time-step": 2238}, {"errors": 0.0676252543926239, "time-step": 2239}, {"errors": 0.06747560203075409, "time-step": 2240}, {"errors": 0.06732630729675293, "time-step": 2241}, {"errors": 0.06717727333307266, "time-step": 2242}, {"errors": 0.06702855974435806, "time-step": 2243}, {"errors": 0.06688015908002853, "time-step": 2244}, {"errors": 0.06673206388950348, "time-step": 2245}, {"errors": 0.06658423691987991, "time-step": 2246}, {"errors": 0.066436767578125, "time-step": 2247}, {"errors": 0.06628959625959396, "time-step": 2248}, {"errors": 0.06614265590906143, "time-step": 2249}, {"errors": 0.06599611788988113, "time-step": 2250}, {"errors": 0.06584982573986053, "time-step": 2251}, {"errors": 0.0657038539648056, "time-step": 2252}, {"errors": 0.06555813550949097, "time-step": 2253}, {"errors": 0.06541275233030319, "time-step": 2254}, {"errors": 0.06526768952608109, "time-step": 2255}, {"errors": 0.06512291729450226, "time-step": 2256}, {"errors": 0.06497843563556671, "time-step": 2257}, {"errors": 0.06483427435159683, "time-step": 2258}, {"errors": 0.06469037383794785, "time-step": 2259}, {"errors": 0.06454681605100632, "time-step": 2260}, {"errors": 0.06440355628728867, "time-step": 2261}, {"errors": 0.0642605796456337, "time-step": 2262}, {"errors": 0.06411789357662201, "time-step": 2263}, {"errors": 0.06397553533315659, "time-step": 2264}, {"errors": 0.06383346021175385, "time-step": 2265}, {"errors": 0.06369167566299438, "time-step": 2266}, {"errors": 0.0635501816868782, "time-step": 2267}, {"errors": 0.06340903043746948, "time-step": 2268}, {"errors": 0.06326813250780106, "time-step": 2269}, {"errors": 0.06312756985425949, "time-step": 2270}, {"errors": 0.06298727542161942, "time-step": 2271}, {"errors": 0.06284727156162262, "time-step": 2272}, {"errors": 0.06270758807659149, "time-step": 2273}, {"errors": 0.06256821006536484, "time-step": 2274}, {"errors": 0.06242910027503967, "time-step": 2275}, {"errors": 0.06229030713438988, "time-step": 2276}, {"errors": 0.06215181574225426, "time-step": 2277}, {"errors": 0.06201360374689102, "time-step": 2278}, {"errors": 0.061875686049461365, "time-step": 2279}, {"errors": 0.06173808127641678, "time-step": 2280}, {"errors": 0.06160072982311249, "time-step": 2281}, {"errors": 0.06146373227238655, "time-step": 2282}, {"errors": 0.06132698431611061, "time-step": 2283}, {"errors": 0.06119054928421974, "time-step": 2284}, {"errors": 0.061054401099681854, "time-step": 2285}, {"errors": 0.060918569564819336, "time-step": 2286}, {"errors": 0.0607830174267292, "time-step": 2287}, {"errors": 0.06064772605895996, "time-step": 2288}, {"errors": 0.06051274389028549, "time-step": 2289}, {"errors": 0.06037807837128639, "time-step": 2290}, {"errors": 0.06024370342493057, "time-step": 2291}, {"errors": 0.06010960787534714, "time-step": 2292}, {"errors": 0.05997578799724579, "time-step": 2293}, {"errors": 0.05984225869178772, "time-step": 2294}, {"errors": 0.059709057211875916, "time-step": 2295}, {"errors": 0.0595761239528656, "time-step": 2296}, {"errors": 0.05944349244236946, "time-step": 2297}, {"errors": 0.05931110680103302, "time-step": 2298}, {"errors": 0.05917905271053314, "time-step": 2299}, {"errors": 0.05904727801680565, "time-step": 2300}, {"errors": 0.05891577899456024, "time-step": 2301}, {"errors": 0.058784596621990204, "time-step": 2302}, {"errors": 0.05865369737148285, "time-step": 2303}, {"errors": 0.05852307751774788, "time-step": 2304}, {"errors": 0.05839274078607559, "time-step": 2305}, {"errors": 0.058262694627046585, "time-step": 2306}, {"errors": 0.05813293159008026, "time-step": 2307}, {"errors": 0.05800343677401543, "time-step": 2308}, {"errors": 0.05787426605820656, "time-step": 2309}, {"errors": 0.05774536728858948, "time-step": 2310}, {"errors": 0.057616740465164185, "time-step": 2311}, {"errors": 0.05748843029141426, "time-step": 2312}, {"errors": 0.057360369712114334, "time-step": 2313}, {"errors": 0.05723261833190918, "time-step": 2314}, {"errors": 0.057105131447315216, "time-step": 2315}, {"errors": 0.05697793513536453, "time-step": 2316}, {"errors": 0.05685102194547653, "time-step": 2317}, {"errors": 0.056724414229393005, "time-step": 2318}, {"errors": 0.05659804120659828, "time-step": 2319}, {"errors": 0.05647200345993042, "time-step": 2320}, {"errors": 0.05634620785713196, "time-step": 2321}, {"errors": 0.05622069537639618, "time-step": 2322}, {"errors": 0.056095484644174576, "time-step": 2323}, {"errors": 0.055970557034015656, "time-step": 2324}, {"errors": 0.055845897644758224, "time-step": 2325}, {"errors": 0.05572152137756348, "time-step": 2326}, {"errors": 0.05559743568301201, "time-step": 2327}, {"errors": 0.055473603308200836, "time-step": 2328}, {"errors": 0.055350080132484436, "time-step": 2329}, {"errors": 0.05522681400179863, "time-step": 2330}, {"errors": 0.0551038458943367, "time-step": 2331}, {"errors": 0.054981134831905365, "time-step": 2332}, {"errors": 0.05485871061682701, "time-step": 2333}, {"errors": 0.05473654344677925, "time-step": 2334}, {"errors": 0.05461467057466507, "time-step": 2335}, {"errors": 0.054493095725774765, "time-step": 2336}, {"errors": 0.054371755570173264, "time-step": 2337}, {"errors": 0.05425069481134415, "time-step": 2338}, {"errors": 0.054129939526319504, "time-step": 2339}, {"errors": 0.05400943383574486, "time-step": 2340}, {"errors": 0.05388922989368439, "time-step": 2341}, {"errors": 0.05376926437020302, "time-step": 2342}, {"errors": 0.05364958196878433, "time-step": 2343}, {"errors": 0.05353020131587982, "time-step": 2344}, {"errors": 0.05341107398271561, "time-step": 2345}, {"errors": 0.053292207419872284, "time-step": 2346}, {"errors": 0.05317363142967224, "time-step": 2347}, {"errors": 0.0530553013086319, "time-step": 2348}, {"errors": 0.05293726176023483, "time-step": 2349}, {"errors": 0.052819494158029556, "time-step": 2350}, {"errors": 0.05270199850201607, "time-step": 2351}, {"errors": 0.052584756165742874, "time-step": 2352}, {"errors": 0.05246780440211296, "time-step": 2353}, {"errors": 0.05235110595822334, "time-step": 2354}, {"errors": 0.05223468318581581, "time-step": 2355}, {"errors": 0.05211852490901947, "time-step": 2356}, {"errors": 0.05200263112783432, "time-step": 2357}, {"errors": 0.051887013018131256, "time-step": 2358}, {"errors": 0.05177165940403938, "time-step": 2359}, {"errors": 0.051656574010849, "time-step": 2360}, {"errors": 0.051541734486818314, "time-step": 2361}, {"errors": 0.051427192986011505, "time-step": 2362}, {"errors": 0.051312901079654694, "time-step": 2363}, {"errors": 0.05119886249303818, "time-step": 2364}, {"errors": 0.051085107028484344, "time-step": 2365}, {"errors": 0.0509716160595417, "time-step": 2366}, {"errors": 0.050858382135629654, "time-step": 2367}, {"errors": 0.050745416432619095, "time-step": 2368}, {"errors": 0.05063271522521973, "time-step": 2369}, {"errors": 0.05052027851343155, "time-step": 2370}, {"errors": 0.05040806531906128, "time-step": 2371}, {"errors": 0.05029613897204399, "time-step": 2372}, {"errors": 0.050184495747089386, "time-step": 2373}, {"errors": 0.05007307231426239, "time-step": 2374}, {"errors": 0.04996193200349808, "time-step": 2375}, {"errors": 0.049851059913635254, "time-step": 2376}, {"errors": 0.049740418791770935, "time-step": 2377}, {"errors": 0.049630071967840195, "time-step": 2378}, {"errors": 0.04951995983719826, "time-step": 2379}, {"errors": 0.04941011220216751, "time-step": 2380}, {"errors": 0.04930055886507034, "time-step": 2381}, {"errors": 0.04919121414422989, "time-step": 2382}, {"errors": 0.049082107841968536, "time-step": 2383}, {"errors": 0.04897329956293106, "time-step": 2384}, {"errors": 0.04886474460363388, "time-step": 2385}, {"errors": 0.0487564280629158, "time-step": 2386}, {"errors": 0.04864838719367981, "time-step": 2387}, {"errors": 0.04854058474302292, "time-step": 2388}, {"errors": 0.048433031886816025, "time-step": 2389}, {"errors": 0.04832573980093002, "time-step": 2390}, {"errors": 0.04821871593594551, "time-step": 2391}, {"errors": 0.048111915588378906, "time-step": 2392}, {"errors": 0.04800537973642349, "time-step": 2393}, {"errors": 0.04789910092949867, "time-step": 2394}, {"errors": 0.04779306799173355, "time-step": 2395}, {"errors": 0.047687284648418427, "time-step": 2396}, {"errors": 0.047581747174263, "time-step": 2397}, {"errors": 0.04747648537158966, "time-step": 2398}, {"errors": 0.047371454536914825, "time-step": 2399}, {"errors": 0.047266677021980286, "time-step": 2400}, {"errors": 0.04716213047504425, "time-step": 2401}, {"errors": 0.04705784469842911, "time-step": 2402}, {"errors": 0.046953827142715454, "time-step": 2403}, {"errors": 0.04685003310441971, "time-step": 2404}, {"errors": 0.046746496111154556, "time-step": 2405}, {"errors": 0.0466432124376297, "time-step": 2406}, {"errors": 0.046540144830942154, "time-step": 2407}, {"errors": 0.0464373342692852, "time-step": 2408}, {"errors": 0.04633479192852974, "time-step": 2409}, {"errors": 0.04623245447874069, "time-step": 2410}, {"errors": 0.04613039642572403, "time-step": 2411}, {"errors": 0.04602857679128647, "time-step": 2412}, {"errors": 0.04592697694897652, "time-step": 2413}, {"errors": 0.04582562297582626, "time-step": 2414}, {"errors": 0.045724548399448395, "time-step": 2415}, {"errors": 0.04562368616461754, "time-step": 2416}, {"errors": 0.045523062348365784, "time-step": 2417}, {"errors": 0.04542271047830582, "time-step": 2418}, {"errors": 0.045322567224502563, "time-step": 2419}, {"errors": 0.04522266238927841, "time-step": 2420}, {"errors": 0.04512302950024605, "time-step": 2421}, {"errors": 0.045023612678050995, "time-step": 2422}, {"errors": 0.044924430549144745, "time-step": 2423}, {"errors": 0.04482549428939819, "time-step": 2424}, {"errors": 0.04472678154706955, "time-step": 2425}, {"errors": 0.0446283221244812, "time-step": 2426}, {"errors": 0.04453009366989136, "time-step": 2427}, {"errors": 0.04443208873271942, "time-step": 2428}, {"errors": 0.04433433711528778, "time-step": 2429}, {"errors": 0.044236816465854645, "time-step": 2430}, {"errors": 0.04413953423500061, "time-step": 2431}, {"errors": 0.044042497873306274, "time-step": 2432}, {"errors": 0.043945662677288055, "time-step": 2433}, {"errors": 0.04384910315275192, "time-step": 2434}, {"errors": 0.04375274479389191, "time-step": 2435}, {"errors": 0.043656617403030396, "time-step": 2436}, {"errors": 0.043560732156038284, "time-step": 2437}, {"errors": 0.04346508905291557, "time-step": 2438}, {"errors": 0.04336967691779137, "time-step": 2439}, {"errors": 0.04327448084950447, "time-step": 2440}, {"errors": 0.043179530650377274, "time-step": 2441}, {"errors": 0.043084803968667984, "time-step": 2442}, {"errors": 0.042990297079086304, "time-step": 2443}, {"errors": 0.04289602115750313, "time-step": 2444}, {"errors": 0.04280197247862816, "time-step": 2445}, {"errors": 0.0427081435918808, "time-step": 2446}, {"errors": 0.04261458292603493, "time-step": 2447}, {"errors": 0.042521219700574875, "time-step": 2448}, {"errors": 0.042428094893693924, "time-step": 2449}, {"errors": 0.042335182428359985, "time-step": 2450}, {"errors": 0.042242493480443954, "time-step": 2451}, {"errors": 0.04215003550052643, "time-step": 2452}, {"errors": 0.04205780103802681, "time-step": 2453}, {"errors": 0.0419657863676548, "time-step": 2454}, {"errors": 0.041874002665281296, "time-step": 2455}, {"errors": 0.04178246483206749, "time-step": 2456}, {"errors": 0.04169110581278801, "time-step": 2457}, {"errors": 0.041600000113248825, "time-step": 2458}, {"errors": 0.041509099304676056, "time-step": 2459}, {"errors": 0.041418448090553284, "time-step": 2460}, {"errors": 0.041327979415655136, "time-step": 2461}, {"errors": 0.04123775288462639, "time-step": 2462}, {"errors": 0.041147734969854355, "time-step": 2463}, {"errors": 0.04105796664953232, "time-step": 2464}, {"errors": 0.040968380868434906, "time-step": 2465}, {"errors": 0.0408790297806263, "time-step": 2466}, {"errors": 0.040789902210235596, "time-step": 2467}, {"errors": 0.04070097953081131, "time-step": 2468}, {"errors": 0.04061229154467583, "time-step": 2469}, {"errors": 0.04052380472421646, "time-step": 2470}, {"errors": 0.0404355525970459, "time-step": 2471}, {"errors": 0.04034748300909996, "time-step": 2472}, {"errors": 0.04025966674089432, "time-step": 2473}, {"errors": 0.040172040462493896, "time-step": 2474}, {"errors": 0.040084630250930786, "time-step": 2475}, {"errors": 0.03999745100736618, "time-step": 2476}, {"errors": 0.03991047292947769, "time-step": 2477}, {"errors": 0.03982369974255562, "time-step": 2478}, {"errors": 0.03973715379834175, "time-step": 2479}, {"errors": 0.039650801569223404, "time-step": 2480}, {"errors": 0.039564669132232666, "time-step": 2481}, {"errors": 0.039478760212659836, "time-step": 2482}, {"errors": 0.03939305990934372, "time-step": 2483}, {"errors": 0.03930756449699402, "time-step": 2484}, {"errors": 0.03922228887677193, "time-step": 2485}, {"errors": 0.03913720324635506, "time-step": 2486}, {"errors": 0.03905235603451729, "time-step": 2487}, {"errors": 0.03896770626306534, "time-step": 2488}, {"errors": 0.038883231580257416, "time-step": 2489}, {"errors": 0.03879900649189949, "time-step": 2490}, {"errors": 0.038714971393346786, "time-step": 2491}, {"errors": 0.0386311300098896, "time-step": 2492}, {"errors": 0.03854752704501152, "time-step": 2493}, {"errors": 0.03846411779522896, "time-step": 2494}, {"errors": 0.03838091716170311, "time-step": 2495}, {"errors": 0.03829789534211159, "time-step": 2496}, {"errors": 0.038215115666389465, "time-step": 2497}, {"errors": 0.03813249617815018, "time-step": 2498}, {"errors": 0.038050100207328796, "time-step": 2499}, {"errors": 0.03796791285276413, "time-step": 2500}, {"errors": 0.03788593411445618, "time-step": 2501}, {"errors": 0.037804145365953445, "time-step": 2502}, {"errors": 0.037722572684288025, "time-step": 2503}, {"errors": 0.03764118254184723, "time-step": 2504}, {"errors": 0.03755999729037285, "time-step": 2505}, {"errors": 0.03747903183102608, "time-step": 2506}, {"errors": 0.03739825263619423, "time-step": 2507}, {"errors": 0.037317659705877304, "time-step": 2508}, {"errors": 0.03723728656768799, "time-step": 2509}, {"errors": 0.0371570959687233, "time-step": 2510}, {"errors": 0.03707712143659592, "time-step": 2511}, {"errors": 0.03699732944369316, "time-step": 2512}, {"errors": 0.03691774234175682, "time-step": 2513}, {"errors": 0.0368383452296257, "time-step": 2514}, {"errors": 0.0367591567337513, "time-step": 2515}, {"errors": 0.03668016567826271, "time-step": 2516}, {"errors": 0.03660134598612785, "time-step": 2517}, {"errors": 0.03652273118495941, "time-step": 2518}, {"errors": 0.03644431382417679, "time-step": 2519}, {"errors": 0.03636608645319939, "time-step": 2520}, {"errors": 0.036288052797317505, "time-step": 2521}, {"errors": 0.03621021658182144, "time-step": 2522}, {"errors": 0.036132581532001495, "time-step": 2523}, {"errors": 0.036055125296115875, "time-step": 2524}, {"errors": 0.03597788140177727, "time-step": 2525}, {"errors": 0.035900793969631195, "time-step": 2526}, {"errors": 0.03582392632961273, "time-step": 2527}, {"errors": 0.035747237503528595, "time-step": 2528}, {"errors": 0.03567075356841087, "time-step": 2529}, {"errors": 0.035594452172517776, "time-step": 2530}, {"errors": 0.035518333315849304, "time-step": 2531}, {"errors": 0.03544239699840546, "time-step": 2532}, {"errors": 0.03536665812134743, "time-step": 2533}, {"errors": 0.03529110178351402, "time-step": 2534}, {"errors": 0.03521574288606644, "time-step": 2535}, {"errors": 0.03514057770371437, "time-step": 2536}, {"errors": 0.03506557643413544, "time-step": 2537}, {"errors": 0.03499075770378113, "time-step": 2538}, {"errors": 0.03491615504026413, "time-step": 2539}, {"errors": 0.03484172746539116, "time-step": 2540}, {"errors": 0.03476746380329132, "time-step": 2541}, {"errors": 0.0346934013068676, "time-step": 2542}, {"errors": 0.034619517624378204, "time-step": 2543}, {"errors": 0.03454583138227463, "time-step": 2544}, {"errors": 0.03447230905294418, "time-step": 2545}, {"errors": 0.03439897298812866, "time-step": 2546}, {"errors": 0.034325823187828064, "time-step": 2547}, {"errors": 0.03425287455320358, "time-step": 2548}, {"errors": 0.03418007493019104, "time-step": 2549}, {"errors": 0.034107450395822525, "time-step": 2550}, {"errors": 0.03403502330183983, "time-step": 2551}, {"errors": 0.033962786197662354, "time-step": 2552}, {"errors": 0.0338907316327095, "time-step": 2553}, {"errors": 0.03381883725523949, "time-step": 2554}, {"errors": 0.03374712914228439, "time-step": 2555}, {"errors": 0.033675599843263626, "time-step": 2556}, {"errors": 0.03360426053404808, "time-step": 2557}, {"errors": 0.03353308141231537, "time-step": 2558}, {"errors": 0.03346209228038788, "time-step": 2559}, {"errors": 0.033391259610652924, "time-step": 2560}, {"errors": 0.033320631831884384, "time-step": 2561}, {"errors": 0.033250145614147186, "time-step": 2562}, {"errors": 0.03317985683679581, "time-step": 2563}, {"errors": 0.03310973197221756, "time-step": 2564}, {"errors": 0.03303977847099304, "time-step": 2565}, {"errors": 0.032970014959573746, "time-step": 2566}, {"errors": 0.03290041536092758, "time-step": 2567}, {"errors": 0.032830994576215744, "time-step": 2568}, {"errors": 0.03276173770427704, "time-step": 2569}, {"errors": 0.03269265592098236, "time-step": 2570}, {"errors": 0.032623738050460815, "time-step": 2571}, {"errors": 0.03255501389503479, "time-step": 2572}, {"errors": 0.032486461102962494, "time-step": 2573}, {"errors": 0.032418061047792435, "time-step": 2574}, {"errors": 0.0323498398065567, "time-step": 2575}, {"errors": 0.0322817787528038, "time-step": 2576}, {"errors": 0.03221388906240463, "time-step": 2577}, {"errors": 0.03214618191123009, "time-step": 2578}, {"errors": 0.03207862749695778, "time-step": 2579}, {"errors": 0.0320112444460392, "time-step": 2580}, {"errors": 0.03194403648376465, "time-step": 2581}, {"errors": 0.03187698498368263, "time-step": 2582}, {"errors": 0.03181011602282524, "time-step": 2583}, {"errors": 0.03174339234828949, "time-step": 2584}, {"errors": 0.03167685121297836, "time-step": 2585}, {"errors": 0.03161046653985977, "time-step": 2586}, {"errors": 0.03154425323009491, "time-step": 2587}, {"errors": 0.031478215008974075, "time-step": 2588}, {"errors": 0.031412336975336075, "time-step": 2589}, {"errors": 0.03134661540389061, "time-step": 2590}, {"errors": 0.03128105029463768, "time-step": 2591}, {"errors": 0.03121565654873848, "time-step": 2592}, {"errors": 0.03115043416619301, "time-step": 2593}, {"errors": 0.031085360795259476, "time-step": 2594}, {"errors": 0.031020451337099075, "time-step": 2595}, {"errors": 0.030955694615840912, "time-step": 2596}, {"errors": 0.03089112415909767, "time-step": 2597}, {"errors": 0.030826689675450325, "time-step": 2598}, {"errors": 0.03076242096722126, "time-step": 2599}, {"errors": 0.030698323622345924, "time-step": 2600}, {"errors": 0.030634388327598572, "time-step": 2601}, {"errors": 0.03057059645652771, "time-step": 2602}, {"errors": 0.030506979674100876, "time-step": 2603}, {"errors": 0.030443506315350533, "time-step": 2604}, {"errors": 0.03038019686937332, "time-step": 2605}, {"errors": 0.030317053198814392, "time-step": 2606}, {"errors": 0.030254041776061058, "time-step": 2607}, {"errors": 0.0301912073045969, "time-step": 2608}, {"errors": 0.030128546059131622, "time-step": 2609}, {"errors": 0.03006599470973015, "time-step": 2610}, {"errors": 0.030003633350133896, "time-step": 2611}, {"errors": 0.02994142845273018, "time-step": 2612}, {"errors": 0.029879357665777206, "time-step": 2613}, {"errors": 0.02981743961572647, "time-step": 2614}, {"errors": 0.029755696654319763, "time-step": 2615}, {"errors": 0.029694100841879845, "time-step": 2616}, {"errors": 0.02963264472782612, "time-step": 2617}, {"errors": 0.029571358114480972, "time-step": 2618}, {"errors": 0.029510220512747765, "time-step": 2619}, {"errors": 0.02944924496114254, "time-step": 2620}, {"errors": 0.029388396069407463, "time-step": 2621}, {"errors": 0.02932770922780037, "time-step": 2622}, {"errors": 0.029267191886901855, "time-step": 2623}, {"errors": 0.029206791892647743, "time-step": 2624}, {"errors": 0.02914656698703766, "time-step": 2625}, {"errors": 0.02908647060394287, "time-step": 2626}, {"errors": 0.029026532545685768, "time-step": 2627}, {"errors": 0.0289667546749115, "time-step": 2628}, {"errors": 0.028907129541039467, "time-step": 2629}, {"errors": 0.02884763292968273, "time-step": 2630}, {"errors": 0.028788287192583084, "time-step": 2631}, {"errors": 0.02872910164296627, "time-step": 2632}, {"errors": 0.0286700539290905, "time-step": 2633}, {"errors": 0.028611164540052414, "time-step": 2634}, {"errors": 0.028552409261465073, "time-step": 2635}, {"errors": 0.028493793681263924, "time-step": 2636}, {"errors": 0.02843533642590046, "time-step": 2637}, {"errors": 0.02837701328098774, "time-step": 2638}, {"errors": 0.028318848460912704, "time-step": 2639}, {"errors": 0.02826082333922386, "time-step": 2640}, {"errors": 0.02820293791592121, "time-step": 2641}, {"errors": 0.02814520336687565, "time-step": 2642}, {"errors": 0.02808760106563568, "time-step": 2643}, {"errors": 0.02803015522658825, "time-step": 2644}, {"errors": 0.027972836047410965, "time-step": 2645}, {"errors": 0.027915677055716515, "time-step": 2646}, {"errors": 0.02785865031182766, "time-step": 2647}, {"errors": 0.027801770716905594, "time-step": 2648}, {"errors": 0.027745017781853676, "time-step": 2649}, {"errors": 0.02768842503428459, "time-step": 2650}, {"errors": 0.027631955221295357, "time-step": 2651}, {"errors": 0.027575630694627762, "time-step": 2652}, {"errors": 0.027519460767507553, "time-step": 2653}, {"errors": 0.0274633951485157, "time-step": 2654}, {"errors": 0.027407506480813026, "time-step": 2655}, {"errors": 0.027351731434464455, "time-step": 2656}, {"errors": 0.02729610539972782, "time-step": 2657}, {"errors": 0.027240626513957977, "time-step": 2658}, {"errors": 0.027185264974832535, "time-step": 2659}, {"errors": 0.027130046859383583, "time-step": 2660}, {"errors": 0.02707497775554657, "time-step": 2661}, {"errors": 0.027020029723644257, "time-step": 2662}, {"errors": 0.026965215802192688, "time-step": 2663}, {"errors": 0.02691054716706276, "time-step": 2664}, {"errors": 0.026856012642383575, "time-step": 2665}, {"errors": 0.026801608502864838, "time-step": 2666}, {"errors": 0.02674735337495804, "time-step": 2667}, {"errors": 0.02669323794543743, "time-step": 2668}, {"errors": 0.02663922868669033, "time-step": 2669}, {"errors": 0.02658536657691002, "time-step": 2670}, {"errors": 0.026531629264354706, "time-step": 2671}, {"errors": 0.026478048413991928, "time-step": 2672}, {"errors": 0.026424581184983253, "time-step": 2673}, {"errors": 0.026371244341135025, "time-step": 2674}, {"errors": 0.026318049058318138, "time-step": 2675}, {"errors": 0.026264989748597145, "time-step": 2676}, {"errors": 0.026212044060230255, "time-step": 2677}, {"errors": 0.026159245520830154, "time-step": 2678}, {"errors": 0.026106566190719604, "time-step": 2679}, {"errors": 0.026054006069898605, "time-step": 2680}, {"errors": 0.02600160241127014, "time-step": 2681}, {"errors": 0.02594931796193123, "time-step": 2682}, {"errors": 0.025897163897752762, "time-step": 2683}, {"errors": 0.025845123454928398, "time-step": 2684}, {"errors": 0.025793222710490227, "time-step": 2685}, {"errors": 0.02574145421385765, "time-step": 2686}, {"errors": 0.025689810514450073, "time-step": 2687}, {"errors": 0.02563830278813839, "time-step": 2688}, {"errors": 0.02558690495789051, "time-step": 2689}, {"errors": 0.02553563192486763, "time-step": 2690}, {"errors": 0.02548450604081154, "time-step": 2691}, {"errors": 0.025433504953980446, "time-step": 2692}, {"errors": 0.02538260817527771, "time-step": 2693}, {"errors": 0.025331858545541763, "time-step": 2694}, {"errors": 0.025281213223934174, "time-step": 2695}, {"errors": 0.02523070201277733, "time-step": 2696}, {"errors": 0.02518032304942608, "time-step": 2697}, {"errors": 0.02513006143271923, "time-step": 2698}, {"errors": 0.02507992833852768, "time-step": 2699}, {"errors": 0.025029907003045082, "time-step": 2700}, {"errors": 0.02498001977801323, "time-step": 2701}, {"errors": 0.024930257350206375, "time-step": 2702}, {"errors": 0.02488061785697937, "time-step": 2703}, {"errors": 0.02483109012246132, "time-step": 2704}, {"errors": 0.02478167973458767, "time-step": 2705}, {"errors": 0.024732399731874466, "time-step": 2706}, {"errors": 0.024683259427547455, "time-step": 2707}, {"errors": 0.024634215980768204, "time-step": 2708}, {"errors": 0.024585289880633354, "time-step": 2709}, {"errors": 0.02453649789094925, "time-step": 2710}, {"errors": 0.0244878139346838, "time-step": 2711}, {"errors": 0.024439264088869095, "time-step": 2712}, {"errors": 0.024390826001763344, "time-step": 2713}, {"errors": 0.024342505261301994, "time-step": 2714}, {"errors": 0.024294303730130196, "time-step": 2715}, {"errors": 0.0242462195456028, "time-step": 2716}, {"errors": 0.0241982564330101, "time-step": 2717}, {"errors": 0.024150414392352104, "time-step": 2718}, {"errors": 0.024102680385112762, "time-step": 2719}, {"errors": 0.024055078625679016, "time-step": 2720}, {"errors": 0.02400757186114788, "time-step": 2721}, {"errors": 0.023960193619132042, "time-step": 2722}, {"errors": 0.023912928998470306, "time-step": 2723}, {"errors": 0.02386578731238842, "time-step": 2724}, {"errors": 0.023818746209144592, "time-step": 2725}, {"errors": 0.023771846666932106, "time-step": 2726}, {"errors": 0.02372504025697708, "time-step": 2727}, {"errors": 0.02367834560573101, "time-step": 2728}, {"errors": 0.023631788790225983, "time-step": 2729}, {"errors": 0.02358531579375267, "time-step": 2730}, {"errors": 0.0235389843583107, "time-step": 2731}, {"errors": 0.02349274605512619, "time-step": 2732}, {"errors": 0.023446639999747276, "time-step": 2733}, {"errors": 0.023400625213980675, "time-step": 2734}, {"errors": 0.023354725912213326, "time-step": 2735}, {"errors": 0.023308943957090378, "time-step": 2736}, {"errors": 0.02326328121125698, "time-step": 2737}, {"errors": 0.02321772836148739, "time-step": 2738}, {"errors": 0.023172281682491302, "time-step": 2739}, {"errors": 0.023126937448978424, "time-step": 2740}, {"errors": 0.023081721737980843, "time-step": 2741}, {"errors": 0.023036599159240723, "time-step": 2742}, {"errors": 0.022991590201854706, "time-step": 2743}, {"errors": 0.022946707904338837, "time-step": 2744}, {"errors": 0.02290191873908043, "time-step": 2745}, {"errors": 0.022857246920466423, "time-step": 2746}, {"errors": 0.022812673822045326, "time-step": 2747}, {"errors": 0.02276821807026863, "time-step": 2748}, {"errors": 0.02272387593984604, "time-step": 2749}, {"errors": 0.02267962507903576, "time-step": 2750}, {"errors": 0.022635482251644135, "time-step": 2751}, {"errors": 0.022591466084122658, "time-step": 2752}, {"errors": 0.02254754677414894, "time-step": 2753}, {"errors": 0.02250373363494873, "time-step": 2754}, {"errors": 0.022460028529167175, "time-step": 2755}, {"errors": 0.022416431456804276, "time-step": 2756}, {"errors": 0.022372925654053688, "time-step": 2757}, {"errors": 0.022329533472657204, "time-step": 2758}, {"errors": 0.022286267951130867, "time-step": 2759}, {"errors": 0.022243088111281395, "time-step": 2760}, {"errors": 0.02220001257956028, "time-step": 2761}, {"errors": 0.022157050669193268, "time-step": 2762}, {"errors": 0.022114183753728867, "time-step": 2763}, {"errors": 0.022071421146392822, "time-step": 2764}, {"errors": 0.022028764709830284, "time-step": 2765}, {"errors": 0.021986225619912148, "time-step": 2766}, {"errors": 0.021943772211670876, "time-step": 2767}, {"errors": 0.02190142683684826, "time-step": 2768}, {"errors": 0.021859178319573402, "time-step": 2769}, {"errors": 0.02181703969836235, "time-step": 2770}, {"errors": 0.021775005385279655, "time-step": 2771}, {"errors": 0.021733073517680168, "time-step": 2772}, {"errors": 0.02169123664498329, "time-step": 2773}, {"errors": 0.021649498492479324, "time-step": 2774}, {"errors": 0.02160787396132946, "time-step": 2775}, {"errors": 0.021566325798630714, "time-step": 2776}, {"errors": 0.02152489498257637, "time-step": 2777}, {"errors": 0.021483559161424637, "time-step": 2778}, {"errors": 0.02144233137369156, "time-step": 2779}, {"errors": 0.02140120416879654, "time-step": 2780}, {"errors": 0.021360158920288086, "time-step": 2781}, {"errors": 0.02131923846900463, "time-step": 2782}, {"errors": 0.021278396248817444, "time-step": 2783}, {"errors": 0.021237647160887718, "time-step": 2784}, {"errors": 0.021197019144892693, "time-step": 2785}, {"errors": 0.021156474947929382, "time-step": 2786}, {"errors": 0.021116036921739578, "time-step": 2787}, {"errors": 0.021075688302516937, "time-step": 2788}, {"errors": 0.021035445854067802, "time-step": 2789}, {"errors": 0.020995289087295532, "time-step": 2790}, {"errors": 0.020955244079232216, "time-step": 2791}, {"errors": 0.020915281027555466, "time-step": 2792}, {"errors": 0.02087542600929737, "time-step": 2793}, {"errors": 0.020835649222135544, "time-step": 2794}, {"errors": 0.02079598791897297, "time-step": 2795}, {"errors": 0.020756404846906662, "time-step": 2796}, {"errors": 0.020716939121484756, "time-step": 2797}, {"errors": 0.02067754417657852, "time-step": 2798}, {"errors": 0.020638253539800644, "time-step": 2799}, {"errors": 0.02059905230998993, "time-step": 2800}, {"errors": 0.02055995725095272, "time-step": 2801}, {"errors": 0.020520959049463272, "time-step": 2802}, {"errors": 0.02048204094171524, "time-step": 2803}, {"errors": 0.02044321782886982, "time-step": 2804}, {"errors": 0.020404493436217308, "time-step": 2805}, {"errors": 0.02036586031317711, "time-step": 2806}, {"errors": 0.020327316597104073, "time-step": 2807}, {"errors": 0.02028886415064335, "time-step": 2808}, {"errors": 0.02025051787495613, "time-step": 2809}, {"errors": 0.02021225169301033, "time-step": 2810}, {"errors": 0.020174071192741394, "time-step": 2811}, {"errors": 0.020135998725891113, "time-step": 2812}, {"errors": 0.0200980082154274, "time-step": 2813}, {"errors": 0.020060105249285698, "time-step": 2814}, {"errors": 0.02002228982746601, "time-step": 2815}, {"errors": 0.019984565675258636, "time-step": 2816}, {"errors": 0.01994694396853447, "time-step": 2817}, {"errors": 0.01990940235555172, "time-step": 2818}, {"errors": 0.01987195387482643, "time-step": 2819}, {"errors": 0.019834598526358604, "time-step": 2820}, {"errors": 0.019797321408987045, "time-step": 2821}, {"errors": 0.019760143011808395, "time-step": 2822}, {"errors": 0.019723044708371162, "time-step": 2823}, {"errors": 0.019686050713062286, "time-step": 2824}, {"errors": 0.01964912749826908, "time-step": 2825}, {"errors": 0.019612299278378487, "time-step": 2826}, {"errors": 0.01957555115222931, "time-step": 2827}, {"errors": 0.019538894295692444, "time-step": 2828}, {"errors": 0.01950233057141304, "time-step": 2829}, {"errors": 0.01946585439145565, "time-step": 2830}, {"errors": 0.019429465755820274, "time-step": 2831}, {"errors": 0.019393155351281166, "time-step": 2832}, {"errors": 0.01935693435370922, "time-step": 2833}, {"errors": 0.019320812076330185, "time-step": 2834}, {"errors": 0.01928476057946682, "time-step": 2835}, {"errors": 0.019248798489570618, "time-step": 2836}, {"errors": 0.01921292394399643, "time-step": 2837}, {"errors": 0.019177144393324852, "time-step": 2838}, {"errors": 0.01914142817258835, "time-step": 2839}, {"errors": 0.01910579577088356, "time-step": 2840}, {"errors": 0.01907026208937168, "time-step": 2841}, {"errors": 0.01903481036424637, "time-step": 2842}, {"errors": 0.01899944618344307, "time-step": 2843}, {"errors": 0.018964162096381187, "time-step": 2844}, {"errors": 0.01892896182835102, "time-step": 2845}, {"errors": 0.018893837928771973, "time-step": 2846}, {"errors": 0.01885879784822464, "time-step": 2847}, {"errors": 0.018823860213160515, "time-step": 2848}, {"errors": 0.018788987770676613, "time-step": 2849}, {"errors": 0.018754204735159874, "time-step": 2850}, {"errors": 0.018719492480158806, "time-step": 2851}, {"errors": 0.018684878945350647, "time-step": 2852}, {"errors": 0.01865033619105816, "time-step": 2853}, {"errors": 0.018615873530507088, "time-step": 2854}, {"errors": 0.01858150027692318, "time-step": 2855}, {"errors": 0.018547195941209793, "time-step": 2856}, {"errors": 0.01851298101246357, "time-step": 2857}, {"errors": 0.018478848040103912, "time-step": 2858}, {"errors": 0.018444795161485672, "time-step": 2859}, {"errors": 0.0184108205139637, "time-step": 2860}, {"errors": 0.018376918509602547, "time-step": 2861}, {"errors": 0.018343109637498856, "time-step": 2862}, {"errors": 0.018309377133846283, "time-step": 2863}, {"errors": 0.01827572099864483, "time-step": 2864}, {"errors": 0.01824214495718479, "time-step": 2865}, {"errors": 0.018208637833595276, "time-step": 2866}, {"errors": 0.01817522756755352, "time-step": 2867}, {"errors": 0.018141895532608032, "time-step": 2868}, {"errors": 0.018108628690242767, "time-step": 2869}, {"errors": 0.018075432628393173, "time-step": 2870}, {"errors": 0.01804233528673649, "time-step": 2871}, {"errors": 0.018009310588240623, "time-step": 2872}, {"errors": 0.01797635853290558, "time-step": 2873}, {"errors": 0.01794348657131195, "time-step": 2874}, {"errors": 0.017910681664943695, "time-step": 2875}, {"errors": 0.017877962440252304, "time-step": 2876}, {"errors": 0.017845315858721733, "time-step": 2877}, {"errors": 0.017812754958868027, "time-step": 2878}, {"errors": 0.01778027042746544, "time-step": 2879}, {"errors": 0.017747849225997925, "time-step": 2880}, {"errors": 0.017715509980916977, "time-step": 2881}, {"errors": 0.017683252692222595, "time-step": 2882}, {"errors": 0.017651058733463287, "time-step": 2883}, {"errors": 0.017618954181671143, "time-step": 2884}, {"errors": 0.01758691295981407, "time-step": 2885}, {"errors": 0.01755494251847267, "time-step": 2886}, {"errors": 0.017523063346743584, "time-step": 2887}, {"errors": 0.017491251230239868, "time-step": 2888}, {"errors": 0.017459502443671227, "time-step": 2889}, {"errors": 0.017427846789360046, "time-step": 2890}, {"errors": 0.01739625632762909, "time-step": 2891}, {"errors": 0.017364734783768654, "time-step": 2892}, {"errors": 0.017333289608359337, "time-step": 2893}, {"errors": 0.01730192080140114, "time-step": 2894}, {"errors": 0.01727062463760376, "time-step": 2895}, {"errors": 0.01723940297961235, "time-step": 2896}, {"errors": 0.017208237200975418, "time-step": 2897}, {"errors": 0.01717715710401535, "time-step": 2898}, {"errors": 0.017146160826086998, "time-step": 2899}, {"errors": 0.017115214839577675, "time-step": 2900}, {"errors": 0.017084352672100067, "time-step": 2901}, {"errors": 0.017053555697202682, "time-step": 2902}, {"errors": 0.017022836953401566, "time-step": 2903}, {"errors": 0.016992192715406418, "time-step": 2904}, {"errors": 0.016961615532636642, "time-step": 2905}, {"errors": 0.016931109130382538, "time-step": 2906}, {"errors": 0.016900675371289253, "time-step": 2907}, {"errors": 0.01687031053006649, "time-step": 2908}, {"errors": 0.016840005293488503, "time-step": 2909}, {"errors": 0.016809780150651932, "time-step": 2910}, {"errors": 0.016779622063040733, "time-step": 2911}, {"errors": 0.016749532893300056, "time-step": 2912}, {"errors": 0.0167195163667202, "time-step": 2913}, {"errors": 0.016689566895365715, "time-step": 2914}, {"errors": 0.0166596919298172, "time-step": 2915}, {"errors": 0.016629891470074654, "time-step": 2916}, {"errors": 0.01660013571381569, "time-step": 2917}, {"errors": 0.01657046005129814, "time-step": 2918}, {"errors": 0.016540858894586563, "time-step": 2919}, {"errors": 0.016511332243680954, "time-step": 2920}, {"errors": 0.016481855884194374, "time-step": 2921}, {"errors": 0.016452452167868614, "time-step": 2922}, {"errors": 0.016423126682639122, "time-step": 2923}, {"errors": 0.016393858939409256, "time-step": 2924}, {"errors": 0.016364671289920807, "time-step": 2925}, {"errors": 0.016335537657141685, "time-step": 2926}, {"errors": 0.01630646176636219, "time-step": 2927}, {"errors": 0.016277477145195007, "time-step": 2928}, {"errors": 0.0162485521286726, "time-step": 2929}, {"errors": 0.016219694167375565, "time-step": 2930}, {"errors": 0.01619088649749756, "time-step": 2931}, {"errors": 0.01616216078400612, "time-step": 2932}, {"errors": 0.016133489087224007, "time-step": 2933}, {"errors": 0.016104893758893013, "time-step": 2934}, {"errors": 0.016076361760497093, "time-step": 2935}, {"errors": 0.016047898679971695, "time-step": 2936}, {"errors": 0.016019489616155624, "time-step": 2937}, {"errors": 0.015991151332855225, "time-step": 2938}, {"errors": 0.0159628763794899, "time-step": 2939}, {"errors": 0.015934664756059647, "time-step": 2940}, {"errors": 0.015906525775790215, "time-step": 2941}, {"errors": 0.015878448262810707, "time-step": 2942}, {"errors": 0.015850428491830826, "time-step": 2943}, {"errors": 0.015822485089302063, "time-step": 2944}, {"errors": 0.01579459384083748, "time-step": 2945}, {"errors": 0.015766765922307968, "time-step": 2946}, {"errors": 0.01573900133371353, "time-step": 2947}, {"errors": 0.015711301937699318, "time-step": 2948}, {"errors": 0.015683665871620178, "time-step": 2949}, {"errors": 0.015656104311347008, "time-step": 2950}, {"errors": 0.015628596767783165, "time-step": 2951}, {"errors": 0.015601150691509247, "time-step": 2952}, {"errors": 0.015573762357234955, "time-step": 2953}, {"errors": 0.015546441078186035, "time-step": 2954}, {"errors": 0.015519186854362488, "time-step": 2955}, {"errors": 0.01549199316650629, "time-step": 2956}, {"errors": 0.015464847907423973, "time-step": 2957}, {"errors": 0.015437774360179901, "time-step": 2958}, {"errors": 0.015410767868161201, "time-step": 2959}, {"errors": 0.015383820980787277, "time-step": 2960}, {"errors": 0.015356937423348427, "time-step": 2961}, {"errors": 0.015330101363360882, "time-step": 2962}, {"errors": 0.015303331427276134, "time-step": 2963}, {"errors": 0.015276624821126461, "time-step": 2964}, {"errors": 0.015249969437718391, "time-step": 2965}, {"errors": 0.015223383903503418, "time-step": 2966}, {"errors": 0.015196858905255795, "time-step": 2967}, {"errors": 0.015170400962233543, "time-step": 2968}, {"errors": 0.015143991447985172, "time-step": 2969}, {"errors": 0.015117642469704151, "time-step": 2970}, {"errors": 0.015091358684003353, "time-step": 2971}, {"errors": 0.015065126121044159, "time-step": 2972}, {"errors": 0.015038957819342613, "time-step": 2973}, {"errors": 0.015012847259640694, "time-step": 2974}, {"errors": 0.014986797235906124, "time-step": 2975}, {"errors": 0.014960814267396927, "time-step": 2976}, {"errors": 0.014934869483113289, "time-step": 2977}, {"errors": 0.014908991754055023, "time-step": 2978}, {"errors": 0.014883177354931831, "time-step": 2979}, {"errors": 0.01485742162913084, "time-step": 2980}, {"errors": 0.014831719920039177, "time-step": 2981}, {"errors": 0.014806082472205162, "time-step": 2982}, {"errors": 0.014780489727854729, "time-step": 2983}, {"errors": 0.014754961244761944, "time-step": 2984}, {"errors": 0.014729497954249382, "time-step": 2985}, {"errors": 0.014704076573252678, "time-step": 2986}, {"errors": 0.014678722247481346, "time-step": 2987}, {"errors": 0.014653431251645088, "time-step": 2988}, {"errors": 0.01462819054722786, "time-step": 2989}, {"errors": 0.01460299827158451, "time-step": 2990}, {"errors": 0.014577865600585938, "time-step": 2991}, {"errors": 0.014552796259522438, "time-step": 2992}, {"errors": 0.01452777348458767, "time-step": 2993}, {"errors": 0.014502815902233124, "time-step": 2994}, {"errors": 0.014477904886007309, "time-step": 2995}, {"errors": 0.014453059062361717, "time-step": 2996}, {"errors": 0.014428270980715752, "time-step": 2997}, {"errors": 0.014403535053133965, "time-step": 2998}, {"errors": 0.014378848485648632, "time-step": 2999}]}}, {"mode": "vega-lite"});
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The main difference between the error curve for our own implementation (<strong>Chart 2</strong>) and the Keras version is the speed at which the error declines. This is mostly accounted for the selection of the Adam optimizer instead of "plain" backpropagation.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
<span class="n">num_correct_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_correct_predictions</span> <span class="o">/</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Multi-layer perceptron accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Multi-layer perceptron accuracy: 100.00%
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">plot_model</span>
<span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">to_file</span><span class="o">=</span><span class="s1">&#39;model.png&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">FileNotFoundError</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/pydot.py</span> in <span class="ansi-cyan-fg">create</span><span class="ansi-blue-fg">(self, prog, format, encoding)</span>
<span class="ansi-green-intense-fg ansi-bold">   1914</span>                 arguments<span class="ansi-blue-fg">=</span>arguments<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 1915</span><span class="ansi-red-fg">                 </span>working_dir<span class="ansi-blue-fg">=</span>tmp_dir<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1916</span>             )

<span class="ansi-green-fg">~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/pydot.py</span> in <span class="ansi-cyan-fg">call_graphviz</span><span class="ansi-blue-fg">(program, arguments, working_dir, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    135</span>         stdout<span class="ansi-blue-fg">=</span>subprocess<span class="ansi-blue-fg">.</span>PIPE<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 136</span><span class="ansi-red-fg">         </span><span class="ansi-blue-fg">**</span>kwargs
<span class="ansi-green-intense-fg ansi-bold">    137</span>     )

<span class="ansi-green-fg">~/.pyenv/versions/3.6.10/lib/python3.6/subprocess.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>                                 errread<span class="ansi-blue-fg">,</span> errwrite<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 729</span><span class="ansi-red-fg">                                 restore_signals, start_new_session)
</span><span class="ansi-green-intense-fg ansi-bold">    730</span>         <span class="ansi-green-fg">except</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/.pyenv/versions/3.6.10/lib/python3.6/subprocess.py</span> in <span class="ansi-cyan-fg">_execute_child</span><span class="ansi-blue-fg">(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)</span>
<span class="ansi-green-intense-fg ansi-bold">   1363</span>                             err_msg <span class="ansi-blue-fg">+=</span> <span class="ansi-blue-fg">&#39;: &#39;</span> <span class="ansi-blue-fg">+</span> repr<span class="ansi-blue-fg">(</span>err_filename<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">-&gt; 1364</span><span class="ansi-red-fg">                     </span><span class="ansi-green-fg">raise</span> child_exception_type<span class="ansi-blue-fg">(</span>errno_num<span class="ansi-blue-fg">,</span> err_msg<span class="ansi-blue-fg">,</span> err_filename<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1365</span>                 <span class="ansi-green-fg">raise</span> child_exception_type<span class="ansi-blue-fg">(</span>err_msg<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;dot&#39;: &#39;dot&#39;

During handling of the above exception, another exception occurred:

<span class="ansi-red-fg">FileNotFoundError</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py</span> in <span class="ansi-cyan-fg">_check_pydot</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span>         <span class="ansi-red-fg"># to check the pydot/graphviz installation.</span>
<span class="ansi-green-fg">---&gt; 28</span><span class="ansi-red-fg">         </span>pydot<span class="ansi-blue-fg">.</span>Dot<span class="ansi-blue-fg">.</span>create<span class="ansi-blue-fg">(</span>pydot<span class="ansi-blue-fg">.</span>Dot<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     29</span>     <span class="ansi-green-fg">except</span> OSError<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/pydot.py</span> in <span class="ansi-cyan-fg">create</span><span class="ansi-blue-fg">(self, prog, format, encoding)</span>
<span class="ansi-green-intense-fg ansi-bold">   1921</span>                     prog=prog)
<span class="ansi-green-fg">-&gt; 1922</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">raise</span> OSError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1923</span>             <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">FileNotFoundError</span>: [Errno 2] &#34;dot&#34; not found in path.

During handling of the above exception, another exception occurred:

<span class="ansi-red-fg">OSError</span>                                   Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-19-a70009143d02&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-green-fg">from</span> keras<span class="ansi-blue-fg">.</span>utils <span class="ansi-green-fg">import</span> plot_model
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>plot_model<span class="ansi-blue-fg">(</span>model<span class="ansi-blue-fg">,</span> to_file<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;model.png&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py</span> in <span class="ansi-cyan-fg">plot_model</span><span class="ansi-blue-fg">(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)</span>
<span class="ansi-green-intense-fg ansi-bold">    238</span>     &#34;&#34;&#34;
<span class="ansi-green-intense-fg ansi-bold">    239</span>     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,
<span class="ansi-green-fg">--&gt; 240</span><span class="ansi-red-fg">                        expand_nested, dpi)
</span><span class="ansi-green-intense-fg ansi-bold">    241</span>     _<span class="ansi-blue-fg">,</span> extension <span class="ansi-blue-fg">=</span> os<span class="ansi-blue-fg">.</span>path<span class="ansi-blue-fg">.</span>splitext<span class="ansi-blue-fg">(</span>to_file<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    242</span>     <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> extension<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py</span> in <span class="ansi-cyan-fg">model_to_dot</span><span class="ansi-blue-fg">(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)</span>
<span class="ansi-green-intense-fg ansi-bold">     77</span>     <span class="ansi-green-fg">from</span> <span class="ansi-blue-fg">.</span><span class="ansi-blue-fg">.</span>models <span class="ansi-green-fg">import</span> Sequential
<span class="ansi-green-intense-fg ansi-bold">     78</span> 
<span class="ansi-green-fg">---&gt; 79</span><span class="ansi-red-fg">     </span>_check_pydot<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     80</span>     <span class="ansi-green-fg">if</span> subgraph<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     81</span>         dot <span class="ansi-blue-fg">=</span> pydot<span class="ansi-blue-fg">.</span>Cluster<span class="ansi-blue-fg">(</span>style<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;dashed&#39;</span><span class="ansi-blue-fg">,</span> graph_name<span class="ansi-blue-fg">=</span>model<span class="ansi-blue-fg">.</span>name<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py</span> in <span class="ansi-cyan-fg">_check_pydot</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     29</span>     <span class="ansi-green-fg">except</span> OSError<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     30</span>         raise OSError(
<span class="ansi-green-fg">---&gt; 31</span><span class="ansi-red-fg">             </span><span class="ansi-blue-fg">&#39;`pydot` failed to call GraphViz.&#39;</span>
<span class="ansi-green-intense-fg ansi-bold">     32</span>             <span class="ansi-blue-fg">&#39;Please install GraphViz (https://www.graphviz.org/) &#39;</span>
<span class="ansi-green-intense-fg ansi-bold">     33</span>             &#39;and ensure that its executables are in the $PATH.&#39;)

<span class="ansi-red-fg">OSError</span>: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Again, we reached 100% of accuracy.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Multilayer-perceptron-limitations">Multilayer perceptron limitations<a class="anchor-link" href="#Multilayer-perceptron-limitations"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Multilayer perceptrons (and multilayer neural networks more) generally have many limitations worth mentioning. I will focus on a few that are more evident at this point and I'll introduce more complex issues in later chapters.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-time">Training time<a class="anchor-link" href="#Training-time"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first and more obvious limitation of the multilayer perceptron is <strong>training time</strong>. It takes an awful lot of iterations for the algorithm to learn to solve a very simple logic problem like the XOR. <strong>This is not an exception but the norm</strong>. Most neural networks you'd encounter in the wild nowadays need from hundreds up to thousands of iterations to reach their top-level accuracy. This has been a common point of criticism, particularly because human learning seems to be way more sample efficient.</p>
<p>There are multiple answers to the training time problem. A first argument has to do with raw <strong>processing capacity</strong>. It is seemingly obvious that a neural network with 1 hidden layer and 3 units does not get even close to the massive computational capacity of the human brain. Even if you consider a small subsection of the brain, and design a very large neural network with dozens of layers and units, the brain still has the advantage in most cases. Of course, this alone probably does not account for the entire gap between humans and neural networks but is a point to consider. A second argument refers to the massive <strong>past training experience</strong> accumulated by humans. Neural networks start from scratch every single time. Humans do not reset their storage memories and skills before attempting to learn something new. On the contrary, humans learn and reuse past learning experience across domains continuously. A third argument is related to the <strong>richness of the training data</strong> experienced by humans. Humans not only rely on past learning experiences but also on more <em>complex and multidimensional training data</em>. Humans integrate signals from all senses (visual, auditory, tactile, etc.) when learning which most likely speeds up the process. In any case, this is still a major issue and a hot topic of research.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Multilayer-perceptrons-are-&quot;fragile&quot;">Multilayer perceptrons are "fragile"<a class="anchor-link" href="#Multilayer-perceptrons-are-&quot;fragile&quot;"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A second notorious limitation is how <strong>brittle</strong> multilayer perceptrons are to <strong>architectural decisions</strong>. An extra layer, a +0.001 in the learning rate, random uniform weight instead for random normal weights, and or even a different random seed can turn perfectly a functional neural network into a useless one. This is partially related to the fact we are trying to solve a nonconvex optimization problem. Gradient descent has no way to find the actual global minima in the error surface. You just can hope it will find a good enough local minima for your problem. All of this force neural network researchers to <strong>search over enormous combinatorial spaces of "hyperparameters"</strong> (i.e., like the learning rate, number layers, etc. Anything but the network weights and biases). In a way, you have to embrace the fact that perfect solutions are rarely found unless you are dealing with simple problems with known solutions like the XOR. Surprisingly, it is often the case that well designed neural networks are able to learn "good enough" solutions for a wide variety of problems. Creating more robust neural networks architectures is another present challenge and hot research topic.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-biological-plasubility-of-backpropagation">The biological plasubility of backpropagation<a class="anchor-link" href="#The-biological-plasubility-of-backpropagation"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The last issue I'll mention is the elephant in the room: <strong>it is not clear that the brain learns via backpropagation</strong>. Rumelhart, Hinton, and Williams presented no evidence in favor of this assumption. You may think that it does not matter because neural networks do not pretend to be exact replicas of the brain anyways. Yet, it is a highly critical issue coming from the perspective of creating "biologically plausible" models of cognition, which is the PDP group perspective. Remember that one of the main problems for Rumelhart was to find a learning mechanism for networks with non-linear units. If the learning mechanism is not plausible, Does the model have any credibility at all? Fortunately, in the last 35 years we have learned quite a lot about the brain, and <a href="https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19">several researchers have proposed how the brain could implement "something like" backpropagation</a>30012-9). Still, keep in mind that this is a highly debated topic and it may pass some time before we reach a resolution.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusions">Conclusions<a class="anchor-link" href="#Conclusions"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The introduction of multilayer perceptrons trained with backpropagation was a major breakthrough in cognitive science and artificial intelligence in the '80s. It brought back to life a line of research that many thought dead for a while. The key for its success was its ability to overcome one of the major criticism from the previous decade: <strong>its inability to solve problems that required non-linear solutions</strong>.</p>
<p>From a cognitive science perspective, the real question is whether such advance says something meaningful about the <strong>plausibility of neural networks as models of cognition</strong>. That is a tough question. If you are in the "neural network team" of course you'd think it does. If you are more skeptic you'd rapidly point out to the many weaknesses and unrealistic assumptions on which neural networks depend on.</p>
<p>Maybe the best way of thinking about this type of advances in neural networks models of cognition is as another piece of a very complicated puzzle. The "puzzle" here is a <strong>working hypothesis</strong>: you are committed to the idea that the puzzle of cognition looks like a neural network when assembled, and your mission is to figure out all the pieces and putting them together. You may be wrong, maybe the puzzle at the end looks like something different, and you'll be proven wrong. Yet, at least in this sense, multilayer perceptrons were a crucial step forward in the neural network research agenda.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">References<a class="anchor-link" href="#References"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep Feedforward Networks. In Deep Learning. MIT Press. <a href="https://www.deeplearningbook.org/contents/mlp.html">https://www.deeplearningbook.org/contents/mlp.html</a></p>
<p>Kelley, H. J. (1960). Gradient theory of optimal flight paths. Ars Journal, 30(10), 947–954.</p>
<p>Bryson, A. E. (1961). A gradient method for optimizing multi-stage allocation processes. Proc. Harvard Univ. Symposium on Digital Computers and Their Applications, 72.</p>
<p>Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J. (1986). Learning Internal Representations by Error Propagation. In Parallel Distributed Processing: Explorations in the Microestructure of Cognition (Vol. 1). MIT Press.</p>
<p>Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323(6088), 533–536.</p>
<p>Werbos, P. J. (1994). The roots of backpropagation: From ordered derivatives to neural networks and political forecasting (Vol. 1). John Wiley &amp; Sons.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Useful-on-line-resources:">Useful on-line resources:<a class="anchor-link" href="#Useful-on-line-resources:"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The internet is flooded with learning resourced about neural networks. Here a selection of my personal favorites for this topic:</p>
<ul>
<li><a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">3Blue1Brown: Neural Networks Series</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU">Welch Labs: Neural Networks Demystified</a></li>
<li><a href="http://neuralnetworksanddeeplearning.com/chap2.html">Michael Nielsen's Neural Networks and Deep Learning Book: How the backpropagation algorithm works</a></li>
</ul>

</div>
</div>
</div>
</div>

 


    </main>
    