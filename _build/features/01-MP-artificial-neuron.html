---
redirect_from:
  - "/features/01-mp-artificial-neuron"
interact_link: content/features/01-MP-artificial-neuron.ipynb
kernel_name: python3
kernel_path: content/features
has_widgets: false
title: |-
  The McCulloch-Pitts Artificial Neuron
pagenum: 3
prev_page:
  url: /features/00-intro.html
next_page:
  url: /features/02-rossenblatt-perceptron.html
suffix: .ipynb
search: neuron mcculloch pitts sum threshold neurons artificial mathematical computational its activity logical synaptic inputs input firing t step boolean model function not w weighted turings machines provided turing simple described nervous behavior logic main center excitatory inhibitory fires where functions study reasoning weights value activation vector modern computer abstract devices limitations machine implementation en wikipedia org wiki calculus ideas immanent axon via terminals dendrites synapses figure centerfigure br style line height px src images svg width signals pre post fire passed such few thinking single cognitive models cognition formulation y cases text geq otherwise considered contribution instance iw axis output

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">The McCulloch-Pitts Artificial Neuron</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Alan Turing's formalization of computation as Turing's Machines provided the theoretical and mathematical foundations for modern computer science.  In brief, Turing Machines "...are simple abstract computational devices intended to help investigate the extent and limitations of what can be computed." (<a href="https://plato.stanford.edu/entries/turing-machine/">https://plato.stanford.edu/entries/turing-machine/</a>). Every modern computer device can be described as a Turing Machine, regardless of the details of its physical implementation (transistors, random access memory, etc.). This foundation provided the inspiration to <a href="https://en.wikipedia.org/wiki/Warren_McCulloch">Warren McCulloch</a> and <a href="https://en.wikipedia.org/wiki/Walter_Pitts">Walter Pitts</a>, who in 1943, first proposed that neuronal activity in the brain can be represented as computational devices in resemblance to Turing's Machines  ("A Logical Calculus of the Ideas Immanent in Nervous Activity").</p>
<p>The crux of McCulloch and Pitts idea, is that given the <em>all-or-none</em> character of neural activity, the behavior of the nervous system can be described by means of <strong>propositional logic</strong>. Biological neurons are cells that can be described by three main elements: (1) the <strong>cell body</strong> containing the nucleus and metabolic machinery; (2) an <strong>axon</strong> that transmit information via its synaptic terminals; (3) and <strong>dendrites</strong> that receive inputs from other neurons via synapses. <strong>Figure 2</strong> shows an abstract scheme of the main components of two neurons and their synapses (REF).</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><center>Figure 1<center/>
<br style = “line-height:100px;”>
<img src="images/neuron_synapse.svg" width="70%"/></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Neurons communicate with each other by passing <strong>electro-chemical signals</strong> from the axon terminals in the pre-synaptic neuron to the dendrites in the post-synaptic neuron. Usually, each neuron connects to hundreds or thousands of neurons. For a neuron to "<em>fire</em>", certain <em>threshold</em> of electrochemical excitation must be passed. The <strong>combined excitatory and inhibitory input</strong> received by the post-synaptic neuron from the pre-synaptic neurons, determines whether the neuron <strong>passes such threshold and fires</strong>. Is this <em>firing</em> or <em>spiking</em> behavior that McCulloch and Pitts modeled computationally. Furthermore, by carefully calibrating the magnitude of the inhibitory and excitatory signals passed to a neuron, McCulloch and Pitts where able to emulate the behavior of a few boolean functions or logical gates, like the AND, OR, and NOR.</p>
<p>At this point, you may be thinking "<em>Hold on, this is a model of function of a single neuron, not of a cognitive process</em>", and your would be correct. Nevertheless, there a few good reasons why we study the McCulloch and Pitts model as a seminal work in computational models of cognition. This model was the first steeping-stone in the development of many computational models of cognition, like the perceptron and multilayer-preceptrons. Additionally, as we mentioned before, McCulloch and Pitts also showed that such model could be used to represent some boolean functions. Boolean functions are about essentially about logic, and logical reasoning is one of the main topics of study in cognitive sciences. In a way, the McCulloch and Pitts artificial neuron provided one of the first clues about how to study logic and reasoning in humans from a computational perspective.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Mathematical-Definition">Mathematical Definition<a class="anchor-link" href="#Mathematical-Definition"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>McCulloch and Pitts developed a mathematical formulation knows as <strong>linear threshold gate</strong>, which describes the activity of a single neuron with two states, firing or not-firing. In its simple form, the mathematical formulation is as follows:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
Sum = \sum_{i=1}^NI_iW_i
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
y(Sum)=
\begin{cases}
1, &amp; \text{if } Sum \geq T \\
0, &amp; \text{otherwise}
\end{cases}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Where  $I_1, I_2,..., I_N$ are input values  $\in\{0,1\}$ ;  $W_1, W_2,..., W_N$ are weights associated with each input $\in\{-1,1\}$ ; $Sum$ is the weighted sum of inputs; and $T$ is a predefined threshold value for the neuron activation (i.e., <em>firing</em>).  An input is considered <strong>excitatory</strong> when its contribution to the weighted sum is positive, for instance $I_1*W_1 = 1 * 1 = 1$; whereas an input is considered <strong>inhibitory</strong> when its contribution to the weighted sum is negative, for instance $I_1*W_1 = 1 * -1 = -1$. If the value of $Sum$ is $\geq$ $T$, the neuron fires, otherwise, it does not.  <strong>Figure 2</strong> display a graphical representation of the function.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>Figure 2</center>
<br style = “line-height:100px;”>
<center><img src="images/linear_threshold_function_crop.svg" width="40%" /></center>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is known as an <em>step-function</em>, where the $y$-axis encode the activation-state of the neuron, and the $Sum$-axis encodes the output of the weighted sum of inputs.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Code-implementation">Code implementation<a class="anchor-link" href="#Code-implementation"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Implementing the McCulloch-Pitts artificial neuron in code is very simple thanks to the features and libraries of high-level programming languages that we have available today. We can do this in four steps using <code>Python</code> and <code>Numpy</code>:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Step 1</strong>: create a vector of inputs and a vector of weights</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span><span class="c1"># generate random vector I, sampling from {0,1}</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># generate random vector W, sampling from {-1,1} </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Input vector:</span><span class="si">{I}</span><span class="s1">, Weight vector:</span><span class="si">{W}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Input vector:[0 1 1], Weight vector:[-1  1  1]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Step 2</strong>: compute the dot product between the vector of inputs and weights</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dot</span> <span class="o">=</span> <span class="n">I</span> <span class="o">@</span> <span class="n">W</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Dot product: </span><span class="si">{dot}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dot product: 2
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Step 3</strong>: define the threshold activation function</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">linear_threshold_gate</span><span class="p">(</span><span class="n">dot</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">T</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Returns the binary threshold output&#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">dot</span> <span class="o">&gt;=</span> <span class="n">T</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Step 4</strong>: compute the output based on the threshold value</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">activation</span> <span class="o">=</span> <span class="n">linear_threshold_gate</span><span class="p">(</span><span class="n">dot</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Activation: </span><span class="si">{activation}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Activation: 1
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the previous example, the threshold was set to $T=1$. Since $Sum=2$, the neuron fires. If we increase the threshold for firing to  $T=3$, the neuron will not fire.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">activation</span> <span class="o">=</span> <span class="n">linear_threshold_gate</span><span class="p">(</span><span class="n">dot</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Activation: </span><span class="si">{activation}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Activation: 0
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Boolean-Algebra-Using-the-McCulloch-Pitts-Artificial-Neuron">Boolean Algebra Using the McCulloch-Pitts Artificial Neuron<a class="anchor-link" href="#Boolean-Algebra-Using-the-McCulloch-Pitts-Artificial-Neuron"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Logical thinking and reasoning are two of the most...</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Limitations-of-the-McCulloch-Pitts-Artificial-Neuron">Limitations of the McCulloch-Pitts Artificial Neuron<a class="anchor-link" href="#Limitations-of-the-McCulloch-Pitts-Artificial-Neuron"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>No learning..</li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">References<a class="anchor-link" href="#References"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>McCulloch, W. S., &amp; Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4), 115-133.</li>
</ul>

</div>
</div>
</div>
</div>

 


    </main>
    